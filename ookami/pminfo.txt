
jbd2.njournals
Help:
Count of active JBD2 (Journal Block Device v2) devices

jbd2.transaction.count
Help:
This metric is sourced from the per-device /proc/fs/jbd2 info file.

jbd2.transaction.requested
Help:
This metric is sourced from the per-device /proc/fs/jbd2 info file.

jbd2.transaction.max_blocks
Help:
This metric is sourced from the per-device /proc/fs/jbd2 info file.

jbd2.transaction.total.blocks
Help:
Total number of blocks in all transactions since device mounted.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.blocks_logged
Help:
Total number of blocks logged in all transactions since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.handles
Help:
Total count of handles used in all transactions since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.waiting
Help:
Total time spent waiting for transactions to complete since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.request_delay
Help:
Total request delay for all transactions to complete since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.running
Help:
Total transaction running time over all transactions since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.being_locked
Help:
Total transaction locked time over all transactions since mount.
Derived from values in the per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.flushing_ordered_mode_data
Help:
Total time flushing data (ordered mode) for all transactions since
mount.  Derived from values in per-device /proc/fs/jbd2 info files.

jbd2.transaction.total.time.logging
Help:
Total time spent logging transactions for all transactions since
mount.  Derived from values in per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.blocks
Help:
Average number of blocks per transaction for all transactions.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.blocks_logged
Help:
Average number of blocks logged per transaction for all transactions.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.handles
Help:
Average number of handles used per transaction for all transactions.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.waiting
Help:
Average time spent waiting for transactions to complete since mount.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.request_delay
Help:
Average request delay for all transactions to complete since mount.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.running
Help:
Average transaction running time over all transactions since mount.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.being_locked
Help:
Average transaction locked time over all transactions since mount.
Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.flushing_ordered_mode_data
Help:
Average time flushing data (ordered mode) for all transactions since
mount.  Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.logging
Help:
Average time spent logging transactions for all transactions since
mount.  Exported directly from per-device /proc/fs/jbd2 info files.

jbd2.transaction.average.time.committing
Help:
Average time spent committing transactions for all transactions since
mount.  Exported directly from per-device /proc/fs/jbd2 info files.

kvm.trace.kvm_vcpu_wakeup
Full Help: Error: One-line or help text is not available

kvm.trace.kvm_hypercall
Full Help: Error: One-line or help text is not available

kvm.trace.kvm_mmio
Full Help: Error: One-line or help text is not available

kvm.trace.kvm_entry
Full Help: Error: One-line or help text is not available

kvm.trace.kvm_exit
Full Help: Error: One-line or help text is not available

kvm.trace.count
Full Help: Error: One-line or help text is not available

kvm.efer_reload
Help:
Number of Extended Feature Enable Register (EFER) reloads.

kvm.exits
Help:
Number of guest exits from I/O port accesses. 

kvm.fpu_reload
Help:
Number of reload fpu(Float Point Unit).

kvm.halt_attempted_poll
Help:
Number of times the vcpu attempts to polls.

kvm.halt_exits
Help:
This type of exit is usually seen when a guest is idle.

kvm.halt_successful_poll
Help:
The number of times the vcpu attempts to polls successfully.

kvm.halt_wakeup
Help:
Number of wakeups from a halt.

kvm.host_state_reload
Help:
Currently tallies MSR setup and guest MSR reads.

kvm.hypercalls
Help:
Number of guest hypervisor service calls.

kvm.insn_emulation
Help:
Number of insn_emulation attempts.

kvm.insn_emulation_fail
Help:
Number of failed insn_emulation attempts.

kvm.invlpg
Help:
Number of invlpg attepts. 

kvm.io_exits
Help:
Number of guest exits from I/O port accesses.

kvm.irq_exits
Help:
Number of guest exits due to external interrupts.

kvm.irq_injections
Help:
Number of interrupts sent to guests.

kvm.irq_window
Help:
Number of guest exits from an outstanding interrupt window.

kvm.largepages
Help:
Number of large pages currently in use.

kvm.mmio_exits
Help:
Number of guest exits due to memory mapped I/O (MMIO) accesses.

kvm.mmu_cache_miss
Help:
Number of cache miss.

kvm.mmu_flooded
Help:
This counts detected write operations not of individual write operations.

kvm.mmu_pde_zapped
Help:
Number of page directory entry (PDE) destruction operations.

kvm.mmu_pte_updated
Help:
Number of PTE updated. 

kvm.mmu_pte_write
Help:
Number of PTE write.

kvm.mmu_recycled
Help:
Number of shadow pages that can be reclaimed.

kvm.mmu_shadow_zapped
Help:
Number of shadow pages that has been zapped.

kvm.mmu_unsync
Help:
Number of non-synchronized pages which are not yet unlinked 

kvm.nmi_injections
Help:
Number of Non-maskable Interrupt (NMI) injections.

kvm.nmi_window
Help:
Number of guest exits from (outstanding) Non-maskable Interrupt (NMI) windows.

kvm.pf_fixed
Help:
Number of fixed (non-paging) page table entry (PTE) maps.

kvm.pf_guest
Help:
Number of page faults injected into guests.

kvm.remote_tlb_flush
Help:
Number of tlb_flush operations performed by the hypervisor.

kvm.request_irq
Help:
Number of guest interrupt window request exits.

kvm.signal_exits
Help:
Number of guest exits due to pending signals from the host.

kvm.tlb_flush
Help:
Number of tlb_flush operations performed by the hypervisor.

hinv.physmem
Help:
total system memory metric from /proc/meminfo

hinv.pagesize
Help:
The memory page size of the running kernel in bytes.

hinv.ncpu
Help:
number of CPUs in the system

hinv.ndisk
Help:
number of disks in the system

hinv.nfilesys
Help:
number of (local) file systems currently mounted

hinv.ninterface
Help:
number of active (up) network interfaces

hinv.nnode
Help:
number of NUMA nodes in the system

hinv.machine
Help:
hardware identifier as reported by uname(2)

hinv.hugepagesize
Help:
The memory huge page size of the running kernel in bytes.

hinv.ntape
Help:
number of Linux scsi tape devices

hinv.map.scsi
Help:
There is one string value for each SCSI device active in the system,
as extracted from /proc/scsi/scsi. The external instance name
for each device is in the format scsiD:C:I:L where
D is controller number, C is channel number, I is device ID
and L is the SCSI LUN number for the device. The values for this
metric are the actual device names (sd[a-z] are SCSI disks, st[0-9]
are SCSI tapes and scd[0-9] are SCSI CD-ROMS.

hinv.map.cpu_num
Help:
logical to physical CPU mapping for each CPU

hinv.map.cpu_node
Help:
logical CPU to NUMA node mapping for each CPU

hinv.map.dmname
Help:
per-device-mapper device persistent name mapping to dm-[0-9]*

hinv.map.mdname
Help:
per-multi-device device persistent name mapping to md[0-9]*

hinv.cpu.clock
Help:
clock rate in Mhz for each CPU as reported by /proc/cpuinfo

hinv.cpu.vendor
Help:
manufacturer of each CPU as reported by /proc/cpuinfo

hinv.cpu.model
Help:
model number of each CPU as reported by /proc/cpuinfo

hinv.cpu.stepping
Help:
stepping of each CPU as reported by /proc/cpuinfo

hinv.cpu.cache
Help:
primary cache size of each CPU as reported by /proc/cpuinfo

hinv.cpu.bogomips
Help:
bogo mips rating for each CPU as reported by /proc/cpuinfo

hinv.cpu.model_name
Help:
model name of each CPU as reported by /proc/cpuinfo

hinv.cpu.flags
Help:
Hardware capability flags for each CPU as reported by /proc/cpuinfo

hinv.cpu.cache_alignment
Help:
Cache alignment for each CPU as reported by /proc/cpuinfo

hinv.cpu.online
Help:
CPU online state from /sys/devices/system/cpu/*/online

hinv.node.online
Help:
NUMA node online state from /sys/devices/system/node/*/online

kernel.all.load
Help:
1, 5 and 15 minute load average

kernel.all.intr
Help:
The value is the first value from the intr field in /proc/stat,
which is a counter of the total number of interrupts processed.
The value is normally converted to a rate (count/second).
This counter usually increases by at least HZ/second,
i.e. the clock interrupt rate, wehich is usually 100/second.

See also kernel.percpu.intr and kernel.percpu.interrupts to get
the breakdown of interrupt count by interrupt type and which CPU
processed each one.

kernel.all.pswitch
Help:
context switches metric from /proc/stat

kernel.all.sysfork
Help:
fork rate metric from /proc/stat

kernel.all.running
Help:
number of currently running processes from /proc/stat

kernel.all.blocked
Help:
number of currently blocked processes from /proc/stat

kernel.all.hz
Help:
value of HZ (jiffies/second) for the currently running kernel

kernel.all.uptime
Help:
time the current kernel has been running

kernel.all.idletime
Help:
time the current kernel has been idle since boot

kernel.all.nusers
Help:
number of user sessions on the system (including root)

kernel.all.nroots
Help:
number of root user sessions on the system (only root)

kernel.all.nsessions
Help:
number of utmp sessions (login records)

kernel.all.lastpid
Help:
most recently allocated process identifier

kernel.all.runnable
Help:
total number of processes in the (per-CPU) run queues

kernel.all.nprocs
Help:
total number of processes (lightweight)

kernel.all.pid_max
Help:
maximum process identifier from /proc/sys/kernel/pid_max

kernel.all.cpu.user
Help:
total user CPU time from /proc/stat for all CPUs, including guest CPU time

kernel.all.cpu.nice
Help:
total nice user CPU time from /proc/stat for all CPUs, including guest time

kernel.all.cpu.sys
Help:
total sys CPU time from /proc/stat for all CPUs

kernel.all.cpu.idle
Help:
total idle CPU time from /proc/stat for all CPUs

kernel.all.cpu.intr
Help:
Total time spent processing interrupts on all CPUs.
This value includes both soft and hard interrupt processing time.

kernel.all.cpu.steal
Help:
Total CPU time when a CPU had a runnable process, but the hypervisor
(virtualisation layer) chose to run something else instead.

kernel.all.cpu.guest
Help:
Total CPU time spent running virtual guest operating systems.

kernel.all.cpu.vuser
Help:
total user CPU time from /proc/stat for all CPUs, excluding guest CPU time

kernel.all.cpu.guest_nice
Help:
Total CPU nice time spent running virtual guest operating systems.

kernel.all.cpu.vnice
Help:
total nice user CPU time from /proc/stat for all CPUs, excluding guest time

kernel.all.cpu.wait.total
Help:
total wait CPU time from /proc/stat for all CPUs

kernel.all.cpu.irq.soft
Help:
Total soft interrupt CPU time (deferred interrupt handling code,
not run in the initial interrupt handler).

kernel.all.cpu.irq.hard
Help:
Total hard interrupt CPU time ("hard" interrupt handling code
is the code run directly on receipt of the initial hardware
interrupt, and does not include "soft" interrupt handling code
which is deferred until later).

kernel.all.interrupts.total
Full Help: Error: One-line or help text is not available

kernel.all.interrupts.errors
Help:
This is a global counter (normally converted to a count/second)
for any and all errors that occur while handling interrupts.

kernel.all.softirqs.total
Full Help: Error: One-line or help text is not available

kernel.all.entropy.avail
Help:
entropy available to random number generators

kernel.all.entropy.poolsize
Help:
maximum size of the entropy pool

kernel.all.pressure.cpu.some.avg
Help:
Indicates the time in which at least some tasks stalled on CPU resources.
The ratios are tracked as recent trends over ten second, one minute,
and five minute windows.
Pressure stall information (PSI) from /proc/pressure/cpu.

kernel.all.pressure.cpu.some.total
Help:
Indicates the time in which at least some tasks stalled on CPU resources.
Pressure stall information (PSI) from /proc/pressure/cpu.

kernel.all.pressure.memory.some.avg
Help:
Indicates the time in which at least some tasks stalled on memory resources.
The ratios are tracked as recent trends over ten second, one minute,
and five minute windows.
Pressure stall information (PSI) from /proc/pressure/memory.

kernel.all.pressure.memory.some.total
Help:
The CPU time for which at least some tasks stalled on memory resources.
Pressure stall information (PSI) from /proc/pressure/memory.

kernel.all.pressure.memory.full.avg
Help:
Indicates the time in which all tasks stalled on memory resources.
The ratios are tracked as recent trends over ten second, one minute,
and five minute windows.
Pressure stall information (PSI) from /proc/pressure/memory.

kernel.all.pressure.memory.full.total
Help:
The CPU time for which all tasks stalled on memory resources.
Pressure stall information (PSI) from /proc/pressure/memory.

kernel.all.pressure.io.some.avg
Help:
Indicates the time in which at least some tasks stalled on IO resources.
The ratios are tracked as recent trends over ten second, one minute,
and five minute windows.
Pressure stall information (PSI) from /proc/pressure/io.

kernel.all.pressure.io.some.total
Help:
The CPU time in which at least some tasks stalled on IO resources.
Pressure stall information (PSI) from /proc/pressure/io.

kernel.all.pressure.io.full.avg
Help:
Indicates the time in which all tasks stalled on IO resources.
The ratios are tracked as recent trends over ten second, one minute,
and five minute windows.
Pressure stall information (PSI) from /proc/pressure/io.

kernel.all.pressure.io.full.total
Help:
The CPU time in which all tasks stalled on IO resources.
Pressure stall information (PSI) from /proc/pressure/io.

kernel.percpu.interrupts.Err
Full Help: Error: One-line or help text is not available

kernel.percpu.interrupts.IPI6
Help:
CPU wake-up interrupts

kernel.percpu.interrupts.IPI5
Help:
IRQ work interrupts

kernel.percpu.interrupts.IPI4
Help:
Timer broadcast interrupts

kernel.percpu.interrupts.IPI3
Help:
CPU stop (for crash dump) interrupts

kernel.percpu.interrupts.IPI2
Help:
CPU stop interrupts

kernel.percpu.interrupts.IPI1
Help:
Function call interrupts

kernel.percpu.interrupts.IPI0
Help:
Rescheduling interrupts

kernel.percpu.interrupts.line323
Help:
ITS-MSI 67633152 Edge nvidia

kernel.percpu.interrupts.line322
Help:
ITS-MSI 524288 Edge nvidia

kernel.percpu.interrupts.line321
Help:
ITS-MSI 71827519 Edge mlx5_comp62@pci:0000:89:00.0

kernel.percpu.interrupts.line320
Help:
ITS-MSI 71827518 Edge mlx5_comp61@pci:0000:89:00.0

kernel.percpu.interrupts.line319
Help:
ITS-MSI 71827517 Edge mlx5_comp60@pci:0000:89:00.0

kernel.percpu.interrupts.line318
Help:
ITS-MSI 71827516 Edge mlx5_comp59@pci:0000:89:00.0

kernel.percpu.interrupts.line317
Help:
ITS-MSI 71827515 Edge mlx5_comp58@pci:0000:89:00.0

kernel.percpu.interrupts.line316
Help:
ITS-MSI 71827514 Edge mlx5_comp57@pci:0000:89:00.0

kernel.percpu.interrupts.line315
Help:
ITS-MSI 71827513 Edge mlx5_comp56@pci:0000:89:00.0

kernel.percpu.interrupts.line314
Help:
ITS-MSI 71827512 Edge mlx5_comp55@pci:0000:89:00.0

kernel.percpu.interrupts.line313
Help:
ITS-MSI 71827511 Edge mlx5_comp54@pci:0000:89:00.0

kernel.percpu.interrupts.line312
Help:
ITS-MSI 71827510 Edge mlx5_comp53@pci:0000:89:00.0

kernel.percpu.interrupts.line311
Help:
ITS-MSI 71827509 Edge mlx5_comp52@pci:0000:89:00.0

kernel.percpu.interrupts.line310
Help:
ITS-MSI 71827508 Edge mlx5_comp51@pci:0000:89:00.0

kernel.percpu.interrupts.line309
Help:
ITS-MSI 71827507 Edge mlx5_comp50@pci:0000:89:00.0

kernel.percpu.interrupts.line308
Help:
ITS-MSI 71827506 Edge mlx5_comp49@pci:0000:89:00.0

kernel.percpu.interrupts.line307
Help:
ITS-MSI 71827505 Edge mlx5_comp48@pci:0000:89:00.0

kernel.percpu.interrupts.line306
Help:
ITS-MSI 71827504 Edge mlx5_comp47@pci:0000:89:00.0

kernel.percpu.interrupts.line305
Help:
ITS-MSI 71827503 Edge mlx5_comp46@pci:0000:89:00.0

kernel.percpu.interrupts.line304
Help:
ITS-MSI 71827502 Edge mlx5_comp45@pci:0000:89:00.0

kernel.percpu.interrupts.line303
Help:
ITS-MSI 71827501 Edge mlx5_comp44@pci:0000:89:00.0

kernel.percpu.interrupts.line302
Help:
ITS-MSI 71827500 Edge mlx5_comp43@pci:0000:89:00.0

kernel.percpu.interrupts.line301
Help:
ITS-MSI 71827499 Edge mlx5_comp42@pci:0000:89:00.0

kernel.percpu.interrupts.line300
Help:
ITS-MSI 71827498 Edge mlx5_comp41@pci:0000:89:00.0

kernel.percpu.interrupts.line299
Help:
ITS-MSI 71827497 Edge mlx5_comp40@pci:0000:89:00.0

kernel.percpu.interrupts.line298
Help:
ITS-MSI 71827496 Edge mlx5_comp39@pci:0000:89:00.0

kernel.percpu.interrupts.line297
Help:
ITS-MSI 71827495 Edge mlx5_comp38@pci:0000:89:00.0

kernel.percpu.interrupts.line296
Help:
ITS-MSI 71827494 Edge mlx5_comp37@pci:0000:89:00.0

kernel.percpu.interrupts.line295
Help:
ITS-MSI 71827493 Edge mlx5_comp36@pci:0000:89:00.0

kernel.percpu.interrupts.line294
Help:
ITS-MSI 71827492 Edge mlx5_comp35@pci:0000:89:00.0

kernel.percpu.interrupts.line293
Help:
ITS-MSI 71827491 Edge mlx5_comp34@pci:0000:89:00.0

kernel.percpu.interrupts.line292
Help:
ITS-MSI 71827490 Edge mlx5_comp33@pci:0000:89:00.0

kernel.percpu.interrupts.line291
Help:
ITS-MSI 71827489 Edge mlx5_comp32@pci:0000:89:00.0

kernel.percpu.interrupts.line290
Help:
ITS-MSI 71827488 Edge mlx5_comp31@pci:0000:89:00.0

kernel.percpu.interrupts.line289
Help:
ITS-MSI 71827487 Edge mlx5_comp30@pci:0000:89:00.0

kernel.percpu.interrupts.line288
Help:
ITS-MSI 71827486 Edge mlx5_comp29@pci:0000:89:00.0

kernel.percpu.interrupts.line287
Help:
ITS-MSI 71827485 Edge mlx5_comp28@pci:0000:89:00.0

kernel.percpu.interrupts.line286
Help:
ITS-MSI 71827484 Edge mlx5_comp27@pci:0000:89:00.0

kernel.percpu.interrupts.line285
Help:
ITS-MSI 71827483 Edge mlx5_comp26@pci:0000:89:00.0

kernel.percpu.interrupts.line284
Help:
ITS-MSI 71827482 Edge mlx5_comp25@pci:0000:89:00.0

kernel.percpu.interrupts.line283
Help:
ITS-MSI 71827481 Edge mlx5_comp24@pci:0000:89:00.0

kernel.percpu.interrupts.line282
Help:
ITS-MSI 71827480 Edge mlx5_comp23@pci:0000:89:00.0

kernel.percpu.interrupts.line281
Help:
ITS-MSI 71827479 Edge mlx5_comp22@pci:0000:89:00.0

kernel.percpu.interrupts.line280
Help:
ITS-MSI 71827478 Edge mlx5_comp21@pci:0000:89:00.0

kernel.percpu.interrupts.line279
Help:
ITS-MSI 71827477 Edge mlx5_comp20@pci:0000:89:00.0

kernel.percpu.interrupts.line278
Help:
ITS-MSI 71827476 Edge mlx5_comp19@pci:0000:89:00.0

kernel.percpu.interrupts.line277
Help:
ITS-MSI 71827475 Edge mlx5_comp18@pci:0000:89:00.0

kernel.percpu.interrupts.line276
Help:
ITS-MSI 71827474 Edge mlx5_comp17@pci:0000:89:00.0

kernel.percpu.interrupts.line275
Help:
ITS-MSI 71827473 Edge mlx5_comp16@pci:0000:89:00.0

kernel.percpu.interrupts.line274
Help:
ITS-MSI 71827472 Edge mlx5_comp15@pci:0000:89:00.0

kernel.percpu.interrupts.line273
Help:
ITS-MSI 71827471 Edge mlx5_comp14@pci:0000:89:00.0

kernel.percpu.interrupts.line272
Help:
ITS-MSI 71827470 Edge mlx5_comp13@pci:0000:89:00.0

kernel.percpu.interrupts.line271
Help:
ITS-MSI 71827469 Edge mlx5_comp12@pci:0000:89:00.0

kernel.percpu.interrupts.line270
Help:
ITS-MSI 71827468 Edge mlx5_comp11@pci:0000:89:00.0

kernel.percpu.interrupts.line269
Help:
ITS-MSI 71827467 Edge mlx5_comp10@pci:0000:89:00.0

kernel.percpu.interrupts.line268
Help:
ITS-MSI 71827466 Edge mlx5_comp9@pci:0000:89:00.0

kernel.percpu.interrupts.line267
Help:
ITS-MSI 71827465 Edge mlx5_comp8@pci:0000:89:00.0

kernel.percpu.interrupts.line266
Help:
ITS-MSI 71827464 Edge mlx5_comp7@pci:0000:89:00.0

kernel.percpu.interrupts.line265
Help:
ITS-MSI 71827463 Edge mlx5_comp6@pci:0000:89:00.0

kernel.percpu.interrupts.line264
Help:
ITS-MSI 71827462 Edge mlx5_comp5@pci:0000:89:00.0

kernel.percpu.interrupts.line263
Help:
ITS-MSI 71827461 Edge mlx5_comp4@pci:0000:89:00.0

kernel.percpu.interrupts.line262
Help:
ITS-MSI 71827460 Edge mlx5_comp3@pci:0000:89:00.0

kernel.percpu.interrupts.line261
Help:
ITS-MSI 71827459 Edge mlx5_comp2@pci:0000:89:00.0

kernel.percpu.interrupts.line260
Help:
ITS-MSI 71827458 Edge mlx5_comp1@pci:0000:89:00.0

kernel.percpu.interrupts.line259
Help:
ITS-MSI 71827457 Edge mlx5_comp0@pci:0000:89:00.0

kernel.percpu.interrupts.line258
Help:
ITS-MSI 71827456 Edge mlx5_async@pci:0000:89:00.0

kernel.percpu.interrupts.line257
Help:
ITS-MSI 5769279 Edge enp11s0f1-62

kernel.percpu.interrupts.line256
Help:
ITS-MSI 5769278 Edge enp11s0f1-61

kernel.percpu.interrupts.line255
Help:
ITS-MSI 5769277 Edge enp11s0f1-60

kernel.percpu.interrupts.line254
Help:
ITS-MSI 5769276 Edge enp11s0f1-59

kernel.percpu.interrupts.line253
Help:
ITS-MSI 5769275 Edge enp11s0f1-58

kernel.percpu.interrupts.line252
Help:
ITS-MSI 5769274 Edge enp11s0f1-57

kernel.percpu.interrupts.line251
Help:
ITS-MSI 5769273 Edge enp11s0f1-56

kernel.percpu.interrupts.line250
Help:
ITS-MSI 5769272 Edge enp11s0f1-55

kernel.percpu.interrupts.line249
Help:
ITS-MSI 5769271 Edge enp11s0f1-54

kernel.percpu.interrupts.line248
Help:
ITS-MSI 5769270 Edge enp11s0f1-53

kernel.percpu.interrupts.line247
Help:
ITS-MSI 5769269 Edge enp11s0f1-52

kernel.percpu.interrupts.line246
Help:
ITS-MSI 5769268 Edge enp11s0f1-51

kernel.percpu.interrupts.line245
Help:
ITS-MSI 5769267 Edge enp11s0f1-50

kernel.percpu.interrupts.line244
Help:
ITS-MSI 5769266 Edge enp11s0f1-49

kernel.percpu.interrupts.line243
Help:
ITS-MSI 5769265 Edge enp11s0f1-48

kernel.percpu.interrupts.line242
Help:
ITS-MSI 5769264 Edge enp11s0f1-47

kernel.percpu.interrupts.line241
Help:
ITS-MSI 5769263 Edge enp11s0f1-46

kernel.percpu.interrupts.line240
Help:
ITS-MSI 5769262 Edge enp11s0f1-45

kernel.percpu.interrupts.line239
Help:
ITS-MSI 5769261 Edge enp11s0f1-44

kernel.percpu.interrupts.line238
Help:
ITS-MSI 5769260 Edge enp11s0f1-43

kernel.percpu.interrupts.line237
Help:
ITS-MSI 5769259 Edge enp11s0f1-42

kernel.percpu.interrupts.line236
Help:
ITS-MSI 5769258 Edge enp11s0f1-41

kernel.percpu.interrupts.line235
Help:
ITS-MSI 5769257 Edge enp11s0f1-40

kernel.percpu.interrupts.line234
Help:
ITS-MSI 5769256 Edge enp11s0f1-39

kernel.percpu.interrupts.line233
Help:
ITS-MSI 5769255 Edge enp11s0f1-38

kernel.percpu.interrupts.line232
Help:
ITS-MSI 5769254 Edge enp11s0f1-37

kernel.percpu.interrupts.line231
Help:
ITS-MSI 5769253 Edge enp11s0f1-36

kernel.percpu.interrupts.line230
Help:
ITS-MSI 5769252 Edge enp11s0f1-35

kernel.percpu.interrupts.line229
Help:
ITS-MSI 5769251 Edge enp11s0f1-34

kernel.percpu.interrupts.line228
Help:
ITS-MSI 5769250 Edge enp11s0f1-33

kernel.percpu.interrupts.line227
Help:
ITS-MSI 5769249 Edge enp11s0f1-32

kernel.percpu.interrupts.line226
Help:
ITS-MSI 5769248 Edge enp11s0f1-31

kernel.percpu.interrupts.line225
Help:
ITS-MSI 5769247 Edge enp11s0f1-30

kernel.percpu.interrupts.line224
Help:
ITS-MSI 5769246 Edge enp11s0f1-29

kernel.percpu.interrupts.line223
Help:
ITS-MSI 5769245 Edge enp11s0f1-28

kernel.percpu.interrupts.line222
Help:
ITS-MSI 5769244 Edge enp11s0f1-27

kernel.percpu.interrupts.line221
Help:
ITS-MSI 5769243 Edge enp11s0f1-26

kernel.percpu.interrupts.line220
Help:
ITS-MSI 5769242 Edge enp11s0f1-25

kernel.percpu.interrupts.line219
Help:
ITS-MSI 5769241 Edge enp11s0f1-24

kernel.percpu.interrupts.line218
Help:
ITS-MSI 5769240 Edge enp11s0f1-23

kernel.percpu.interrupts.line217
Help:
ITS-MSI 5769239 Edge enp11s0f1-22

kernel.percpu.interrupts.line216
Help:
ITS-MSI 5769238 Edge enp11s0f1-21

kernel.percpu.interrupts.line215
Help:
ITS-MSI 5769237 Edge enp11s0f1-20

kernel.percpu.interrupts.line214
Help:
ITS-MSI 5769236 Edge enp11s0f1-19

kernel.percpu.interrupts.line213
Help:
ITS-MSI 5769235 Edge enp11s0f1-18

kernel.percpu.interrupts.line212
Help:
ITS-MSI 5769234 Edge enp11s0f1-17

kernel.percpu.interrupts.line211
Help:
ITS-MSI 5769233 Edge enp11s0f1-16

kernel.percpu.interrupts.line210
Help:
ITS-MSI 5769232 Edge enp11s0f1-15

kernel.percpu.interrupts.line209
Help:
ITS-MSI 5769231 Edge enp11s0f1-14

kernel.percpu.interrupts.line208
Help:
ITS-MSI 5769230 Edge enp11s0f1-13

kernel.percpu.interrupts.line207
Help:
ITS-MSI 5769229 Edge enp11s0f1-12

kernel.percpu.interrupts.line206
Help:
ITS-MSI 5769228 Edge enp11s0f1-11

kernel.percpu.interrupts.line205
Help:
ITS-MSI 5769227 Edge enp11s0f1-10

kernel.percpu.interrupts.line204
Help:
ITS-MSI 5769226 Edge enp11s0f1-9

kernel.percpu.interrupts.line203
Help:
ITS-MSI 5769225 Edge enp11s0f1-8

kernel.percpu.interrupts.line202
Help:
ITS-MSI 5769224 Edge enp11s0f1-7

kernel.percpu.interrupts.line201
Help:
ITS-MSI 5769223 Edge enp11s0f1-6

kernel.percpu.interrupts.line200
Help:
ITS-MSI 5769222 Edge enp11s0f1-5

kernel.percpu.interrupts.line199
Help:
ITS-MSI 5769221 Edge enp11s0f1-4

kernel.percpu.interrupts.line198
Help:
ITS-MSI 5769220 Edge enp11s0f1-3

kernel.percpu.interrupts.line197
Help:
ITS-MSI 5769219 Edge enp11s0f1-2

kernel.percpu.interrupts.line196
Help:
ITS-MSI 5769218 Edge enp11s0f1-1

kernel.percpu.interrupts.line195
Help:
ITS-MSI 5769217 Edge enp11s0f1-0

kernel.percpu.interrupts.line194
Help:
ITS-MSI 5769216 Edge mlx5_async@pci:0000:0b:00.1

kernel.percpu.interrupts.line193
Help:
ITS-MSI 5767231 Edge enp11s0f0-62

kernel.percpu.interrupts.line192
Help:
ITS-MSI 5767230 Edge enp11s0f0-61

kernel.percpu.interrupts.line191
Help:
ITS-MSI 5767229 Edge enp11s0f0-60

kernel.percpu.interrupts.line190
Help:
ITS-MSI 5767228 Edge enp11s0f0-59

kernel.percpu.interrupts.line189
Help:
ITS-MSI 5767227 Edge enp11s0f0-58

kernel.percpu.interrupts.line188
Help:
ITS-MSI 5767226 Edge enp11s0f0-57

kernel.percpu.interrupts.line187
Help:
ITS-MSI 5767225 Edge enp11s0f0-56

kernel.percpu.interrupts.line186
Help:
ITS-MSI 5767224 Edge enp11s0f0-55

kernel.percpu.interrupts.line185
Help:
ITS-MSI 5767223 Edge enp11s0f0-54

kernel.percpu.interrupts.line184
Help:
ITS-MSI 5767222 Edge enp11s0f0-53

kernel.percpu.interrupts.line183
Help:
ITS-MSI 5767221 Edge enp11s0f0-52

kernel.percpu.interrupts.line182
Help:
ITS-MSI 5767220 Edge enp11s0f0-51

kernel.percpu.interrupts.line181
Help:
ITS-MSI 5767219 Edge enp11s0f0-50

kernel.percpu.interrupts.line180
Help:
ITS-MSI 5767218 Edge enp11s0f0-49

kernel.percpu.interrupts.line179
Help:
ITS-MSI 5767217 Edge enp11s0f0-48

kernel.percpu.interrupts.line178
Help:
ITS-MSI 5767216 Edge enp11s0f0-47

kernel.percpu.interrupts.line177
Help:
ITS-MSI 5767215 Edge enp11s0f0-46

kernel.percpu.interrupts.line176
Help:
ITS-MSI 5767214 Edge enp11s0f0-45

kernel.percpu.interrupts.line175
Help:
ITS-MSI 5767213 Edge enp11s0f0-44

kernel.percpu.interrupts.line174
Help:
ITS-MSI 5767212 Edge enp11s0f0-43

kernel.percpu.interrupts.line173
Help:
ITS-MSI 5767211 Edge enp11s0f0-42

kernel.percpu.interrupts.line172
Help:
ITS-MSI 5767210 Edge enp11s0f0-41

kernel.percpu.interrupts.line171
Help:
ITS-MSI 5767209 Edge enp11s0f0-40

kernel.percpu.interrupts.line170
Help:
ITS-MSI 5767208 Edge enp11s0f0-39

kernel.percpu.interrupts.line169
Help:
ITS-MSI 5767207 Edge enp11s0f0-38

kernel.percpu.interrupts.line168
Help:
ITS-MSI 5767206 Edge enp11s0f0-37

kernel.percpu.interrupts.line167
Help:
ITS-MSI 5767205 Edge enp11s0f0-36

kernel.percpu.interrupts.line166
Help:
ITS-MSI 5767204 Edge enp11s0f0-35

kernel.percpu.interrupts.line165
Help:
ITS-MSI 5767203 Edge enp11s0f0-34

kernel.percpu.interrupts.line164
Help:
ITS-MSI 5767202 Edge enp11s0f0-33

kernel.percpu.interrupts.line163
Help:
ITS-MSI 5767201 Edge enp11s0f0-32

kernel.percpu.interrupts.line162
Help:
ITS-MSI 5767200 Edge enp11s0f0-31

kernel.percpu.interrupts.line161
Help:
ITS-MSI 5767199 Edge enp11s0f0-30

kernel.percpu.interrupts.line160
Help:
ITS-MSI 5767198 Edge enp11s0f0-29

kernel.percpu.interrupts.line159
Help:
ITS-MSI 5767197 Edge enp11s0f0-28

kernel.percpu.interrupts.line158
Help:
ITS-MSI 5767196 Edge enp11s0f0-27

kernel.percpu.interrupts.line157
Help:
ITS-MSI 5767195 Edge enp11s0f0-26

kernel.percpu.interrupts.line156
Help:
ITS-MSI 5767194 Edge enp11s0f0-25

kernel.percpu.interrupts.line155
Help:
ITS-MSI 5767193 Edge enp11s0f0-24

kernel.percpu.interrupts.line154
Help:
ITS-MSI 5767192 Edge enp11s0f0-23

kernel.percpu.interrupts.line153
Help:
ITS-MSI 5767191 Edge enp11s0f0-22

kernel.percpu.interrupts.line152
Help:
ITS-MSI 5767190 Edge enp11s0f0-21

kernel.percpu.interrupts.line151
Help:
ITS-MSI 5767189 Edge enp11s0f0-20

kernel.percpu.interrupts.line150
Help:
ITS-MSI 5767188 Edge enp11s0f0-19

kernel.percpu.interrupts.line149
Help:
ITS-MSI 5767187 Edge enp11s0f0-18

kernel.percpu.interrupts.line148
Help:
ITS-MSI 5767186 Edge enp11s0f0-17

kernel.percpu.interrupts.line147
Help:
ITS-MSI 5767185 Edge enp11s0f0-16

kernel.percpu.interrupts.line146
Help:
ITS-MSI 5767184 Edge enp11s0f0-15

kernel.percpu.interrupts.line145
Help:
ITS-MSI 5767183 Edge enp11s0f0-14

kernel.percpu.interrupts.line144
Help:
ITS-MSI 5767182 Edge enp11s0f0-13

kernel.percpu.interrupts.line143
Help:
ITS-MSI 5767181 Edge enp11s0f0-12

kernel.percpu.interrupts.line142
Help:
ITS-MSI 5767180 Edge enp11s0f0-11

kernel.percpu.interrupts.line141
Help:
ITS-MSI 5767179 Edge enp11s0f0-10

kernel.percpu.interrupts.line140
Help:
ITS-MSI 5767178 Edge enp11s0f0-9

kernel.percpu.interrupts.line139
Help:
ITS-MSI 5767177 Edge enp11s0f0-8

kernel.percpu.interrupts.line138
Help:
ITS-MSI 5767176 Edge enp11s0f0-7

kernel.percpu.interrupts.line137
Help:
ITS-MSI 5767175 Edge enp11s0f0-6

kernel.percpu.interrupts.line136
Help:
ITS-MSI 5767174 Edge enp11s0f0-5

kernel.percpu.interrupts.line135
Help:
ITS-MSI 5767173 Edge enp11s0f0-4

kernel.percpu.interrupts.line134
Help:
ITS-MSI 5767172 Edge enp11s0f0-3

kernel.percpu.interrupts.line133
Help:
ITS-MSI 5767171 Edge enp11s0f0-2

kernel.percpu.interrupts.line132
Help:
ITS-MSI 5767170 Edge enp11s0f0-1

kernel.percpu.interrupts.line131
Help:
ITS-MSI 5767169 Edge enp11s0f0-0

kernel.percpu.interrupts.line130
Help:
ITS-MSI 5767168 Edge mlx5_async@pci:0000:0b:00.0

kernel.percpu.interrupts.line129
Help:
ITS-MSI 2621503 Edge ib0-62

kernel.percpu.interrupts.line128
Help:
ITS-MSI 2621502 Edge ib0-61

kernel.percpu.interrupts.line127
Help:
ITS-MSI 2621501 Edge ib0-60

kernel.percpu.interrupts.line126
Help:
ITS-MSI 2621500 Edge ib0-59

kernel.percpu.interrupts.line125
Help:
ITS-MSI 2621499 Edge ib0-58

kernel.percpu.interrupts.line124
Help:
ITS-MSI 2621498 Edge ib0-57

kernel.percpu.interrupts.line123
Help:
ITS-MSI 2621497 Edge ib0-56

kernel.percpu.interrupts.line122
Help:
ITS-MSI 2621496 Edge ib0-55

kernel.percpu.interrupts.line121
Help:
ITS-MSI 2621495 Edge ib0-54

kernel.percpu.interrupts.line120
Help:
ITS-MSI 2621494 Edge ib0-53

kernel.percpu.interrupts.line119
Help:
ITS-MSI 2621493 Edge ib0-52

kernel.percpu.interrupts.line118
Help:
ITS-MSI 2621492 Edge ib0-51

kernel.percpu.interrupts.line117
Help:
ITS-MSI 2621491 Edge ib0-50

kernel.percpu.interrupts.line116
Help:
ITS-MSI 2621490 Edge ib0-49

kernel.percpu.interrupts.line115
Help:
ITS-MSI 2621489 Edge ib0-48

kernel.percpu.interrupts.line114
Help:
ITS-MSI 2621488 Edge ib0-47

kernel.percpu.interrupts.line113
Help:
ITS-MSI 2621487 Edge ib0-46

kernel.percpu.interrupts.line112
Help:
ITS-MSI 2621486 Edge ib0-45

kernel.percpu.interrupts.line111
Help:
ITS-MSI 2621485 Edge ib0-44

kernel.percpu.interrupts.line110
Help:
ITS-MSI 2621484 Edge ib0-43

kernel.percpu.interrupts.line109
Help:
ITS-MSI 2621483 Edge ib0-42

kernel.percpu.interrupts.line108
Help:
ITS-MSI 2621482 Edge ib0-41

kernel.percpu.interrupts.line107
Help:
ITS-MSI 2621481 Edge ib0-40

kernel.percpu.interrupts.line106
Help:
ITS-MSI 2621480 Edge ib0-39

kernel.percpu.interrupts.line105
Help:
ITS-MSI 2621479 Edge ib0-38

kernel.percpu.interrupts.line104
Help:
ITS-MSI 2621478 Edge ib0-37

kernel.percpu.interrupts.line103
Help:
ITS-MSI 2621477 Edge ib0-36

kernel.percpu.interrupts.line102
Help:
ITS-MSI 2621476 Edge ib0-35

kernel.percpu.interrupts.line101
Help:
ITS-MSI 2621475 Edge ib0-34

kernel.percpu.interrupts.line100
Help:
ITS-MSI 2621474 Edge ib0-33

kernel.percpu.interrupts.line99
Help:
ITS-MSI 2621473 Edge ib0-32

kernel.percpu.interrupts.line98
Help:
ITS-MSI 2621472 Edge ib0-31

kernel.percpu.interrupts.line97
Help:
ITS-MSI 2621471 Edge ib0-30

kernel.percpu.interrupts.line96
Help:
ITS-MSI 2621470 Edge ib0-29

kernel.percpu.interrupts.line95
Help:
ITS-MSI 2621469 Edge ib0-28

kernel.percpu.interrupts.line94
Help:
ITS-MSI 2621468 Edge ib0-27

kernel.percpu.interrupts.line93
Help:
ITS-MSI 2621467 Edge ib0-26

kernel.percpu.interrupts.line92
Help:
ITS-MSI 2621466 Edge ib0-25

kernel.percpu.interrupts.line91
Help:
ITS-MSI 2621465 Edge ib0-24

kernel.percpu.interrupts.line90
Help:
ITS-MSI 2621464 Edge ib0-23

kernel.percpu.interrupts.line89
Help:
ITS-MSI 2621463 Edge ib0-22

kernel.percpu.interrupts.line88
Help:
ITS-MSI 2621462 Edge ib0-21

kernel.percpu.interrupts.line87
Help:
ITS-MSI 2621461 Edge ib0-20

kernel.percpu.interrupts.line86
Help:
ITS-MSI 2621460 Edge ib0-19

kernel.percpu.interrupts.line85
Help:
ITS-MSI 2621459 Edge ib0-18

kernel.percpu.interrupts.line84
Help:
ITS-MSI 2621458 Edge ib0-17

kernel.percpu.interrupts.line83
Help:
ITS-MSI 2621457 Edge ib0-16

kernel.percpu.interrupts.line82
Help:
ITS-MSI 2621456 Edge ib0-15

kernel.percpu.interrupts.line81
Help:
ITS-MSI 2621455 Edge ib0-14

kernel.percpu.interrupts.line80
Help:
ITS-MSI 2621454 Edge ib0-13

kernel.percpu.interrupts.line79
Help:
ITS-MSI 2621453 Edge ib0-12

kernel.percpu.interrupts.line78
Help:
ITS-MSI 2621452 Edge ib0-11

kernel.percpu.interrupts.line77
Help:
ITS-MSI 2621451 Edge ib0-10

kernel.percpu.interrupts.line76
Help:
ITS-MSI 2621450 Edge ib0-9

kernel.percpu.interrupts.line75
Help:
ITS-MSI 2621449 Edge ib0-8

kernel.percpu.interrupts.line74
Help:
ITS-MSI 2621448 Edge ib0-7

kernel.percpu.interrupts.line73
Help:
ITS-MSI 2621447 Edge ib0-6

kernel.percpu.interrupts.line72
Help:
ITS-MSI 2621446 Edge ib0-5

kernel.percpu.interrupts.line71
Help:
ITS-MSI 2621445 Edge ib0-4

kernel.percpu.interrupts.line70
Help:
ITS-MSI 2621444 Edge ib0-3

kernel.percpu.interrupts.line69
Help:
ITS-MSI 2621443 Edge ib0-2

kernel.percpu.interrupts.line68
Help:
ITS-MSI 2621442 Edge ib0-1

kernel.percpu.interrupts.line67
Help:
ITS-MSI 2621441 Edge ib0-0

kernel.percpu.interrupts.line66
Help:
ITS-MSI 2621440 Edge mlx5_async@pci:0000:05:00.0

kernel.percpu.interrupts.line65
Help:
ITS-MSI 67356679 Edge xhci_hcd

kernel.percpu.interrupts.line64
Help:
ITS-MSI 67356678 Edge xhci_hcd

kernel.percpu.interrupts.line63
Help:
ITS-MSI 67356677 Edge xhci_hcd

kernel.percpu.interrupts.line62
Help:
ITS-MSI 67356676 Edge xhci_hcd

kernel.percpu.interrupts.line61
Help:
ITS-MSI 67356675 Edge xhci_hcd

kernel.percpu.interrupts.line60
Help:
ITS-MSI 67356674 Edge xhci_hcd

kernel.percpu.interrupts.line59
Help:
ITS-MSI 67356673 Edge xhci_hcd

kernel.percpu.interrupts.line58
Help:
ITS-MSI 67356672 Edge xhci_hcd

kernel.percpu.interrupts.line57
Help:
ITS-MSI 67354631 Edge xhci_hcd

kernel.percpu.interrupts.line56
Help:
ITS-MSI 67354630 Edge xhci_hcd

kernel.percpu.interrupts.line55
Help:
ITS-MSI 67354629 Edge xhci_hcd

kernel.percpu.interrupts.line54
Help:
ITS-MSI 67354628 Edge xhci_hcd

kernel.percpu.interrupts.line53
Help:
ITS-MSI 67354627 Edge xhci_hcd

kernel.percpu.interrupts.line52
Help:
ITS-MSI 67354626 Edge xhci_hcd

kernel.percpu.interrupts.line51
Help:
ITS-MSI 67354625 Edge xhci_hcd

kernel.percpu.interrupts.line50
Help:
ITS-MSI 67354624 Edge xhci_hcd

kernel.percpu.interrupts.line49
Help:
ITS-MSI 247815 Edge xhci_hcd

kernel.percpu.interrupts.line48
Help:
ITS-MSI 247814 Edge xhci_hcd

kernel.percpu.interrupts.line47
Help:
ITS-MSI 247813 Edge xhci_hcd

kernel.percpu.interrupts.line46
Help:
ITS-MSI 247812 Edge xhci_hcd

kernel.percpu.interrupts.line45
Help:
ITS-MSI 247811 Edge xhci_hcd

kernel.percpu.interrupts.line44
Help:
ITS-MSI 247810 Edge xhci_hcd

kernel.percpu.interrupts.line43
Help:
ITS-MSI 247809 Edge xhci_hcd

kernel.percpu.interrupts.line42
Help:
ITS-MSI 247808 Edge xhci_hcd

kernel.percpu.interrupts.line41
Help:
ITS-MSI 245767 Edge xhci_hcd

kernel.percpu.interrupts.line40
Help:
ITS-MSI 245766 Edge xhci_hcd

kernel.percpu.interrupts.line39
Help:
ITS-MSI 245765 Edge xhci_hcd

kernel.percpu.interrupts.line38
Help:
ITS-MSI 245764 Edge xhci_hcd

kernel.percpu.interrupts.line37
Help:
ITS-MSI 245763 Edge xhci_hcd

kernel.percpu.interrupts.line36
Help:
ITS-MSI 245762 Edge xhci_hcd

kernel.percpu.interrupts.line35
Help:
ITS-MSI 245761 Edge xhci_hcd

kernel.percpu.interrupts.line34
Help:
ITS-MSI 245760 Edge xhci_hcd

kernel.percpu.interrupts.line33
Help:
ITS-MSI 67373056 Edge ahci[0000:80:10.1]

kernel.percpu.interrupts.line32
Help:
ITS-MSI 67371008 Edge ahci[0000:80:10.0]

kernel.percpu.interrupts.line31
Help:
ITS-MSI 264192 Edge ahci[0000:00:10.1]

kernel.percpu.interrupts.line30
Help:
ITS-MSI 262144 Edge ahci[0000:00:10.0]

kernel.percpu.interrupts.line21
Help:
GICv3 23 Level arm-pmu

kernel.percpu.interrupts.line20
Help:
GICv3 218 Edge smbus_alert

kernel.percpu.interrupts.line19
Help:
GICv3 213 Level CAV9007:06

kernel.percpu.interrupts.line16
Help:
GICv3 81 Level uart-pl011

kernel.percpu.interrupts.line13
Help:
GICv3 93 Edge ACPI:Ged

kernel.percpu.interrupts.line12
Help:
GICv3 89 Edge ACPI:Ged

kernel.percpu.interrupts.line10
Help:
GICv3 236 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line9
Help:
GICv3 235 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line8
Help:
GICv3 234 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line7
Help:
GICv3 108 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line6
Help:
GICv3 107 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line5
Help:
GICv3 106 Edge arm-smmu-v3-combined-irq

kernel.percpu.interrupts.line4
Help:
GICv3 26 Level arch_timer

kernel.percpu.interrupts.line3
Help:
GICv3 27 Level kvm guest vtimer

kernel.percpu.interrupts.line2
Help:
GICv3 30 Level kvm guest ptimer

kernel.percpu.interrupts.line1
Help:
GICv3 25 Level vgic

kernel.percpu.softirqs.RCU
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.HRTIMER
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.SCHED
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.TASKLET
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.IRQ_POLL
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.BLOCK
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.NET_RX
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.NET_TX
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.TIMER
Full Help: Error: One-line or help text is not available

kernel.percpu.softirqs.HI
Full Help: Error: One-line or help text is not available

kernel.percpu.intr
Help:
Aggregate count of each CPUs interrupt processing count, calculated
as the sum of all interrupt types in /proc/interrupts for each CPU.

kernel.percpu.cpu.user
Help:
percpu user CPU time metric from /proc/stat, including guest CPU time

kernel.percpu.cpu.nice
Help:
percpu nice user CPU time metric from /proc/stat, including guest CPU time

kernel.percpu.cpu.sys
Help:
percpu sys CPU time metric from /proc/stat

kernel.percpu.cpu.idle
Help:
percpu idle CPU time metric from /proc/stat

kernel.percpu.cpu.intr
Help:
Total time spent processing interrupts on each CPU (this includes
both soft and hard interrupt processing time).

kernel.percpu.cpu.steal
Help:
Per-CPU time when the CPU had a runnable process, but the hypervisor
(virtualisation layer) chose to run something else instead.

kernel.percpu.cpu.guest
Help:
Per-CPU time spent running (virtual) guest operating systems.

kernel.percpu.cpu.vuser
Help:
percpu user CPU time metric from /proc/stat, excluding guest CPU time

kernel.percpu.cpu.guest_nice
Help:
Per-CPU nice time spent running (virtual) guest operating systems.

kernel.percpu.cpu.vnice
Help:
percpu nice user CPU time metric from /proc/stat, excluding guest CPU time

kernel.percpu.cpu.wait.total
Help:
Per-CPU I/O wait CPU time - time spent with outstanding I/O requests.

kernel.percpu.cpu.irq.soft
Help:
Per-CPU soft interrupt CPU time (deferred interrupt handling code,
not run in the initial interrupt handler).

kernel.percpu.cpu.irq.hard
Help:
Per-CPU hard interrupt CPU time ("hard" interrupt handling code
is the code run directly on receipt of the initial hardware
interrupt, and does not include "soft" interrupt handling code
which is deferred until later).

kernel.pernode.cpu.user
Help:
total user CPU time from /proc/stat for each node, including guest CPU time

kernel.pernode.cpu.nice
Help:
total nice user CPU time from /proc/stat for each node, including guest time

kernel.pernode.cpu.sys
Help:
total sys CPU time from /proc/stat for each node

kernel.pernode.cpu.idle
Help:
total idle CPU time from /proc/stat for each node

kernel.pernode.cpu.intr
Help:
total interrupt CPU time from /proc/stat for each node

kernel.pernode.cpu.steal
Help:
total virtualisation CPU steal time for each node

kernel.pernode.cpu.guest
Help:
total virtual guest CPU time for each node

kernel.pernode.cpu.vuser
Help:
total user CPU time from /proc/stat for each node, excluding guest CPU time

kernel.pernode.cpu.guest_nice
Help:
total virtual nice guest CPU time for each node

kernel.pernode.cpu.vnice
Help:
total nice user CPU time from /proc/stat for each node, excluding guest time

kernel.pernode.cpu.wait.total
Help:
total wait CPU time from /proc/stat for each node

kernel.pernode.cpu.irq.soft
Help:
soft interrupt CPU time from /proc/stat for each node

kernel.pernode.cpu.irq.hard
Help:
hard interrupt CPU time from /proc/stat for each node

kernel.uname.release
Help:
Release level of the running kernel as reported via the release[]
value returned from uname(2) or uname -r.

See also pmda.uname.

kernel.uname.version
Help:
Version level of the running kernel as reported by the version[]
value returned from uname(2) or uname -v.  Usually a build number
followed by a build date.

See also pmda.uname.

kernel.uname.sysname
Help:
Name of the implementation of the running operating system as reported
by the sysname[] value returned from uname(2) or uname -s.  Usually
"Linux".

See also pmda.uname.

kernel.uname.machine
Help:
Name of the hardware type the system is running on as reported by the machine[]
value returned from uname(2) or uname -m, e.g. "i686".

See also pmda.uname.

kernel.uname.nodename
Help:
Name of this node on the network as reported by the nodename[]
value returned from uname(2) or uname -n.  Usually a synonym for
the host name.

See also pmda.uname.

kernel.uname.distro
Help:
The Linux distribution name, as determined by a number of heuristics.
For example:
+ on Fedora, the contents of /etc/fedora-release
+ on RedHat, the contents of /etc/redhat-release

mem.physmem
Help:
The value of this metric corresponds to the "MemTotal" field
reported by /proc/meminfo. Note that this does not necessarily
correspond to actual installed physical memory - there may
be areas of the physical address space mapped as ROM in
various peripheral devices and the bios may be mirroring
certain ROMs in RAM.

mem.freemem
Help:
free system memory metric from /proc/meminfo

mem.util.used
Help:
Used memory is the difference between mem.physmem and mem.freemem.

mem.util.free
Help:
Alias for mem.freemem.

mem.util.shared
Help:
Shared memory metric. Currently always zero on Linux 2.4 kernels
and has been removed from 2.6 kernels.

mem.util.bufmem
Help:
Memory allocated for buffer_heads.

mem.util.cached
Help:
Memory used by the page cache, including buffered file data.
This is in-memory cache for files read from the disk (the pagecache)
but doesn't include SwapCached.

mem.util.other
Help:
Memory that is not free (i.e. has been referenced) and is not cached.
mem.physmem - mem.util.free - mem.util.cached - mem.util.buffers

mem.util.swapCached
Help:
Memory that once was swapped out, is swapped back in but still also
is in the swapfile (if memory is needed it doesn't need to be swapped
out AGAIN because it is already in the swapfile. This saves I/O)

mem.util.active
Help:
Memory that has been used more recently and usually not reclaimed unless
absolutely necessary.

mem.util.inactive
Help:
Memory which has been less recently used.  It is more eligible to be
reclaimed for other purposes

mem.util.highTotal
Help:
This is apparently an i386 specific metric, and seems to be always zero
on ia64 architecture (and possibly others). On i386 arch (at least),
highmem is all memory above ~860MB of physical memory. Highmem areas
are for use by userspace programs, or for the pagecache. The kernel
must use tricks to access this memory, making it slower to access
than lowmem.

mem.util.highFree
Help:
See mem.util.highTotal. Not used on ia64 arch (and possibly others).

mem.util.lowTotal
Help:
Lowmem is memory which can be used for everything that highmem can be
used for, but it is also availble for the kernel's use for its own
data structures. Among many other things, it is where everything
from the Slab is allocated.  Bad things happen when you're out of lowmem.
(this may only be true on i386 architectures).

mem.util.lowFree
Help:
See mem.util.lowTotal

mem.util.swapTotal
Help:
total amount of swap space available

mem.util.swapFree
Help:
Memory which has been evicted from RAM, and is temporarily on the disk

mem.util.dirty
Help:
Memory which is waiting to get written back to the disk

mem.util.writeback
Help:
Memory which is actively being written back to the disk

mem.util.mapped
Help:
files which have been mmaped, such as libraries

mem.util.slab
Help:
in-kernel data structures cache

mem.util.committed_AS
Help:
An estimate of how much RAM you would need to make a 99.99% guarantee
that there never is OOM (out of memory) for this workload. Normally
the kernel will overcommit memory. That means, say you do a 1GB malloc,
nothing happens, really. Only when you start USING that malloc memory
you will get real memory on demand, and just as much as you use.

mem.util.pageTables
Help:
Kbytes in kernel page tables, from /proc/meminfo

mem.util.reverseMaps
Help:
Kbytes in reverse mapped pages, from /proc/meminfo

mem.util.cache_clean
Help:
Kbytes cached and not dirty or writeback, derived from /proc/meminfo

mem.util.anonpages
Help:
Kbytes in user pages not backed by files, from /proc/meminfo

mem.util.commitLimit
Help:
The static total, in Kbytes, available for commitment to address 
spaces. Thus, mem.util.committed_AS may range up to this total. Normally 
the kernel overcommits memory, so this value may exceed mem.physmem

mem.util.bounce
Help:
Kbytes in bounce buffers, from /proc/meminfo

mem.util.NFS_Unstable
Help:
Kbytes in NFS unstable memory, from /proc/meminfo

mem.util.slabReclaimable
Help:
Kbytes in reclaimable slab pages, from /proc/meminfo

mem.util.slabUnreclaimable
Help:
Kbytes in unreclaimable slab pages, from /proc/meminfo

mem.util.active_anon
Help:
anonymous Active list LRU memory

mem.util.inactive_anon
Help:
anonymous Inactive list LRU memory

mem.util.active_file
Help:
file-backed Active list LRU memory

mem.util.inactive_file
Help:
file-backed Inactive list LRU memory

mem.util.unevictable
Help:
kbytes of memory that is unevictable

mem.util.mlocked
Help:
kbytes of memory that is pinned via mlock()

mem.util.shmem
Help:
kbytes of shmem

mem.util.kernelStack
Help:
kbytes of memory used for kernel stacks

mem.util.hugepagesTotal
Help:
a count of total hugepages

mem.util.hugepagesFree
Help:
a count of free hugepages

mem.util.hugepagesRsvd
Help:
a count of reserved hugepages

mem.util.hugepagesSurp
Help:
a count of surplus hugepages

mem.util.directMap4k
Help:
amount of memory that is directly mapped in 4kB pages

mem.util.directMap2M
Help:
amount of memory that is directly mapped in 2MB pages

mem.util.vmallocTotal
Help:
amount of kernel memory allocated via vmalloc

mem.util.vmallocUsed
Help:
amount of used vmalloc memory

mem.util.vmallocChunk
Help:
amount of vmalloc chunk memory

mem.util.mmap_copy
Help:
amount of mmap_copy space (non-MMU kernels only)

mem.util.quicklists
Help:
amount of memory in the per-CPU quicklists

mem.util.corrupthardware
Help:
amount of memory in hardware corrupted pages

mem.util.anonhugepages
Help:
amount of memory in anonymous huge pages

mem.util.directMap1G
Help:
amount of memory that is directly mapped in 1GB pages

mem.util.available
Help:
The amount of memory that is available for a new workload,
without pushing the system into swap. Estimated from MemFree,
Active(file), Inactive(file), and SReclaimable, as well as the "low"
watermarks from /proc/zoneinfo.

mem.util.hugepagesTotalBytes
Help:
amount of memory in total hugepages

mem.util.hugepagesFreeBytes
Help:
amount of memory in free hugepages

mem.util.hugepagesRsvdBytes
Help:
amount of memory in reserved hugepages

mem.util.hugepagesSurpBytes
Help:

User memory (Kbytes) in pages not backed by files, e.g. from malloc()

mem.numa.max_bandwidth
Help:
Maximum memory bandwidth supported on each numa node. It makes use of a
bandwith.conf file which has the bandwidth information for each node :
node_num:bandwidth
The node_num must match with any node in sysfs/devices/system/node directory.
And, the bandwidth is expressed in terms of MBps. This config file should be
filled up manually after running some bandwidth saturation benchmark tools.

mem.numa.util.total
Help:
per-node total memory

mem.numa.util.free
Help:
per-node free memory

mem.numa.util.used
Help:
per-node used memory

mem.numa.util.active
Help:
per-node Active list LRU memory

mem.numa.util.inactive
Help:
per-node Inactive list LRU memory

mem.numa.util.active_anon
Help:
per-node anonymous Active list LRU memory

mem.numa.util.inactive_anon
Help:
per-node anonymous Inactive list LRU memory

mem.numa.util.active_file
Help:
per-node file-backed Active list LRU memory

mem.numa.util.inactive_file
Help:
per-node file-backed Inactive list LRU memory

mem.numa.util.highTotal
Help:
per-node highmem total

mem.numa.util.highFree
Help:
per-node highmem free

mem.numa.util.lowTotal
Help:
per-node lowmem total

mem.numa.util.lowFree
Help:
per-node lowmem free

mem.numa.util.unevictable
Help:
per-node Unevictable memory

mem.numa.util.mlocked
Help:
per-node count of Mlocked memory

mem.numa.util.dirty
Help:
per-node dirty memory

mem.numa.util.writeback
Help:
per-node count of memory locked for writeback to stable storage

mem.numa.util.filePages
Help:
per-node count of memory backed by files

mem.numa.util.mapped
Help:
per-node mapped memory

mem.numa.util.anonpages
Help:
per-node anonymous memory

mem.numa.util.shmem
Help:
per-node amount of shared memory

mem.numa.util.kernelStack
Help:
per-node memory used as kernel stacks

mem.numa.util.pageTables
Help:
per-node memory used for pagetables

mem.numa.util.NFS_Unstable
Help:
per-node memory holding NFS data that needs writeback

mem.numa.util.bounce
Help:
per-node memory used for bounce buffers

mem.numa.util.writebackTmp
Help:
per-node temporary memory used for writeback

mem.numa.util.slab
Help:
per-node memory used for slab objects

mem.numa.util.slabReclaimable
Help:
per-node memory used for slab objects that can be reclaimed

mem.numa.util.slabUnreclaimable
Help:
per-node memory used for slab objects that is unreclaimable

mem.numa.util.hugepagesTotal
Help:
per-node total count of hugepages

mem.numa.util.hugepagesFree
Help:
per-node count of free hugepages

mem.numa.util.hugepagesSurp
Help:
per-node count of surplus hugepages

mem.numa.util.hugepagesTotalBytes
Help:
per-node total amount of hugepages memory

mem.numa.util.hugepagesFreeBytes
Help:
per-node amount of free hugepages memory

mem.numa.util.hugepagesSurpBytes
Help:
per-node amount of surplus hugepages memory

mem.numa.alloc.hit
Help:
per-node count of times a task wanted alloc on local node and succeeded

mem.numa.alloc.miss
Help:
per-node count of times a task wanted alloc on local node but got another node

mem.numa.alloc.foreign
Help:
count of times a task on another node alloced on that node, but got this node

mem.numa.alloc.interleave_hit
Help:
count of times interleaving wanted to allocate on this node and succeeded

mem.numa.alloc.local_node
Help:
count of times a process ran on this node and got memory on this node

mem.numa.alloc.other_node
Help:
count of times a process ran on this node and got memory from another node

mem.vmstat.allocstall
Help:
Count of direct reclaim calls since boot, from /proc/vmstat

mem.vmstat.balloon_deflate
Help:
number of virt guest balloon page deflations

mem.vmstat.balloon_inflate
Help:
count of virt guest balloon page inflations

mem.vmstat.balloon_migrate
Help:
number of virt guest balloon page migrations

mem.vmstat.compact_blocks_moved
Help:
count of compact blocks moved

mem.vmstat.compact_daemon_wake
Help:
number of times the memory compaction daemon was woken

mem.vmstat.compact_fail
Help:
count of unsuccessful compactions for high order allocations

mem.vmstat.compact_free_scanned
Help:
count of pages scanned for freeing by compaction daemon

mem.vmstat.compact_migrate_scanned
Help:
count of pages scanned for migration by compaction daemon

mem.vmstat.compact_pagemigrate_failed
Help:
count of pages unsuccessfully compacted

mem.vmstat.compact_pages_moved
Help:
count of pages successfully moved for compaction

mem.vmstat.compact_stall
Help:
count of failures to even start compacting

mem.vmstat.compact_success
Help:
count of successful compactions for high order allocations

mem.vmstat.drop_pagecache
Help:
count of calls to drop page cache pages

mem.vmstat.drop_slab
Help:
count of calls to drop slab cache pages

mem.vmstat.htlb_buddy_alloc_fail
Help:
Count of huge TLB page buddy allocation failures, from /proc/vmstat

mem.vmstat.htlb_buddy_alloc_success
Help:
Count of huge TLB page buddy allocation successes, from /proc/vmstat

mem.vmstat.kswapd_inodesteal
Help:
Count of pages reclaimed via kswapd inode freeing since boot, from
/proc/vmstat

mem.vmstat.kswapd_low_wmark_hit_quickly
Help:
Count of times kswapd reached low watermark quickly, from /proc/vmstat

mem.vmstat.kswapd_high_wmark_hit_quickly
Help:
Count of times kswapd reached high watermark quickly, from /proc/vmstat

mem.vmstat.kswapd_skip_congestion_wait
Help:
Count of times kswapd skipped waiting due to device congestion as a
result of being under the low watermark, from /proc/vmstat

mem.vmstat.kswapd_steal
Help:
Count of pages reclaimed by kswapd since boot, from /proc/vmstat

mem.vmstat.nr_active_anon
Help:
number of active anonymous memory pages

mem.vmstat.nr_active_file
Help:
number of active file memory memory pages

mem.vmstat.nr_anon_pages
Help:
Instantaneous number of anonymous mapped pagecache pages, from /proc/vmstat
See also mem.vmstat.mapped for other mapped pages.

mem.vmstat.nr_anon_transparent_hugepages
Help:
Instantaneous number of anonymous transparent huge pages, from /proc/vmstat

mem.vmstat.nr_bounce
Help:
Instantaneous number of bounce buffer pages, from /proc/vmstat

mem.vmstat.nr_dirtied
Help:
Count of pages entering dirty state, from /proc/vmstat

mem.vmstat.nr_dirty
Help:
Instantaneous number of pages in dirty state, from /proc/vmstat

mem.vmstat.nr_dirty_background_threshold
Help:
background writeback threshold

mem.vmstat.nr_dirty_threshold
Help:
dirty throttling threshold

mem.vmstat.nr_free_cma
Help:
count of free Contiguous Memory Allocator pages

mem.vmstat.nr_free_pages
Help:
number of free pages

mem.vmstat.nr_inactive_anon
Help:
number of inactive anonymous memory pages

mem.vmstat.nr_inactive_file
Help:
number of inactive file memory pages

mem.vmstat.nr_isolated_anon
Help:
number of isolated anonymous memory pages

mem.vmstat.nr_isolated_file
Help:
number of isolated file memory pages

mem.vmstat.nr_kernel_stack
Help:
number of pages of kernel stack

mem.vmstat.nr_mapped
Help:
Instantaneous number of mapped pagecache pages, from /proc/vmstat
See also mem.vmstat.nr_anon for anonymous mapped pages.

mem.vmstat.nr_mlock
Help:
number of pages under mlock

mem.vmstat.nr_pages_scanned
Help:
count of pages scanned during page reclaim

mem.vmstat.nr_page_table_pages
Help:
Instantaneous number of page table pages, from /proc/vmstat

mem.vmstat.nr_shmem
Help:
number of shared memory pages

mem.vmstat.nr_slab
Help:
Instantaneous number of slab pages, from /proc/vmstat
This counter was retired in 2.6.18 kernels, and is now the sum of
mem.vmstat.nr_slab_reclaimable and mem.vmstat.nr_slab_unreclaimable.

mem.vmstat.nr_slab_reclaimable
Help:
Instantaneous number of reclaimable slab pages, from /proc/vmstat.

mem.vmstat.nr_slab_unreclaimable
Help:
Instantaneous number of unreclaimable slab pages, from /proc/vmstat.

mem.vmstat.nr_unevictable
Help:
number of unevictable pages

mem.vmstat.nr_unstable
Help:
Instantaneous number of pages in unstable state, from /proc/vmstat

mem.vmstat.nr_vmscan_immediate_reclaim
Help:
prioritise for reclaim when writeback ends

mem.vmstat.nr_vmscan_write
Help:
Count of pages written from the LRU by the VM scanner, from /proc/vmstat.
The VM is supposed to minimise the number of pages which get written
from the LRU (for IO scheduling efficiency, and for high reclaim-success
rates).

mem.vmstat.nr_writeback
Help:
Instantaneous number of pages in writeback state, from /proc/vmstat

mem.vmstat.nr_writeback_temp
Help:
number of temporary writeback pages

mem.vmstat.nr_written
Help:
Count of pages written out, from /proc/vmstat

mem.vmstat.numa_foreign
Help:
count of foreign NUMA zone allocations

mem.vmstat.numa_hint_faults
Help:
count of page migrations from NUMA PTE fault hints

mem.vmstat.numa_hint_faults_local
Help:
count of NUMA PTE fault hints satisfied locally

mem.vmstat.numa_hit
Help:
count of successful allocations from preferred NUMA zone

mem.vmstat.numa_huge_pte_updates
Help:
count of NUMA huge page table entry updates

mem.vmstat.numa_interleave
Help:
count of interleaved NUMA allocations

mem.vmstat.numa_local
Help:
count of successful allocations from local NUMA zone

mem.vmstat.numa_miss
Help:
count of unsuccessful allocations from preferred NUMA zona

mem.vmstat.numa_other
Help:
count of unsuccessful allocations from local NUMA zone

mem.vmstat.numa_pages_migrated
Help:
count of NUMA page migrations

mem.vmstat.numa_pte_updates
Help:
count of NUMA page table entry updates

mem.vmstat.pageoutrun
Help:
Count of kswapd calls to page reclaim since boot, from /proc/vmstat

mem.vmstat.pgactivate
Help:
Count of pages moved from inactive to active since boot, from /proc/vmstat

mem.vmstat.pgalloc_dma
Help:
Count of dma mem page allocations since boot, from /proc/vmstat

mem.vmstat.pgalloc_dma32
Help:
Count of dma32 mem page allocations since boot, from /proc/vmstat

mem.vmstat.pgalloc_high
Help:
Count of high mem page allocations since boot, from /proc/vmstat

mem.vmstat.pgalloc_movable
Help:
Count of movable mem page allocations since boot, from /proc/vmstat

mem.vmstat.pgalloc_normal
Help:
Count of normal mem page allocations since boot, from /proc/vmstat

mem.vmstat.pgrefill_dma32
Help:
Count of dma32 mem pages inspected in refill_inactive_zone since boot,
from /proc/vmstat

mem.vmstat.pgrefill_movable
Help:
Count of movable mem pages inspected in refill_inactive_zone since boot,
from /proc/vmstat

mem.vmstat.pgdeactivate
Help:
Count of pages moved from active to inactive since boot, from /proc/vmstat

mem.vmstat.pgfault
Help:
Count of page major and minor fault operations since boot, from /proc/vmstat

mem.vmstat.pgfree
Help:
Count of page free operations since boot, from /proc/vmstat

mem.vmstat.pginodesteal
Help:
Count of pages reclaimed via inode freeing since boot, from /proc/vmstat

mem.vmstat.pglazyfreed
Help:
count of pages lazily freed

mem.vmstat.pgmajfault
Help:
Count of major page fault operations since boot, from /proc/vmstat

mem.vmstat.pgmigrate_fail
Help:
count of unsuccessful NUMA page migrations

mem.vmstat.pgmigrate_success
Help:
count of successful NUMA page migrations

mem.vmstat.pgpgin
Help:
Count of page in operations since boot, from /proc/vmstat

mem.vmstat.pgpgout
Help:
Count of page out operations since boot, from /proc/vmstat

mem.vmstat.pgrefill_dma
Help:
Count of dma mem pages inspected in refill_inactive_zone since boot,
from /proc/vmstat

mem.vmstat.pgrefill_high
Help:
Count of high mem pages inspected in refill_inactive_zone since boot,
from /proc/vmstat

mem.vmstat.pgrefill_normal
Help:
Count of normal mem pages inspected in refill_inactive_zone since boot,
from /proc/vmstat

mem.vmstat.pgrotated
Help:
Count of pages rotated to tail of the LRU since boot, from /proc/vmstat

mem.vmstat.pgscan_direct
Help:
Count of mem pages scanned directly since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgscan_direct_dma
Help:
Count of dma mem pages scanned since boot, from /proc/vmstat

mem.vmstat.pgscan_direct_dma32
Help:
Count of dma32 mem pages scanned since boot, from /proc/vmstat

mem.vmstat.pgscan_direct_high
Help:
Count of high mem pages scanned since boot, from /proc/vmstat

mem.vmstat.pgscan_direct_movable
Help:
Count of movable mem pages scanned since boot, from /proc/vmstat

mem.vmstat.pgscan_direct_normal
Help:
Count of normal mem pages scanned since boot, from /proc/vmstat

mem.vmstat.pgscan_direct_throttle
Help:
Count of throttled mem pages scanned directly since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgscan_kswapd
Help:
Count of mem pages scanned by kswapd since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgscan_kswapd_dma
Help:
Count of dma mem pages scanned by kswapd since boot, from /proc/vmstat

mem.vmstat.pgscan_kswapd_dma32
Help:
Count of dma32 mem pages scanned by kswapd since boot, from /proc/vmstat

mem.vmstat.pgscan_kswapd_high
Help:
Count of high mem pages scanned by kswapd since boot, from /proc/vmstat

mem.vmstat.pgscan_kswapd_movable
Help:
Count of movable mem pages scanned by kswapd since boot, from /proc/vmstat

mem.vmstat.pgscan_kswapd_normal
Help:
Count of normal mem pages scanned by kswapd since boot, from /proc/vmstat

mem.vmstat.pgsteal_dma
Help:
Count of dma mem pages reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_dma32
Help:
Count of dma32 mem pages reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_high
Help:
Count of high mem pages reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_movable
Help:
Count of movable mem pages reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_normal
Help:
Count of normal mem pages reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_kswapd
Help:
Count of mem pages reclaimed by kswapd since boot, from /proc/vmstat

mem.vmstat.pgsteal_kswapd_dma
Help:
Count of dma mem pages reclaimed by kswapd since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_kswapd_dma32
Help:
Count of dma32 mem pages reclaimed by kswapd since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_kswapd_normal
Help:
Count of normal mem pages reclaimed by kswapd since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_kswapd_movable
Help:
Count of movable mem pages reclaimed by kswapd since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_direct
Help:
Count of mem pages directly reclaimed since boot, from /proc/vmstat

mem.vmstat.pgsteal_direct_dma
Help:
Count of dma mem pages reclaimed since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_direct_dma32
Help:
Count of dma32 mem pages reclaimed since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_direct_normal
Help:
Count of normal mem pages reclaimed since boot, from /proc/vmstat
since Linux 3.4

mem.vmstat.pgsteal_direct_movable
Help:
Count of movable mem pages reclaimed since boot, from /proc/vmstat
since Linux 2.6.23

mem.vmstat.pswpin
Help:
Count of pages swapped in since boot, from /proc/vmstat

mem.vmstat.pswpout
Help:
Count of pages swapped out since boot, from /proc/vmstat

mem.vmstat.slabs_scanned
Help:
Count of slab pages scanned since boot, from /proc/vmstat

mem.vmstat.thp_collapse_alloc
Help:
transparent huge page collapse allocations

mem.vmstat.thp_collapse_alloc_failed
Help:
transparent huge page collapse failures

mem.vmstat.thp_deferred_split_page
Help:
count of huge page enqueues for splitting

mem.vmstat.thp_fault_alloc
Help:
transparent huge page fault allocations

mem.vmstat.thp_fault_fallback
Help:
transparent huge page fault fallbacks

mem.vmstat.thp_split
Help:
count of transparent huge page splits

mem.vmstat.thp_split_page
Help:
count of huge page splits into base pages

mem.vmstat.thp_split_page_failed
Help:
count of failures to split a huge page

mem.vmstat.thp_split_pmd
Help:
This can happen, for instance, when an application calls mprotect() or
munmap() on part of huge page. It doesn't split huge page, only the page
table entry.

mem.vmstat.thp_zero_page_alloc
Help:
count of transparent huge page zeroed page allocations

mem.vmstat.thp_zero_page_alloc_failed
Help:
count of transparent huge page zeroed page allocation failures

mem.vmstat.unevictable_pgs_cleared
Help:
count of unevictable pages cleared

mem.vmstat.unevictable_pgs_culled
Help:
count of unevictable pages culled

mem.vmstat.unevictable_pgs_mlocked
Help:
count of mlocked unevictable pages

mem.vmstat.unevictable_pgs_mlockfreed
Help:
count of unevictable pages mlock freed

mem.vmstat.unevictable_pgs_munlocked
Help:
count of unevictable pages munlocked

mem.vmstat.unevictable_pgs_rescued
Help:
count of unevictable pages rescued

mem.vmstat.unevictable_pgs_scanned
Help:
count of unevictable pages scanned

mem.vmstat.unevictable_pgs_stranded
Help:
count of unevictable pages stranded

mem.vmstat.workingset_activate
Help:
count of page activations to form the working set

mem.vmstat.workingset_nodereclaim
Help:
count of NUMA node working set page reclaims

mem.vmstat.workingset_refault
Help:
count of refaults of previously evicted pages

mem.vmstat.zone_reclaim_failed
Help:
number of zone reclaim failures

mem.vmstat.compact_isolated
Help:
count of page isolations for memory compaction

mem.vmstat.nr_shmem_hugepages
Help:
number of huge pages used for shared memory

mem.vmstat.nr_shmem_pmdmapped
Help:
number of huge page PMD mappings

mem.vmstat.nr_zone_inactive_anon
Help:
number of inactive anonymous memory pages in zones

mem.vmstat.nr_zone_active_anon
Help:
number of inactive file memory pages in zones

mem.vmstat.nr_zone_inactive_file
Help:
number of isolated anonymous memory pages in zones

mem.vmstat.nr_zone_active_file
Help:
number of isolated file memory pages in zones

mem.vmstat.nr_zone_unevictable
Help:
number of unevictable memory pages in zones

mem.vmstat.nr_zone_write_pending
Help:
count of dirty, writeback and unstable pages

mem.vmstat.nr_zspages
Help:
number of compressed pages

mem.vmstat.thp_file_alloc
Help:
count of times huge pages were allocated and put in page cache

mem.vmstat.thp_file_mapped
Help:
count of times huge pages were used for file mappings

mem.buddyinfo.pages
Help:
fragmented page count from /proc/buddyinfo

mem.buddyinfo.total
Help:
page fragmentation size from /proc/buddyinfo

mem.slabinfo.objects.active
Help:
number of active objects in each cache

mem.slabinfo.objects.total
Help:
total number of objects in each cache

mem.slabinfo.objects.size
Help:
size of individual objects of each cache

mem.slabinfo.slabs.active
Help:
number of active slabs comprising each cache

mem.slabinfo.slabs.total
Help:
total number of slabs comprising each cache

mem.slabinfo.slabs.pages_per_slab
Help:
number of pages in each slab

mem.slabinfo.slabs.objects_per_slab
Help:
number of objects in each slab

mem.slabinfo.slabs.total_size
Help:
total number of bytes allocated for active objects in each slab

mem.zoneinfo.free
Help:
free space in each zone for each NUMA node

mem.zoneinfo.min
Help:
min space in each zone for each NUMA node

mem.zoneinfo.low
Help:
low space in each zone for each NUMA node

mem.zoneinfo.high
Help:
high space in each zone for each NUMA node

mem.zoneinfo.scanned
Help:
scanned space in each zone for each NUMA node

mem.zoneinfo.spanned
Help:
spanned space in each zone for each NUMA node

mem.zoneinfo.present
Help:
present space in each zone for each NUMA node

mem.zoneinfo.managed
Help:
managed space in each zone for each NUMA node

mem.zoneinfo.nr_free_pages
Help:
number of free pages in each zone for each NUMA node.

mem.zoneinfo.nr_alloc_batch
Help:
Number of pages allocated to other zones due to insufficient memory, for
each zone for each NUMA node.

mem.zoneinfo.nr_inactive_anon
Help:
number of inactive anonymous memory pages in each zone for each NUMA node

mem.zoneinfo.nr_active_anon
Help:
number of active anonymous memory pages in each zone for each NUMA node

mem.zoneinfo.nr_inactive_file
Help:
number of inactive file memory pages in each zone for each NUMA node

mem.zoneinfo.nr_active_file
Help:
number of active file memory memory pages in each zone for each NUMA node

mem.zoneinfo.nr_unevictable
Help:
number of unevictable pages in each zone for each NUMA node

mem.zoneinfo.nr_mlock
Help:
number of pages under mlock in each zone for each NUMA node

mem.zoneinfo.nr_anon_pages
Help:
number of anonymous mapped pagecache pages in each zone for each NUMA node

mem.zoneinfo.nr_mapped
Help:
number of mapped pagecache pages in each zone for each NUMA node

mem.zoneinfo.nr_file_pages
Help:
number of file pagecache pages in each zone for each NUMA node

mem.zoneinfo.nr_dirty
Help:
number of pages dirty state in each zone for each NUMA node

mem.zoneinfo.nr_writeback
Help:
number of pages writeback state in each zone for each NUMA node

mem.zoneinfo.nr_slab_reclaimable
Help:
number of reclaimable slab pages in each zone for each NUMA node

mem.zoneinfo.nr_slab_unreclaimable
Help:
number of unreclaimable slab pages in each zone for each NUMA node

mem.zoneinfo.nr_page_table_pages
Help:
number of page table pages in each zone for each NUMA node

mem.zoneinfo.nr_kernel_stack
Help:
number of pages of kernel stack in each zone for each NUMA node

mem.zoneinfo.nr_unstable
Help:
number of pages unstable state in each zone for each NUMA node

mem.zoneinfo.nr_bounce
Help:
number of bounce buffer pages in each zone for each NUMA node

mem.zoneinfo.nr_vmscan_write
Help:
Count of pages written from the LRU by the VM scanner in each zone
for each NUMA node.The VM is supposed to minimise the number of
pages which get written from the LRU (for IO scheduling efficiency,
and for high reclaim-success rates).

mem.zoneinfo.nr_vmscan_immediate_reclaim
Help:
prioritise for reclaim when writeback ends in each zone for each NUMA node

mem.zoneinfo.nr_writeback_temp
Help:
number of temporary writeback pages in each zone for each NUMA node

mem.zoneinfo.nr_isolated_anon
Help:
number of isolated anonymous memory pages in each zone for each NUMA node

mem.zoneinfo.nr_isolated_file
Help:
number of isolated file memory pages in each zone for each NUMA node

mem.zoneinfo.nr_shmem
Help:
number of shared memory pages in each zone for each NUMA node

mem.zoneinfo.nr_dirtied
Help:
count of pages entering dirty state in each zone for each NUMA node

mem.zoneinfo.nr_written
Help:
count of pages written out in each zone for each NUMA node

mem.zoneinfo.numa_hit
Help:
Count of successful allocations from preferred NUMA zone in each zone
for each NUMA node.

mem.zoneinfo.numa_miss
Help:
Count of unsuccessful allocations from preferred NUMA zone in each zone
for each NUMA node.

mem.zoneinfo.numa_foreign
Help:
Count of foreign NUMA zone allocations in each zone for each NUMA node.

mem.zoneinfo.numa_interleave
Help:
count of interleaved NUMA allocations in each zone for each NUMA node

mem.zoneinfo.numa_local
Help:
Count of successful allocations from local NUMA zone in each zone for
each NUMA node.

mem.zoneinfo.numa_other
Help:
Count of unsuccessful allocations from local NUMA zone in each zone for
each NUMA node.

mem.zoneinfo.workingset_refault
Help:
count of refaults of previously evicted pages in each zone for each NUMA node

mem.zoneinfo.workingset_activate
Help:
count of page activations to form the working set in each zone for each NUMA node

mem.zoneinfo.workingset_nodereclaim
Help:
count of NUMA node working set page reclaims in each zone for each NUMA node

mem.zoneinfo.nr_anon_transparent_hugepages
Help:
number of anonymous transparent huge pages in each zone for each NUMA node

mem.zoneinfo.nr_free_cma
Help:
count of free Contiguous Memory Allocator pages in each zone for each NUMA node.

mem.zoneinfo.protection
Help:
protection space in each zone for each NUMA node

mem.ksm.full_scans
Help:
Number of times that KSM has scanned for duplicated content

mem.ksm.merge_across_nodes
Help:
Kernel allows merging across NUMA nodes

mem.ksm.pages_shared
Help:
The number of nodes in the stable tree

mem.ksm.pages_sharing
Help:
The number of virtual pages that are sharing a single page

mem.ksm.pages_to_scan
Help:
Number of pages to scan at a time

mem.ksm.pages_unshared
Help:
The number of nodes in the unstable tree

mem.ksm.pages_volatile
Help:
Number of pages that are candidate to be shared

mem.ksm.run_state
Help:
Whether the KSM daemon has run and/or is running

mem.ksm.sleep_time
Help:
Time ksmd should sleep between batches

swap.pagesin
Help:
pages read from swap devices due to demand for physical memory

swap.pagesout
Help:
pages written to swap devices due to demand for physical memory

swap.in
Help:
number of swap in operations

swap.out
Help:
number of swap out operations

swap.free
Help:
swap free metric from /proc/meminfo

swap.length
Help:
total swap available metric from /proc/meminfo

swap.used
Help:
swap used metric from /proc/meminfo

network.interface.collisions
Help:
colls column on the "Transmit" side of /proc/net/dev
(stats->collisions counter in rtnl_link_stats64).
Counter only valid for outgoing packets.

network.interface.mtu
Help:
maximum transmission unit on network interface

network.interface.speed
Help:
The linespeed on the network interface, as reported by the kernel,
scaled from Megabits/second to Megabytes/second.
See also network.interface.baudrate for the bytes/second value.

network.interface.baudrate
Help:
The linespeed on the network interface, as reported by the kernel,
scaled up from Megabits/second to bits/second and divided by 8 to convert
to bytes/second.
See also network.interface.speed for the Megabytes/second value.

network.interface.duplex
Help:
value one for half or two for full duplex interface

network.interface.up
Help:
boolean for whether interface is currently up or down

network.interface.running
Help:
boolean for whether interface has resources allocated

network.interface.wireless
Help:
boolean for whether interface is wireless

network.interface.type
Help:
sysfs interface name assignment type value

network.interface.inet_addr
Help:
string INET interface address (ifconfig style)

network.interface.ipv6_addr
Help:
string IPv6 interface address (ifconfig style)

network.interface.ipv6_scope
Help:
string IPv6 interface scope (ifconfig style)

network.interface.hw_addr
Help:
hardware address (from sysfs)

network.interface.in.bytes
Help:
bytes column on the "Receive" side of /proc/net/dev (stats->rx_bytes counter in
rtnl_link_stats64)

network.interface.in.packets
Help:
packets column on the "Receive" side of /proc/net/dev
(stats->rx_packets counter in rtnl_link_stats64)

network.interface.in.errors
Help:
errors column on the "Receive" side of /proc/net/dev
(stats->rx_errors counter in rtnl_link_stats64)

network.interface.in.drops
Help:
drop column on the "Receive" side of /proc/net/dev
(stats->{rx_dropped + rx_missed_errors} counters in rtnl_link_stats64)
rx_dropped are the dropped packets due to no space in linux buffers and rx_missed
are due to the receiver NIC missing a packet.
Not all NICS use the rx_missed_errors counter.

network.interface.in.fifo
Help:
fifo column on the "Receive" side of /proc/net/dev
(stats->rx_fifo_errors counter in rtnl_link_stats64)

network.interface.in.frame
Help:
frame column on the "Receive" side of /proc/net/dev
(stats->{rx_length_errors + rx_over_errors + rx_crc_errors + rx_frame_errors}
counters in rtnl_link_stats64)

network.interface.in.compressed
Help:
compressed column on the "Receive" side of /proc/net/dev
(stats->rx_compressed counter in rtnl_link_stats64).
Almost exclusively used for CSLIP or HDLC devices

network.interface.in.mcasts
Help:
multicast column on the "Receive" side of /proc/net/dev
(stats->multicast counter in rtnl_link_stats64)

network.interface.out.bytes
Help:
bytes column on the "Transmit" side of /proc/net/dev
(stats->tx_bytes counter in rtnl_link_stats64)

network.interface.out.packets
Help:
packets column on the "Transmit" side of /proc/net/dev
(stats->tx_packets counter in rtnl_link_stats64)

network.interface.out.errors
Help:
errors column on the "Transmit" side of /proc/net/dev
(stats->tx_errors counter in rtnl_link_stats64)

network.interface.out.drops
Help:
drop column on the "Transmit" side of /proc/net/dev
(stats->tx_dropped counter in rtnl_link_stats64)

network.interface.out.fifo
Help:
fifo column on the "Transmit" side of /proc/net/dev
(stats->tx_fifo_errors counter in rtnl_link_stats64)

network.interface.out.carrier
Help:
carrier column on the "Transmit" side of /proc/net/dev
(stats->{tx_carrier_errors + tx_aborted_errors + tx_window_errors +
tx_heartbeat_errors} counters in rtnl_link_stats64).

network.interface.out.compressed
Help:
compressed column on the "Transmit" side of /proc/net/dev
(stats->tx_compressed counter in rtnl_link_stats64).
Almost exclusively used for CSLIP or HDLC devices

network.interface.total.bytes
Help:
network total (in+out) bytes from /proc/net/dev per network interface

network.interface.total.packets
Help:
network total (in+out) packets from /proc/net/dev per network interface

network.interface.total.errors
Help:
network total (in+out) errors from /proc/net/dev per network interface

network.interface.total.drops
Help:
network total (in+out) drops from /proc/net/dev per network interface

network.interface.total.mcasts
Help:
Linux does not account for outgoing mcast packets per device, so this counter
is identical to the incoming mcast metric.

network.sockstat.total
Help:
total number of sockets used by the system.

network.sockstat.tcp.inuse
Help:
instantaneous number of tcp sockets currently in use

network.sockstat.tcp.orphan
Help:
instantaneous number of orphan sockets

network.sockstat.tcp.tw
Help:
instantaneous number of sockets wating close

network.sockstat.tcp.alloc
Help:
instantaneous number of allocated sockets

network.sockstat.tcp.mem
Help:
instantaneous number of used memory for tcp 

network.sockstat.udp.inuse
Help:
instantaneous number of udp sockets currently in use

network.sockstat.udp.mem
Help:
nstantaneous number of used memory for udp

network.sockstat.udplite.inuse
Help:
instantaneous number of udplite sockets currently in use

network.sockstat.raw.inuse
Help:
instantaneous number of raw sockets currently in use

network.sockstat.frag.inuse
Help:
instantaneous number of frag sockets currently in use

network.sockstat.frag.memory
Help:
nstantaneous number of used memory for frag

network.sockstat.tcp6.inuse
Help:
instantaneous number of tcp6 sockets currently in use

network.sockstat.udp6.inuse
Help:
instantaneous number of udp6 sockets currently in use

network.sockstat.udplite6.inuse
Help:
instantaneous number of udplite6 sockets currently in use

network.sockstat.raw6.inuse
Help:
instantaneous number of raw6 sockets currently in use

network.sockstat.frag6.inuse
Help:
instantaneous number of frag6 sockets currently in use

network.sockstat.frag6.memory
Help:
instantaneous number of used memory for frag6

network.ip.forwarding
Help:
count of ip forwarding

network.ip.defaultttl
Help:
count of ip defaultttl

network.ip.inreceives
Help:
count of ip inreceives

network.ip.inhdrerrors
Help:
count of ip inhdrerrors

network.ip.inaddrerrors
Help:
count of ip inaddrerrors

network.ip.forwdatagrams
Help:
count of ip forwdatagrams

network.ip.inunknownprotos
Help:
count of ip inunknownprotos

network.ip.indiscards
Help:
count of ip indiscards

network.ip.indelivers
Help:
count of ip indelivers

network.ip.outrequests
Help:
count of ip outrequests

network.ip.outdiscards
Help:
count of ip outdiscards

network.ip.outnoroutes
Help:
count of ip outnoroutes

network.ip.reasmtimeout
Help:
count of ip reasmtimeout

network.ip.reasmreqds
Help:
count of ip reasmreqds

network.ip.reasmoks
Help:
count of ip reasmoks

network.ip.reasmfails
Help:
count of ip reasmfails

network.ip.fragoks
Help:
count of ip fragoks

network.ip.fragfails
Help:
count of ip fragfails

network.ip.fragcreates
Help:
count of ip fragcreates

network.ip.innoroutes
Help:
Number of IP datagrams discarded due to no routes in forwarding path

network.ip.intruncatedpkts
Help:
Number of IP datagrams discarded due to frame not carrying enough data

network.ip.inmcastpkts
Help:
Number of received IP multicast datagrams

network.ip.outmcastpkts
Help:
Number of sent IP multicast datagrams

network.ip.inbcastpkts
Help:
Number of received IP broadcast datagrams

network.ip.outbcastpkts
Help:
Number of sent IP bradcast datagrams

network.ip.inoctets
Help:
Number of received octets

network.ip.outoctets
Help:
Number of sent octets

network.ip.inmcastoctets
Help:
Number of received IP multicast octets

network.ip.outmcastoctets
Help:
Number of sent IP multicast octets

network.ip.inbcastoctets
Help:
Number of received IP broadcast octets

network.ip.outbcastoctets
Help:
Number of sent IP broadcast octets

network.ip.csumerrors
Help:
Number of IP datagrams with checksum errors

network.ip.noectpkts
Help:
Number of packets received with NOECT

network.ip.ect1pkts
Help:
Number of packets received with ECT(1)

network.ip.ect0pkts
Help:
Number of packets received with ECT(0)

network.ip.cepkts
Help:
Number of packets received with Congestion Experimented

network.icmp.inmsgs
Help:
count of icmp inmsgs

network.icmp.inerrors
Help:
count of icmp inerrors

network.icmp.indestunreachs
Help:
count of icmp indestunreachs

network.icmp.intimeexcds
Help:
count of icmp intimeexcds

network.icmp.inparmprobs
Help:
count of icmp inparmprobs

network.icmp.insrcquenchs
Help:
count of icmp insrcquenchs

network.icmp.inredirects
Help:
count of icmp inredirects

network.icmp.inechos
Help:
count of icmp inechos

network.icmp.inechoreps
Help:
count of icmp inechoreps

network.icmp.intimestamps
Help:
count of icmp intimestamps

network.icmp.intimestampreps
Help:
count of icmp intimestampreps

network.icmp.inaddrmasks
Help:
count of icmp inaddrmasks

network.icmp.inaddrmaskreps
Help:
count of icmp inaddrmaskreps

network.icmp.outmsgs
Help:
count of icmp outmsgs

network.icmp.outerrors
Help:
count of icmp outerrors

network.icmp.outdestunreachs
Help:
count of icmp outdestunreachs

network.icmp.outtimeexcds
Help:
count of icmp outtimeexcds

network.icmp.outparmprobs
Help:
count of icmp outparmprobs

network.icmp.outsrcquenchs
Help:
count of icmp outsrcquenchs

network.icmp.outredirects
Help:
count of icmp outredirects

network.icmp.outechos
Help:
count of icmp outechos

network.icmp.outechoreps
Help:
count of icmp outechoreps

network.icmp.outtimestamps
Help:
count of icmp outtimestamps

network.icmp.outtimestampreps
Help:
count of icmp outtimestampreps

network.icmp.outaddrmasks
Help:
count of icmp outaddrmasks

network.icmp.outaddrmaskreps
Help:
count of icmp outaddrmaskreps

network.icmp.incsumerrors
Help:
count of icmp in checksum errors

network.icmpmsg.intype
Help:
count of icmp message types recvd

network.icmpmsg.outtype
Help:
count of icmp message types sent

network.tcp.rtoalgorithm
Help:
the restransmission timeout algorithm in use

network.tcp.rtomin
Help:
minimum retransmission timeout

network.tcp.rtomax
Help:
maximum retransmission timeout

network.tcp.maxconn
Help:
limit on tcp connections

network.tcp.activeopens
Help:
count of tcp activeopens

network.tcp.passiveopens
Help:
count of tcp passiveopens

network.tcp.attemptfails
Help:
count of tcp attemptfails

network.tcp.estabresets
Help:
count of tcp estabresets

network.tcp.currestab
Help:
current established tcp connections

network.tcp.insegs
Help:
count of tcp segments received

network.tcp.outsegs
Help:
count of tcp segments sent

network.tcp.retranssegs
Help:
count of tcp segments retransmitted

network.tcp.inerrs
Help:
count of tcp segments received in error

network.tcp.outrsts
Help:
count of tcp segments sent with RST flag

network.tcp.incsumerrors
Help:
count of tcp segments received with checksum errors

network.tcp.syncookiessent
Help:
Number of sent SYN cookies

network.tcp.syncookiesrecv
Help:
Number of received SYN cookies

network.tcp.syncookiesfailed
Help:
Number of failed SYN cookies

network.tcp.embryonicrsts
Help:
Number of resets received for embryonic SYN_RECV sockets

network.tcp.prunecalled
Help:
Number of packets pruned from receive queue because of socket buffer overrun

network.tcp.rcvpruned
Help:
Number of packets pruned from receive queue

network.tcp.ofopruned
Help:
Number of packets dropped from out-of-order queue because of socket buffer overrun

network.tcp.outofwindowicmps
Help:
Number of dropped out of window ICMPs

network.tcp.lockdroppedicmps
Help:
Number of dropped ICMP because socket was locked

network.tcp.arpfilter
Help:
Number of arp packets filtered

network.tcp.timewaited
Help:
Number of TCP sockets finished time wait in fast timer

network.tcp.timewaitrecycled
Help:
Number of time wait sockets recycled by time stamp

network.tcp.timewaitkilled
Help:
Number of TCP sockets finished time wait in slow timer

network.tcp.pawspassiverejected
Help:
Number of passive connections rejected because of timestamp

network.tcp.pawsactiverejected
Help:
Number of active connections rejected because of timestamp

network.tcp.pawsestabrejected
Help:
Number of packets rejects in established connections because of timestamp

network.tcp.delayedacks
Help:
Number of delayed acks sent

network.tcp.delayedacklocked
Help:
Number of delayed acks further delayed because of locked socket

network.tcp.delayedacklost
Help:
Number of times quick ack mode was activated times

network.tcp.listenoverflows
Help:
Number of times the listen queue of a socket overflowed

network.tcp.listendrops
Help:
Number of SYNs to LISTEN sockets dropped

network.tcp.prequeued
Help:
Number of packets directly queued to recvmsg prequeue

network.tcp.directcopyfrombacklog
Help:
Number of bytes directly in process context from backlog

network.tcp.directcopyfromprequeue
Help:
Number of bytes directly received in process context from prequeue

network.tcp.prequeueddropped
Help:
Number of packets dropped from prequeue

network.tcp.hphits
Help:
Number of packet headers predicted

network.tcp.hphitstouser
Help:
Number of packets header predicted and directly queued to user

network.tcp.pureacks
Help:
Number of acknowledgments not containing data payload received

network.tcp.hpacks
Help:
Number of predicted acknowledgments

network.tcp.renorecovery
Help:
Number of times recovered from packet loss due to fast retransmit

network.tcp.sackrecovery
Help:
Number of times recovered from packet loss by selective acknowledgements

network.tcp.sackreneging
Help:
Number of bad SACK blocks received

network.tcp.fackreorder
Help:
Number of times detected reordering using FACK

network.tcp.sackreorder
Help:
Number of times detected reordering using SACK

network.tcp.renoreorder
Help:
Number of times detected reordering using reno fast retransmit

network.tcp.tsreorder
Help:
Number of times detected reordering times using time stamp

network.tcp.fullundo
Help:
Number of congestion windows fully recovered without slow start

network.tcp.partialundo
Help:
Number of congestion windows partially recovered using Hoe heuristic

network.tcp.dsackundo
Help:
Number of congestion windows recovered without slow start using DSACK

network.tcp.lossundo
Help:
Number of congestion windows recovered without slow start after partial ack

network.tcp.lostretransmit
Help:
Number of retransmits lost

network.tcp.renofailures
Help:
Number of timeouts after reno fast retransmit

network.tcp.sackfailures
Help:
Number of timeouts after SACK recovery

network.tcp.lossfailures
Help:
Number of timeouts in loss state

network.tcp.fastretrans
Help:
Number of fast retransmits

network.tcp.forwardretrans
Help:
Number of forward retransmits

network.tcp.slowstartretrans
Help:
Number of retransmits in slow start

network.tcp.timeouts
Help:
Number of other TCP timeouts

network.tcp.lossprobes
Help:
Number of sent TCP loss probes

network.tcp.lossproberecovery
Help:
Number of TCP loss probe recoveries

network.tcp.renorecoveryfail
Help:
Number of reno fast retransmits failed

network.tcp.sackrecoveryfail
Help:
Number of SACK retransmits failed

network.tcp.schedulerfail
Help:
Number of times receiver scheduled too late for direct processing

network.tcp.rcvcollapsed
Help:
Number of packets collapsed in receive queue due to low socket buffer

network.tcp.dsackoldsent
Help:
Number of DSACKs sent for old packets

network.tcp.dsackofosent
Help:
Number of DSACKs sent for out of order packets

network.tcp.dsackrecv
Help:
Number of DSACKs received

network.tcp.dsackoforecv
Help:
Number of DSACKs for out of order packets received

network.tcp.abortondata
Help:
Number of connections reset due to unexpected data

network.tcp.abortonclose
Help:
Number of connections reset due to early user close

network.tcp.abortonmemory
Help:
Number of connections aborted due to memory pressure

network.tcp.abortontimeout
Help:
Number of connections aborted due to timeout

network.tcp.abortonlinger
Help:
Number of connections aborted after user close in linger timeout

network.tcp.abortfailed
Help:
Number of times unable to send RST due to no memory

network.tcp.memorypressures
Help:
Numer of times TCP ran low on memory

network.tcp.sackdiscard
Help:
Number of SACKs discarded

network.tcp.dsackignoredold
Help:
Number of ignored old duplicate SACKs

network.tcp.dsackignorednoundo
Help:
Number of ignored duplicate SACKs with undo_marker not set

network.tcp.spuriousrtos
Help:
Number of FRTO's successfully detected spurious RTOs

network.tcp.md5notfound
Help:
Number of times MD5 hash expected but not found

network.tcp.md5unexpected
Help:
Number of times MD5 hash unexpected but found

network.tcp.sackshifted
Help:
Number of SACKs shifted

network.tcp.sackmerged
Help:
Number of SACKs merged

network.tcp.sackshiftfallback
Help:
Number of SACKs fallbacks

network.tcp.backlogdrop
Help:
Number of frames dropped because of full backlog queue

network.tcp.minttldrop
Help:
Number of frames dropped when TTL is under the minimum

network.tcp.deferacceptdrop
Help:
Due to SYNACK retrans count lower than defer_accept value

network.tcp.iprpfilter
Help:
Number of packets dropped in input path because of rp_filter settings

network.tcp.timewaitoverflow
Help:
Number of occurences of time wait bucket overflow

network.tcp.reqqfulldocookies
Help:
Number of times a SYNCOOKIE was replied to client

network.tcp.reqqfulldrop
Help:
Number of times a SYN request was dropped due to disabled syncookies

network.tcp.retransfail
Help:
Number of failed tcp_retransmit_skb() calls

network.tcp.rcvcoalesce
Help:
Number of times tried to coalesce the receive queue

network.tcp.ofoqueue
Help:
Number of packets queued in OFO queue

network.tcp.ofodrop
Help:
Number of packets meant to be queued in OFO but dropped because socket rcvbuf
limit reached.

network.tcp.ofomerge
Help:
Number of packets in OFO that were merged with other packets

network.tcp.challengeack
Help:
Number of challenge ACKs sent (RFC 5961 3.2)

network.tcp.synchallenge
Help:
Number of challenge ACKs sent in response to SYN packets

network.tcp.fastopenactive
Help:
Number of successful active fast opens

network.tcp.fastopenactivefail
Help:
Number of fast open attempts failed due to remote not accepting it or time outs

network.tcp.fastopenpassive
Help:
Number of successful passive fast opens

network.tcp.fastopenpassivefail
Help:
Number of passive fast open attempts failed

network.tcp.fastopenlistenoverflow
Help:
Number of times the fastopen listen queue overflowed

network.tcp.fastopencookiereqd
Help:
Number of fast open cookies requested

network.tcp.spuriousrtxhostqueues
Help:
Number of times that the fast clone is not yet freed in tcp_transmit_skb()

network.tcp.busypollrxpackets
Help:
Number of low latency application-fetched packets

network.tcp.autocorking
Help:
Number of times stack detected skb was underused and its flush was deferred

network.tcp.fromzerowindowadv
Help:
Number of times window went from zero to non-zero

network.tcp.tozerowindowadv
Help:
Number of times window went from non-zero to zero

network.tcp.wantzerowindowadv
Help:
Number of times zero window announced

network.tcp.synretrans
Help:
Number of SYN-SYN/ACK retransmits to break down retransmissions in SYN, fast/timeout
retransmits.

network.tcp.origdatasent
Help:
Excluding retransmission but including data-in-SYN). This counter is different from
TcpOutSegs because TcpOutSegs also tracks pure ACKs. TCPOrigDataSent is
more useful to track the TCP retransmission rate.

network.udp.indatagrams
Help:
count of udp indatagrams

network.udp.noports
Help:
count of udp noports

network.udp.inerrors
Help:
count of udp inerrors

network.udp.outdatagrams
Help:
count of udp outdatagrams

network.udp.recvbuferrors
Help:
count of udp receive buffer errors

network.udp.sndbuferrors
Help:
count of udp send buffer errors

network.udp.incsumerrors
Help:
count of udp in checksum errors

network.udplite.indatagrams
Help:
count of udplite indatagrams

network.udplite.noports
Help:
count of udplite noports

network.udplite.inerrors
Help:
count of udplite inerrors

network.udplite.outdatagrams
Help:
count of udplite outdatagrams

network.udplite.recvbuferrors
Help:
count of udplite receive buffer errors

network.udplite.sndbuferrors
Help:
count of udplite send buffer errors

network.udplite.incsumerrors
Help:
count of udplite in checksum errors

network.udpconn.established
Help:
Number of established udp connections

network.udpconn.listen
Help:
Number of udp connections in listen state

network.rawconn.count
Help:
Number of raw socket connections

network.tcpconn.established
Help:
Number of established connections

network.tcpconn.syn_sent
Help:
Number of SYN_SENT connections

network.tcpconn.syn_recv
Help:
Number of SYN_RECV connections

network.tcpconn.fin_wait1
Help:
Number of FIN_WAIT1 connections

network.tcpconn.fin_wait2
Help:
Number of FIN_WAIT2 connections

network.tcpconn.time_wait
Help:
Number of TIME_WAIT connections

network.tcpconn.close
Help:
Number of CLOSE connections

network.tcpconn.close_wait
Help:
Number of CLOSE_WAIT connections

network.tcpconn.last_ack
Help:
Number of LAST_ACK connections

network.tcpconn.listen
Help:
Number of LISTEN connections

network.tcpconn.closing
Help:
Number of CLOSING connections

network.softnet.processed
Help:
number of packets (not including netpoll) received by the interrupt handler

network.softnet.dropped
Help:
number of packets that were dropped because netdev_max_backlog was exceeded

network.softnet.time_squeeze
Help:
number of times ksoftirq ran out of netdev_budget or time slice with work remaining

network.softnet.cpu_collision
Help:
number of times that two cpus collided trying to get the device queue lock

network.softnet.received_rps
Help:
number of times rps_trigger_softirq has been called

network.softnet.flow_limit_count
Help:
softnet_data flow limit counter

network.softnet.percpu.processed
Help:
number of packets (not including netpoll) received by the interrupt handler

network.softnet.percpu.dropped
Help:
number of packets that were dropped because netdev_max_backlog was exceeded

network.softnet.percpu.time_squeeze
Help:
number of times ksoftirq ran out of netdev_budget or time slice with work remaining

network.softnet.percpu.cpu_collision
Help:
number of times that two cpus collided trying to get the device queue lock

network.softnet.percpu.received_rps
Help:
number of times rps_trigger_softirq has been called

network.softnet.percpu.flow_limit_count
Help:
The network stack has to drop packets when a receive processing a CPUs
backlog reaches netdev_max_backlog.  The flow_limit_count counter is
the number of times very active flows have dropped their traffic earlier
to maintain capacity for other less active flows.

network.unix.datagram.count
Help:
Number of datagram unix domain sockets

network.unix.stream.established
Help:
Number of established unix domain socket streams

network.unix.stream.listen
Help:
Number of unix domain socket streams in listen state

network.unix.stream.count
Help:
Number of unix domain socket streams

network.ip6.inreceives
Help:
count of ip6 inreceives

network.ip6.inhdrerrors
Help:
count of ip6 inhdrerrors

network.ip6.intoobigerrors
Help:
count of ip6 intoobigerrors

network.ip6.innoroutes
Help:
count of ip6 innoroutes

network.ip6.inaddrerrors
Help:
count of ip6 inaddrerrors

network.ip6.inunknownprotos
Help:
count of ip6 inunknownprotos

network.ip6.intruncatedpkts
Help:
count of ip6 intruncatedpkts

network.ip6.indiscards
Help:
count of ip6 indiscards

network.ip6.indelivers
Help:
count of ip6 indelivers

network.ip6.outforwdatagrams
Help:
count of ip6 outforwdatagrams

network.ip6.outrequests
Help:
count of ip6 outrequests

network.ip6.outdiscards
Help:
count of ip6 outdiscards

network.ip6.outnoroutes
Help:
count of ip6 outnoroutes

network.ip6.reasmtimeout
Help:
count of ip6 reasmtimeout

network.ip6.reasmreqds
Help:
count of ip6 reassembly requireds

network.ip6.reasmoks
Help:
count of ip6 reassembly oks

network.ip6.reasmfails
Help:
count of ip6 reassembly failures

network.ip6.fragoks
Help:
count of ip6 fragmentation oks

network.ip6.fragfails
Help:
count of ip6 fragmentation failures

network.ip6.fragcreates
Help:
count of ip6 fragmentation creations

network.ip6.inmcastpkts
Help:
count of ip6 multicast packets in

network.ip6.outmcastpkts
Help:
count of ip6 multicast packets out

network.ip6.inoctets
Help:
count of ip6 octets in

network.ip6.outoctets
Help:
count of ip6 octets out

network.ip6.inmcastoctets
Help:
count of ip6 multicast octets in

network.ip6.outmcastoctets
Help:
count of ip6 multicast octets out

network.ip6.inbcastoctets
Help:
count of ip6 broadcast octets in

network.ip6.outbcastoctets
Help:
count of ip6 broadcast octets uot

network.ip6.innoectpkts
Help:
count of ip6 packets received with NOECT

network.ip6.inect1pkts
Help:
count of ip6 packets received with ECT(1)

network.ip6.inect0pkts
Help:
count of ip6 packets received with ECT(0)

network.ip6.incepkts
Help:
count of ip6 Congestion Experimented packets in

network.icmp6.inmsgs
Help:
count of icmp6 inmsgs

network.icmp6.inerrors
Help:
count of icmp6 inerrors

network.icmp6.outmsgs
Help:
count of icmp6 outmsgs

network.icmp6.outerrors
Help:
count of icmp6 outerrors

network.icmp6.incsumerrors
Help:
count of icmp6 incsumerrors

network.icmp6.indestunreachs
Help:
count of icmp6 indestunreachs

network.icmp6.inpkttoobigs
Help:
count of icmp6 inpkttoobigs

network.icmp6.intimeexcds
Help:
count of icmp6 intimeexcds

network.icmp6.inparmproblems
Help:
count of icmp6 inparmprobs

network.icmp6.inechos
Help:
count of icmp6 inechos

network.icmp6.inechoreplies
Help:
count of icmp6 inechoreplies

network.icmp6.ingroupmembqueries
Help:
count of icmp6 ingroupmembqueries

network.icmp6.ingroupmembresponses
Help:
count of icmp6 ingroupmembresponses

network.icmp6.ingroupmembreductions
Help:
count of icmp6 ingroupmembreductions

network.icmp6.inroutersolicits
Help:
count of icmp6 inroutersolicits

network.icmp6.inrouteradvertisements
Help:
count of icmp6 inrouteradvertisements

network.icmp6.inneighborsolicits
Help:
count of icmp6 inneighborsolicits

network.icmp6.inneighboradvertisements
Help:
count of icmp6 inneighboradvertisements

network.icmp6.inredirects
Help:
count of icmp6 inredirects

network.icmp6.inmldv2reports
Help:
count of icmp6 inmldv2reports

network.icmp6.outdestunreachs
Help:
count of icmp6 outdestunreachs

network.icmp6.outpkttoobigs
Help:
count of icmp6 outpkttoobigs

network.icmp6.outtimeexcds
Help:
count of icmp6 outtimeexcds

network.icmp6.outparmproblems
Help:
count of icmp6 outparmproblems

network.icmp6.outechos
Help:
count of icmp6 outechos

network.icmp6.outechoreplies
Help:
count of icmp6 outechoreplies

network.icmp6.outgroupmembqueries
Help:
count of icmp6 outgroupmembqueries

network.icmp6.outgroupmembresponses
Help:
count of icmp6 outgroupmembresponses

network.icmp6.outgroupmembreductions
Help:
count of icmp6 outgroupmembreductions

network.icmp6.outroutersolicits
Help:
count of icmp6 outroutersolicits

network.icmp6.outrouteradvertisements
Help:
count of icmp6 outrouteradvertisements

network.icmp6.outneighborsolicits
Help:
count of icmp6 outneighborsolicits

network.icmp6.outneighboradvertisements
Help:
count of icmp6 outneighboradvertisements

network.icmp6.outredirects
Help:
count of icmp6 outredirects

network.icmp6.outmldv2reports
Help:
count of icmp6 outmldv2reports

network.udp6.indatagrams
Help:
count of udp6 indatagrams

network.udp6.noports
Help:
count of udp6 noports

network.udp6.inerrors
Help:
count of udp6 inerrors

network.udp6.outdatagrams
Help:
count of udp6 outdatagrams

network.udp6.rcvbuferrors
Help:
count of udp6 rcvbuferrors

network.udp6.sndbuferrors
Help:
count of udp6 sndbuferrors

network.udp6.incsumerrors
Help:
count of udp6 incsumerrors

network.udp6.ignoredmulti
Help:
count of udp6 ignoredmulti

network.udpconn6.established
Help:
Number of established udp6 connections

network.udpconn6.listen
Help:
Number of udp6 connections in listen state

network.udplite6.indatagrams
Help:
count of udplite6 indatagrams

network.udplite6.noports
Help:
count of udplite6 noports

network.udplite6.inerrors
Help:
count of udplite6 inerrors

network.udplite6.outdatagrams
Help:
count of udplite6 outdatagrams

network.udplite6.rcvbuferrors
Help:
count of udplite6 receive buffer errors

network.udplite6.sndbuferrors
Help:
count of udplite6 send buffer errors

network.udplite6.incsumerrors
Help:
count of udplite6 in checksum errors

network.rawconn6.count
Help:
Number of raw6 socket connections

network.tcpconn6.established
Help:
Number of established tcp6 connections

network.tcpconn6.syn_sent
Help:
Number of SYN_SENT tcp6 connections

network.tcpconn6.syn_recv
Help:
Number of SYN_RECV tcp6 connections

network.tcpconn6.fin_wait1
Help:
Number of FIN_WAIT1 tcp6 connections

network.tcpconn6.fin_wait2
Help:
Number of FIN_WAIT2 tcp6 connections

network.tcpconn6.time_wait
Help:
Number of TIME_WAIT tcp6 connections

network.tcpconn6.close
Help:
Number of CLOSE tcp6 connections

network.tcpconn6.close_wait
Help:
Number of CLOSE_WAIT tcp6 connections

network.tcpconn6.last_ack
Help:
Number of LAST_ACK tcp6 connections

network.tcpconn6.listen
Help:
Number of LISTEN tcp6 connections

network.tcpconn6.closing
Help:
Number of CLOSING tcp6 connections

disk.dev.read
Help:
Cumulative number of disk read operations since system boot time (subject
to counter wrap).

disk.dev.write
Help:
Cumulative number of disk write operations since system boot time (subject
to counter wrap).

disk.dev.total
Help:
Cumulative number of disk read and write operations since system boot
time (subject to counter wrap).

disk.dev.blkread
Help:
Cumulative number of disk block read operations since system boot time
(subject to counter wrap).

disk.dev.blkwrite
Help:
Cumulative number of disk block write operations since system boot time
(subject to counter wrap).

disk.dev.blktotal
Help:
Cumulative number of disk block read and write operations since system
boot time (subject to counter wrap).

disk.dev.read_bytes
Help:
per-disk count of bytes read

disk.dev.write_bytes
Help:
per-disk count of bytes written

disk.dev.total_bytes
Help:
per-disk count of total bytes read and written

disk.dev.read_merge
Help:
Count of read requests that were merged with an already queued read request.

disk.dev.write_merge
Help:
Count of write requests that were merged with an already queued write request.

disk.dev.avactive
Help:
Counts the number of milliseconds for which at least one I/O is in
progress for each device.

When converted to a rate, this metric represents the average utilization of
the disk during the sampling interval.  A value of 0.5 (or 50%) means the
disk was active (i.e. busy) half the time.

disk.dev.read_rawactive
Help:
For each completed read on each disk the response time (queue time plus
service time) in milliseconds is added to the associated instance of
this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding reads for a disk.  When divided by the number
of completed reads for a disk (disk.dev.read), the value represents the
stochastic average of the read response (or wait) time for that disk.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dev.r_await = delta(disk.dev.read_rawactive) / delta(disk.dev.read)

disk.dev.write_rawactive
Help:
For each completed write on each disk the response time (queue time plus
service time) in milliseconds is added to the associated instance of
this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding writes for a disk.  When divided by
the number of completed writes for a disk (disk.dev.write), the value
represents the stochastic average of the write response (or wait)
time for that disk.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dev.w_await = delta(disk.dev.write_rawactive) / delta(disk.dev.write)

disk.dev.total_rawactive
Help:
For each completed I/O on each disk the response time (queue time plus
service time) in milliseconds is added to the associated instance of
this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding I/Os for a disk.  When divided by the number
of completed I/Os for a disk (disk.dev.total), the value represents the
stochastic average of the I/O response (or wait) time for that disk.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dev.await = delta(disk.dev.total_rawactive) / delta(disk.dev.total)

disk.dev.aveq
Help:
When converted to a rate, this metric represents the time averaged disk
request queue length during the sampling interval.  A value of 2.5 (or 250%)
represents a time averaged queue length of 2.5 requests during the sampling
interval.

disk.dev.scheduler
Help:
The name of the I/O scheduler in use for each device.  The scheduler
is part of the block layer in the kernel, and attempts to optimise the
I/O submission patterns using various techniques (typically, sorting
and merging adjacent requests into larger ones to reduce seek activity,
but certainly not limited to that).

disk.dev.capacity
Help:
Total space presented by each block device, from /proc/partitions.

disk.all.read
Help:
Cumulative number of disk read operations since system boot time
(subject to counter wrap), summed over all disk devices.

disk.all.write
Help:
Cumulative number of disk read operations since system boot time
(subject to counter wrap), summed over all disk devices.

disk.all.total
Help:
Cumulative number of disk read and write operations since system boot
time (subject to counter wrap), summed over all disk devices.

disk.all.blkread
Help:
Cumulative number of disk block read operations since system boot time
(subject to counter wrap), summed over all disk devices.

disk.all.blkwrite
Help:
Cumulative number of disk block write operations since system boot time
(subject to counter wrap), summed over all disk devices.

disk.all.blktotal
Help:
Cumulative number of disk block read and write operations since system
boot time (subject to counter wrap), summed over all disk devices.

disk.all.read_bytes
Help:
count of bytes read for all disk devices

disk.all.write_bytes
Help:
count of bytes written for all disk devices

disk.all.total_bytes
Help:
total count of bytes read and written for all disk devices

disk.all.read_merge
Help:
Total count of read requests that were merged with an already queued read request.

disk.all.write_merge
Help:
Total count of write requests that were merged with an already queued write request.

disk.all.avactive
Help:
Counts the number of milliseconds for which at least one I/O is in
progress on each disk, summed across all disks.

When converted to a rate and divided by the number of disks (hinv.ndisk),
this metric represents the average utilization of all disks during the
sampling interval.  A value of 0.25 (or 25%) means that on average every
disk was active (i.e. busy) one quarter of the time.

disk.all.read_rawactive
Help:
For each completed read on every disk the response time (queue time plus
service time) in milliseconds is added to this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding reads across all disks.  When divided
by the number of completed reads for all disks (disk.all.read), value
represents the stochastic average of the read response (or wait) time
across all disks.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.all.r_await = delta(disk.all.read_rawactive) / delta(disk.all.read)

disk.all.write_rawactive
Help:
For each completed write on every disk the response time (queue time
plus service time) in milliseconds is added to this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding writes across all disks.  When divided by
the number of completed writes for all disks (disk.all.write), value
represents the stochastic average of the write response (or wait) time
across all disks.

disk.all.total_rawactive
Help:
For each completed I/O on every disk the response time (queue time
plus service time) in milliseconds is added to this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding I/Os across all disks.  When divided by
the number of completed I/Os for all disks (disk.all.total), value
represents the stochastic average of the I/O response (or wait) time
across all disks.

disk.all.aveq
Help:
When converted to a rate, this metric represents the average across all disks
of the time averaged request queue length during the sampling interval.  A
value of 1.5 (or 150%) suggests that (on average) each all disk experienced a
time averaged queue length of 1.5 requests during the sampling interval.

disk.partitions.read
Help:
Cumulative number of disk read operations since system boot time
(subject to counter wrap) for individual disk partitions or logical
volumes.

disk.partitions.write
Help:
Cumulative number of disk write operations since system boot time
(subject to counter wrap) for individual disk partitions or logical
volumes.

disk.partitions.total
Help:
Cumulative number of disk read and write operations since system boot
time (subject to counter wrap) for individual disk partitions or
logical volumes.

disk.partitions.blkread
Help:
Cumulative number of disk block read operations since system boot time
(subject to counter wrap) for individual disk partitions or logical
volumes.

disk.partitions.blkwrite
Help:
Cumulative number of disk block write operations since system boot time
(subject to counter wrap) for individual disk partitions or logical
volumes.

disk.partitions.blktotal
Help:
Cumulative number of disk block read and write operations since system
boot time (subject to counter wrap) for individual disk partitions or
logical volumes.

disk.partitions.read_bytes
Help:
Cumulative number of bytes read since system boot time (subject to
counter wrap) for individual disk partitions or logical volumes.

disk.partitions.write_bytes
Help:
Cumulative number of bytes written since system boot time (subject to
counter wrap) for individual disk partitions or logical volumes.

disk.partitions.total_bytes
Help:
Cumulative number of bytes read and written since system boot time
(subject to counter wrap) for individual disk partitions or logical
volumes.

disk.partitions.read_merge
Help:
per-disk-partition count of merged read requests

disk.partitions.write_merge
Help:
per-disk-partition count of merged write requests

disk.partitions.avactive
Help:
Counts the number of milliseconds for which at least one I/O is in
progress for each disk partition.

When converted to a rate, this metric represents the average utilization
of the disk partition during the sampling interval.  A value of 0.5
(or 50%) means the disk partition was active (i.e. busy) half the time.

disk.partitions.aveq
Help:
per-disk-partition device time averaged count of request queue length

disk.partitions.read_rawactive
Help:
For each completed read on each disk partition the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time average
of the number of outstanding reads for a disk partition.  When divided by
the number of completed reads for a disk partition (disk.partitions.read),
the value represents the stochastic average of the read response (or wait)
time for that disk partition.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.partitions.r_await = delta(disk.partitions.read_rawactive) /
                             delta(disk.partitions.read)

disk.partitions.write_rawactive
Help:
For each completed write on each disk partition the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding writes for a disk partition.
When divided by the number of completed writes for a disk partition
(disk.partitions.write), the value represents the stochastic average of
the write response (or wait) time for that disk partition.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.partitions.w_await = delta(disk.partitions.write_rawactive) /
                             delta(disk.partitions.write)

disk.partitions.total_rawactive
Help:
For each completed I/O on each disk partition the response time (queue
time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding I/Os for a disk partition.
When divided by the number of completed I/Os for a disk partition
(disk.partitions.total), the value represents the stochastic average of
the I/O response (or wait) time for that disk partition.

disk.partitions.capacity
Help:
Total space presented by each disk partition, from /proc/partitions.

disk.dm.read
Help:
per-device-mapper device read operations

disk.dm.write
Help:
per-device-mapper device write operations

disk.dm.total
Help:
per-device-mapper device total (read+write) operations

disk.dm.blkread
Help:
per-device-mapper device block read operations

disk.dm.blkwrite
Help:
per-device-mapper device block write operations

disk.dm.blktotal
Help:
per-device-mapper device total (read+write) block operations

disk.dm.read_bytes
Help:
per-device-mapper device count of bytes read

disk.dm.write_bytes
Help:
per-device-mapper device count of bytes written

disk.dm.total_bytes
Help:
per-device-mapper device count of total bytes read and written

disk.dm.read_merge
Help:
per-device-mapper device count of merged read requests

disk.dm.write_merge
Help:
per-device-mapper device count of merged write requests

disk.dm.avactive
Help:
Counts the number of milliseconds for which at least one I/O is in
progress for each device-mapper device.

When converted to a rate, this metric represents the average utilization
of the device during the sampling interval.  A value of 0.5 (or 50%)
means the device was active (i.e. busy) half the time.

disk.dm.aveq
Help:
per-device-mapper device time averaged count of request queue length

disk.dm.read_rawactive
Help:
For each completed read on each device-mapper device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding reads for a device-mapper device.
When divided by the number of completed reads for a device-mapper device
(disk.dm.read), the value represents the stochastic average of the read
response (or wait) time for that device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dm.r_await = delta(disk.dm.read_rawactive) / delta(disk.dm.read)

disk.dm.write_rawactive
Help:
For each completed write on each device-mapper device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding writes for a device-mapper device.
When divided by the number of completed writes for a device-mapper device
(disk.dm.write), the value represents the stochastic average of the
write response (or wait) time for that device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dm.w_await = delta(disk.dm.write_rawactive) / delta(disk.dm.write)

disk.dm.total_rawactive
Help:
For each completed I/O on each device-mapper device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding I/Os for a device-mapper device.
When divided by the number of completed I/Os for a device-mapper device
(disk.dm.total), the value represents the stochastic average of the I/O
response (or wait) time for that device-mapper device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.dm.await = delta(disk.dm.total_rawactive) / delta(disk.dm.total)

disk.dm.capacity
Help:
Total space presented by each device mapper device, from /proc/partitions.

disk.md.read
Help:
per-multi-device device read operations

disk.md.write
Help:
per-multi-device device write operations

disk.md.total
Help:
per-multi-device device total (read+write) operations

disk.md.blkread
Help:
per-multi-device device block read operations

disk.md.blkwrite
Help:
per-multi-device device block write operations

disk.md.blktotal
Help:
per-multi-device device total (read+write) block operations

disk.md.read_bytes
Help:
per-multi-device device count of bytes read

disk.md.write_bytes
Help:
per-multi-device device count of bytes written

disk.md.total_bytes
Help:
per-multi-device device count of total bytes read and written

disk.md.read_merge
Help:
per-multi-device device count of merged read requests

disk.md.write_merge
Help:
per-multi-device device count of merged write requests

disk.md.avactive
Help:
Counts the number of milliseconds for which at least one I/O is in
progress for each multi-device device.

When converted to a rate, this metric represents the average utilization
of the device during the sampling interval.  A value of 0.5 (or 50%)
means the device was active (i.e. busy) half the time.

disk.md.aveq
Help:
per-multi-device device time averaged count of request queue length

disk.md.read_rawactive
Help:
For each completed read on each multi-device device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding reads for a multi-device device.
When divided by the number of completed reads for a multi-device device
(disk.md.read), the value represents the stochastic average of the read
response (or wait) time for that device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.md.r_await = delta(disk.md.read_rawactive) / delta(disk.md.read)

disk.md.write_rawactive
Help:
For each completed write on each multi-device device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding writes for a multi-device device.
When divided by the number of completed writes for a multi-device device
(disk.md.write), the value represents the stochastic average of the
write response (or wait) time for that device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.md.w_await = delta(disk.md.write_rawactive) / delta(disk.md.write)

disk.md.total_rawactive
Help:
For each completed I/O on each multi-device device the response time
(queue time plus service time) in milliseconds is added to the associated
instance of this metric.

When converted to a normalized rate, the value represents the time
average of the number of outstanding I/Os for a multi-device device.
When divided by the number of completed I/Os for a multi-device device
(disk.md.total), the value represents the stochastic average of the I/O
response (or wait) time for that multi-device device.

It is suitable mainly for use in calculations with other metrics,
e.g. mirroring the results from existing performance tools:

 iostat.md.await = delta(disk.md.total_rawactive) / delta(disk.md.total)

disk.md.status
Help:
per-multi-device "mdadm --test --detail <device>" return code

disk.md.capacity
Help:
Total space presented by each multi-device device, from /proc/partitions.

filesys.capacity
Help:
Total capacity of mounted filesystem (Kbytes)

filesys.used
Help:
Total space used on mounted filesystem (Kbytes)

filesys.free
Help:
Total space free on mounted filesystem (Kbytes)

filesys.maxfiles
Help:
Inodes capacity of mounted filesystem

filesys.usedfiles
Help:
Number of inodes allocated on mounted filesystem

filesys.freefiles
Help:
Number of unallocated inodes on mounted filesystem

filesys.mountdir
Help:
File system mount point

filesys.full
Help:
Percentage of filesystem in use

filesys.blocksize
Help:
Size of each block on mounted filesystem (Bytes)

filesys.avail
Help:
Total space free to non-superusers on mounted filesystem (Kbytes)

filesys.readonly
Help:
Indicates whether a filesystem is mounted readonly

swapdev.free
Help:
physical swap free space

swapdev.length
Help:
physical swap size

swapdev.maxswap
Help:
maximum swap length (same as swapdev.length on Linux)

swapdev.vlength
Help:
Virtual swap size (always zero on Linux since Linux does not support
virtual swap).

This metric is retained on Linux for interoperability with PCP monitor
tools running on IRIX.

swapdev.priority
Help:
swap resource priority

rpc.client.rpccnt
Help:
cumulative total of client RPC requests

rpc.client.rpcretrans
Help:
cumulative total of client RPC retransmissions

rpc.client.rpcauthrefresh
Help:
cumulative total of client RPC auth refreshes

rpc.client.netcnt
Help:
cumulative total of client RPC network layer requests

rpc.client.netudpcnt
Help:
cumulative total of client RPC UDP network layer requests

rpc.client.nettcpcnt
Help:
cumulative total of client RPC TCP network layer requests

rpc.client.nettcpconn
Help:
cumulative total of client RPC TCP network layer connection requests

rpc.server.rpccnt
Help:
cumulative total of server RPC requests

rpc.server.rpcerr
Help:
cumulative total of server RPC errors

rpc.server.rpcbadfmt
Help:
cumulative total of server RPC bad format errors

rpc.server.rpcbadauth
Help:
cumulative total of server RPC bad auth errors

rpc.server.rpcbadclnt
Help:
cumulative total of server RPC bad client errors

rpc.server.rchits
Help:
cumulative total of request-reply-cache hits

rpc.server.rcmisses
Help:
cumulative total of request-reply-cache misses

rpc.server.rcnocache
Help:
cumulative total of uncached request-reply-cache requests

rpc.server.fh_cached
Help:
cumulative total of file handle cache requests

rpc.server.fh_valid
Help:
cumulative total of file handle cache validations

rpc.server.fh_fixup
Help:
cumulative total of file handle cache fixup validations

rpc.server.fh_lookup
Help:
cumulative total of file handle cache new lookups

rpc.server.fh_stale
Help:
cumulative total of stale file handle cache errors

rpc.server.fh_concurrent
Help:
cumulative total of concurrent file handle cache requests

rpc.server.netcnt
Help:
cumulative total of server RPC network layer requests

rpc.server.netudpcnt
Help:
cumulative total of server RPC UDP network layer requests

rpc.server.nettcpcnt
Help:
cumulative total of server RPC TCP network layer requests

rpc.server.nettcpconn
Help:
cumulative total of server RPC TCP network layer connection requests

rpc.server.fh_anon
Help:
cumulative total anonymous file dentries returned

rpc.server.fh_nocache_dir
Help:
count of directory file handles not found cached

rpc.server.fh_nocache_nondir
Help:
count of non-directory file handles not found cached

rpc.server.io_read
Help:
cumulative count of bytes returned from read requests

rpc.server.io_write
Help:
cumulative count of bytes passed into write requests

rpc.server.th_cnt
Help:
available nfsd threads

rpc.server.th_fullcnt
Help:
number of times the last free nfsd thread was used

rpc.server.ra_size
Help:
size of read-ahead params cache

rpc.server.ra_hits
Help:
count of read-ahead params cache hits

rpc.server.ra_misses
Help:
count of read-ahead params cache misses

nfs.client.calls
Help:
cumulative total of client NFSv2 requests

nfs.client.reqs
Help:
cumulative total of client NFSv2 requests by request type

nfs.server.calls
Help:
cumulative total of server NFSv2 requests

nfs.server.reqs
Help:
cumulative total of client NFSv2 requests by request type

nfs.server.threads.total
Help:
number of nfsd threads running

nfs.server.threads.pools
Help:
number of thread pools

nfs.server.threads.requests
Help:
cumulative total of requests received

nfs.server.threads.enqueued
Help:
cumulative total of requests that had to wait to be processed

nfs.server.threads.processed
Help:
cumulative total of requests processed immediately

nfs.server.threads.timedout
Help:
cumulative total of threads that timedout from inactivity

nfs3.client.calls
Help:
cumulative total of client NFSv3 requests

nfs3.client.reqs
Help:
cumulative total of client NFSv3 requests by request type

nfs3.server.calls
Help:
cumulative total of server NFSv3 requests

nfs3.server.reqs
Help:
cumulative total of client NFSv3 requests by request type

nfs4.client.calls
Help:
cumulative total of client NFSv4 requests

nfs4.client.reqs
Help:
cumulative total for each client NFSv4 request type

nfs4.server.calls
Help:
cumulative total of server NFSv4 operations, plus NULL requests

nfs4.server.reqs
Help:
cumulative total for each server NFSv4 operation, and for NULL requests

pmda.uname
Help:
Identity and type of current system.  The concatenation of the values
returned from utsname(2), also similar to uname -a.

See also the kernel.uname.* metrics

pmda.version
Help:
build version of Linux PMDA

ipc.sem.max_semmap
Help:
maximum number of entries in a semaphore map (from semctl(..,IPC_INFO,..))

ipc.sem.max_semid
Help:
maximum number of semaphore identifiers (from semctl(..,IPC_INFO,..))

ipc.sem.max_sem
Help:
maximum number of semaphores in system (from semctl(..,IPC_INFO,..))

ipc.sem.num_undo
Help:
number of undo structures in system (from semctl(..,IPC_INFO,..))

ipc.sem.max_perid
Help:
maximum number of semaphores per identifier (from semctl(..,IPC_INFO,..))

ipc.sem.max_ops
Help:
maximum number of operations per semop call (from semctl(..,IPC_INFO,..))

ipc.sem.max_undoent
Help:
maximum number of undo entries per process (from semctl(..,IPC_INFO,..))

ipc.sem.sz_semundo
Help:
size of struct sem_undo (from semctl(..,IPC_INFO,..))

ipc.sem.max_semval
Help:
semaphore maximum value (from semctl(..,IPC_INFO,..))

ipc.sem.max_exit
Help:
adjust on exit maximum value (from semctl(..,IPC_INFO,..))

ipc.sem.used_sem
Help:
number of semaphore sets currently on the system (from semctl(..,SEM_INFO,..))

ipc.sem.tot_sem
Help:
number of semaphores in all sets on the system (from semctl(..,SEM_INFO,..))

ipc.sem.key
Help:
key of these semaphore (from msgctl(..,SEM_STAT,..))

ipc.sem.owner
Help:
username of owner (from msgctl(..,SEM_STAT,..))

ipc.sem.perms
Help:
access permissions (from msgctl(..,SEM_STAT,..))

ipc.sem.nsems
Help:
number of semaphore (from semctl(..,SEM_STAT,..))

ipc.msg.sz_pool
Help:
size of message pool in kilobytes (from msgctl(..,IPC_INFO,..))

ipc.msg.mapent
Help:
number of entries in a message map (from msgctl(..,IPC_INFO,..))

ipc.msg.max_msgsz
Help:
maximum size of a message in bytes (from msgctl(..,IPC_INFO,..))

ipc.msg.max_defmsgq
Help:
default maximum size of a message queue (from msgctl(..,IPC_INFO,..))

ipc.msg.max_msgqid
Help:
maximum number of message queue identifiers (from msgctl(..,IPC_INFO,..))

ipc.msg.max_msgseg
Help:
message segment size (from msgctl(..,IPC_INFO,..))

ipc.msg.num_smsghdr
Help:
number of system message headers (from msgctl(..,IPC_INFO,..))

ipc.msg.max_seg
Help:
maximum number of message segments (from msgctl(..,IPC_INFO,..))

ipc.msg.used_queues
Help:
number of message queues that currently exist (from msgctl(..,MSG_INFO,..))

ipc.msg.tot_msg
Help:
total number of messages in all queues (from msgctl(..,MSG_INFO,..))

ipc.msg.tot_bytes
Help:
number of bytes in all messages in all queues (from msgctl(..,MSG_INFO,..))

ipc.msg.key
Help:
name of these messages slot (from msgctl(..,MSG_STAT,..))

ipc.msg.owner
Help:
username of owner (from msgctl(..,MSG_STAT,..))

ipc.msg.perms
Help:
access permissions (from msgctl(..,MSG_STAT,..))

ipc.msg.msgsz
Help:
used size in bytes (from msgctl(..,MSG_STAT,..))

ipc.msg.messages
Help:
number of messages currently queued (from msgctl(..,MSG_STAT,..))

ipc.msg.last_send_pid
Help:
last process to send on each message queue

ipc.msg.last_recv_pid
Help:
last process to recv on each message queue

ipc.shm.max_segsz
Help:
maximum shared segment size in bytes (from shmctl(..,IPC_INFO,..))

ipc.shm.min_segsz
Help:
minimum shared segment size in bytes (from shmctl(..,IPC_INFO,..))

ipc.shm.max_seg
Help:
maximum number of shared segments in system (from shmctl(..,IPC_INFO,..))

ipc.shm.max_segproc
Help:
maximum number of shared segments per process (from shmctl(..,IPC_INFO,..))

ipc.shm.max_shmsys
Help:
maximum amount of shared memory in system in pages (from shmctl(..,IPC_INFO,..))

ipc.shm.tot
Help:
total number of shared memory pages (from shmctl(..,SHM_INFO,..))

ipc.shm.rss
Help:
number of resident shared memory pages (from shmctl(..,SHM_INFO,..))

ipc.shm.swp
Help:
number of swapped shared memory pages (from shmctl(..,SHM_INFO,..))

ipc.shm.used_ids
Help:
number of currently existing segments (from shmctl(..,SHM_INFO,..))

ipc.shm.swap_attempts
Help:
number of swap attempts (from shmctl(..,SHM_INFO,..))

ipc.shm.swap_successes
Help:
number of swap successes (from shmctl(..,SHM_INFO,..))

ipc.shm.key
Help:
Key supplied to shmget (from shmctl(.., SHM_STAT, ..))

ipc.shm.owner
Help:
share memory segment owner (rom shmctl(.., SHM_STAT, ..))

ipc.shm.perms
Help:
operation perms (from shmctl(.., SHM_STAT, ..))

ipc.shm.segsz
Help:
size of segment (bytes) (from shmctl(.., SHM_STAT, ..))

ipc.shm.nattch
Help:
no. of current attaches (from shmctl(.., SHM_STAT, ..))

ipc.shm.status
Help:
The string value may contain the space-separated values "dest" (a shared memory
segment marked for destruction on last detach) and "locked" or the empty string.

ipc.shm.creator_pid
Help:
process creating each shared memory segment

ipc.shm.last_access_pid
Help:
process last accessing each shared memory segment

vfs.files.count
Help:
number of in-use file structures

vfs.files.free
Help:
number of available file structures

vfs.files.max
Help:
hard maximum on number of file structures

vfs.inodes.count
Help:
number of in-use inode structures

vfs.inodes.free
Help:
number of available inode structures

vfs.dentry.count
Help:
number of in-use directory entry structures

vfs.dentry.free
Help:
number of available directory entry structures

vfs.aio.count
Help:
number of in-use asynchronous IO structures

vfs.aio.max
Help:
hard maximum on number of asynchronous IO structures

vfs.locks.posix.read
Help:
number of POSIX locks held for reading

vfs.locks.posix.write
Help:
number of POSIX locks held for writing

vfs.locks.posix.count
Help:
number of POSIX lock structures

vfs.locks.flock.read
Help:
number of advisory file locks held for reading

vfs.locks.flock.write
Help:
number of advisory file locks held for writing

vfs.locks.flock.count
Help:
number of advisory file lock structures

vfs.locks.lease.read
Help:
number of file leases held for reading

vfs.locks.lease.write
Help:
number of file leases held for writing

vfs.locks.lease.count
Help:
number of file lease structures

tmpfs.capacity
Help:
Total capacity of mounted tmpfs filesystem (Kbytes)

tmpfs.used
Help:
Total space used on mounted tmpfs filesystem (Kbytes)

tmpfs.free
Help:
Total space free on mounted tmpfs filesystem (Kbytes)

tmpfs.maxfiles
Help:
Inodes capacity of mounted tmpfs filesystem

tmpfs.usedfiles
Help:
Number of inodes allocated on mounted tmpfs filesystem

tmpfs.freefiles
Help:
Number of unallocated inodes on mounted tmpfs filesystem

tmpfs.full
Help:
Percentage of tmpfs filesystem in use

sysfs.kernel.uevent_seqnum
Help:
counter of the number of uevents processed by the udev subsystem

tape.dev.in_flight
Help:
number of I/Os currently outstanding to this tape device

tape.dev.io_ns
Help:
The amount of time spent waiting (in nanoseconds) for all I/O to complete
(including read and write). This includes tape movement commands such as seeking
between file or set marks and implicit tape movement such as when rewind on close
tape devices are used.

tape.dev.other_cnt
Help:
number of I/Os issued to the tape drive other than read or write commands

tape.dev.read_byte_cnt
Help:
number of bytes read from the tape drive

tape.dev.read_cnt
Help:
number of read requests issued to the tape drive

tape.dev.read_ns
Help:
cummulative amount of time spent waiting for read requests to complete

tape.dev.resid_cnt
Help:
Number of times during a read or write we found the residual amount to be non-zero.
For reads this means a program is issuing a read larger than the block size on tape.
For writes it means not all data made it to tape.

tape.dev.write_byte_cnt
Help:
number of bytes written to the tape drive

tape.dev.write_cnt
Help:
number of write requests issued to the tape drive

tape.dev.write_ns
Help:
cummulative amount of time spent waiting for write requests to complete

tty.serial.tx
Help:
Number of transmit interrupts for current serial line.

tty.serial.rx
Help:
Number of receive interrupts for current serial line.

tty.serial.frame
Help:
Number of frame errors for current serial line.

tty.serial.parity
Help:
Number of parity errors for current serial line.

tty.serial.brk
Help:
Number of breaks for current serial line.

tty.serial.overrun
Help:
Number of overrun errors for current serial line.

tty.serial.irq
Help:
IRQ number.

mmv.control.files
Help:
Count of currently mapped and exported statistics files.

mmv.control.debug
Help:
See pmdbg(1).  pmstore into this metric to change the debug value.

mmv.control.reload
Help:
Writing anything other then 0 to this metric will result in
re-reading directory and re-mapping files.

pmcd.datasize
Help:
This metric returns the amount of memory in kilobytes allocated for the
data segment of PMCD and any DSO agents (PMDAs) that it has loaded.

This is handy for tracing memory utilization (and leaks) in DSOs during
development.

pmcd.numagents
Help:
The number of agents (PMDAs) currently connected to PMCD.  This may differ
from the number of agents configured in $PCP_PMCDCONF_PATH if agents have
terminated and/or been timed-out by PMCD.

pmcd.numclients
Help:
The number of connections open to client programs retrieving information
from PMCD.

pmcd.timezone
Help:
Value for the $TZ environment variable where the PMCD is running.
Enables determination of "local" time for timestamps returned via
PMCD from a remote host.

pmcd.simabi
Help:
SIM is the subprogram interface model (originally from the MIPS object
code formats), and ABI is the application binary interface.  Both
relate to the way the PMCD binary was compiled and linked.

Usually DSO PMDAs must be compiled and linked in the same way before
they can be used with PMCD.

On some platforms this metric is not available.

pmcd.version
Help:
PMCD version

pmcd.services
Help:
A space-separated string representing all running PCP services with PID
files in $PCP_RUN_DIR (such as pmcd itself, pmproxy and a few others).

pmcd.openfds
Help:
The highest file descriptor index used by PMCD for a Client or PMDA
connection.

pmcd.build
Help:
Minor part of the PCP build version numbering.  For example on Linux
with RPM packaging, if the PCP RPM version is pcp-2.5.99-20070323 then
pmcd.build returns the string "20070323".

pmcd.hostname
Help:
A reasonably unique identifier of the PMCD installation, for use
by pmlogger or other tools to identify the source principal of
the data (as distinct from identifying the connection/protocol
used to reach it).

pmcd.sighups
Help:
count of SIGHUP signals pmcd has received

pmcd.pid
Help:
PID for the current pmcd invocation

pmcd.seqnum
Help:

The configuration sequence number starts at 1 when pmcd is started
and is incremented by 1 each time a PMDA is started or restarted.

So all the while the value of pmcd.seqnum remains constant we can
assert the data from all the PMDAs forms a continuous time series
and in particular no counters or other metrics have been reset due
to a PMDA start/restart.

pmcd.labels
Help:
Additional end-user and PMCS metadata can be associated with performance
metrics via $PCP_SYSCONF_DIR/labels files.  This metric exports the user
defined labels that will be reported by pmGetContextLabels(3).  This set
does not include labels automatically associated with every context such
as the hostname, user and group identifier, container identifier, etc.

pmcd.control.debug
Help:
The current value of the PMCD debug flags.  This is a bit-wise OR of the
flags described in the output of pmdbg -l.  The PMCD-specific flags are:

    DBG_TRACE_APPL0       2048  Trace agent & client I/O and termination
    DBG_TRACE_APPL1       4096  Trace host access control
    DBG_TRACE_APPL2       8192  Trace config file scanner and parser

It is possible to store values into this metric, see the -ol options for
pmdbg(1) to help determine appropriate values for the debug flags.

Diagnostic output is written to the PMCD log file (usually
$PCP_LOG_DIR/pmcd/pmcd.log).

pmcd.control.timeout
Help:
PDU exchanges with agents (PMDAs) managed by PMCD are subject to timeouts
which detect and clean up slow or disfunctional agents.  This metric
returns the current timeout period in seconds being used for the agents.
If the value is zero, timeouts are not being used.  This corresponds to
the -t option described in the man page, pmcd(1).

It is possible to store a new timeout value into this metric.  Storing zero
will turn off timeouts.  Subsequent storing of a non-zero value will turn
on the timeouts again.

pmcd.control.register
Help:
A vector of 16 32-bit registers that are identified by the instance
identifiers 0 through 15.

The register contents are initially zero, but may be subsequently
modified to be an arbitrary value using pmStore(3) or pmstore(1).

The values are not used internally, but rather act as a repository into
which operational information might be stored, and then exported to
modify the behavior of client programs, e.g. inhibit pmie(1) rule
firing, or trigger a status indicator.  In this way,
pmcd.control.register acts like a primitive bulletin board.

Example use might be as follows
    register[0]	telephone no. of person assigned to current system problem
    register[1]	telephone no. of person assigned to current network problem
    register[2]	ORACLE database is down
    register[3]	backup in progress
    register[4]	shopping days to Christmas

pmcd.control.traceconn
Help:
Set to 1 to enable PMCD event tracing for all connection-related
events for clients and PMDAs.

Set to 0 to disable PMCD connection event tracing.

pmcd.control.tracepdu
Help:
Set to 1 to enable PMCD event tracing for all PDUs sent and received
by PMCD.

Set to 0 to disable PMCD PDU event tracing.

pmcd.control.tracenobuf
Help:
Set to 1 to enable unbuffered PMCD event tracing, where each event is
reported as it happens.

Set to 0 to enable buffering of PMCD event traces (this is the default),
and event traces will only be dumped or reported when an error occurs or
a value is stored into the PCP metric pmcd.control.dumptrace.

pmcd.control.tracebufs
Help:
Defaults to 20.  May be changed dynamically.

pmcd.control.dumptrace
Help:
Storing any value into this metric causes the PMCD event trace buffers to
be dumped to PMCD's log file.

pmcd.control.dumpconn
Help:
Storing any value into this metric causes the details of the current PMCD
client connections to be dumped to PMCD's log file.

pmcd.control.sighup
Help:
Storing any value into this metric causes PMCD to be reset by sending
itself a SIGHUP signal.

On reset (either by storing into pmcd.control.sighup or by sending PMCD a
SIGHUP directly), PMCD will restart any failed PMDAs and reload the PMNS
if it has been changed.

pmcd.pdu_in.error
Help:
Running total of BINARY mode ERROR PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.result
Help:
Running total of BINARY mode RESULT PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.profile
Help:
Running total of BINARY mode PROFILE PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.fetch
Help:
Running total of BINARY mode FETCH PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.desc_req
Help:
Running total of BINARY mode DESC_REQ PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.desc
Help:
Running total of BINARY mode DESC PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.instance_req
Help:
Running total of BINARY mode INSTANCE_REQ PDUs received by the PMCD
from clients and agents.

pmcd.pdu_in.instance
Help:
Running total of BINARY mode INSTANCE PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.text_req
Help:
Running total of BINARY mode TEXT_REQ PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.text
Help:
Running total of BINARY mode TEXT PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.control_req
Help:
Running total of BINARY mode CONTROL_REQ PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.creds
Help:
Running total of BINARY mode CREDS PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.pmns_ids
Help:
Running total of BINARY mode PMNS_IDS PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.pmns_names
Help:
Running total of BINARY mode PMNS_NAMES PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.pmns_child
Help:
Running total of BINARY mode PMNS_CHILD PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.total
Help:
Running total of all BINARY mode PDUs received by the PMCD from clients
and agents.

pmcd.pdu_in.pmns_traverse
Help:
Running total of BINARY mode PMNS_TRAVERSE PDUs received by the PMCD from
clients and agents.

pmcd.pdu_in.auth
Help:
Running total of BINARY mode AUTH PDUs received by PMCD from
clients and agents.  These PDUs are used for authentication.

pmcd.pdu_in.label_req
Help:
Running total of BINARY mode LABEL_REQ PDUs received by PMCD from
clients and agents.  These PDUs are used to request metric metadata
labels.

pmcd.pdu_in.label
Help:
Running total of BINARY mode LABEL PDUs received by PMCD from
clients and agents.  These PDUs are used to send custom metric
metadata in the form of name:value pairs (labels).

pmcd.pdu_out.error
Help:
Running total of BINARY mode ERROR PDUs sent by the PMCD to clients and
agents.

pmcd.pdu_out.result
Help:
Running total of BINARY mode RESULT PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.profile
Help:
Running total of BINARY mode PROFILE PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.fetch
Help:
Running total of BINARY mode FETCH PDUs sent by the PMCD to clients and
agents.

pmcd.pdu_out.desc_req
Help:
Running total of BINARY mode DESC_REQ PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.desc
Help:
Running total of BINARY mode DESC PDUs sent by the PMCD to clients and
agents.

pmcd.pdu_out.instance_req
Help:
Running total of BINARY mode INSTANCE_REQ PDUs sent by the PMCD to
clients and agents.

pmcd.pdu_out.instance
Help:
Running total of BINARY mode INSTANCE PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.text_req
Help:
Running total of BINARY mode TEXT_REQ PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.text
Help:
Running total of BINARY mode TEXT PDUs sent by the PMCD to clients and
agents.

pmcd.pdu_out.control_req
Help:
Running total of BINARY mode CONTROL_REQ PDUs sent by the PMCD to
clients and agents.

pmcd.pdu_out.creds
Help:
Running total of BINARY mode CREDS PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.pmns_ids
Help:
Running total of BINARY mode PMNS_IDS PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.pmns_names
Help:
Running total of BINARY mode PMNS_NAMES PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.pmns_child
Help:
Running total of BINARY mode PMNS_CHILD PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.total
Help:
Running total of all BINARY mode PDUs sent by the PMCD to clients and
agents.

pmcd.pdu_out.pmns_traverse
Help:
Running total of BINARY mode PMNS_TRAVERSE PDUs sent by the PMCD to clients
and agents.

pmcd.pdu_out.auth
Help:
Running total of BINARY mode AUTH PDUs sent by the PMCD to clients
and agents.  These PDUs are used for authentication.

pmcd.pdu_out.label_req
Help:
Running total of BINARY mode LABEL_REQ PDUs sent by the PMCD to clients
and agents.  These are used to request metadata labels (name:value pairs).

pmcd.pdu_out.label
Help:
Running total of BINARY mode LABEL PDUs sent by the PMCD to clients
and agents.  These are used to send metadata labels (name:value pairs).

pmcd.agent.type
Help:
From $PCP_PMCDCONF_PATH, this metric encodes the PMDA type as follows:
	(x << 1) | y
where "x" is the IPC type between PMCD and the PMDA, i.e. 0 for DSO, 1
for socket or 2 for pipe, and "y" is the message passing style, i.e.
0 for binary or 1 for ASCII.

pmcd.agent.status
Help:
This metric encodes the current status of each PMDA.  The default value
is 0 if the PMDA is active.

Other values encode various degrees of PMDA difficulty in three bit fields
(bit 0 is the low-order bit) as follows:

bits 7..0
    1   the PMDA is connected, but not yet "ready" to accept requests
        from the PMDA
    2   the PMDA has exited of its own accord
    4   some error prevented the PMDA being started
    8   PMCD stopped communication with the PMDA due to a protocol or
        timeout error

bits 15..8
        the exit() status from the PMDA

bits 23..16
        the number of the signal that terminated the PMDA

pmcd.agent.fenced
Help:
A value of zero indicates not enabled, one indicates that operations
requiring fetch-level access controls are currently being denied and
PM_ERR_PMDAFENCED error code returned, for each PMDA.

The fence status is initially zero for all PMDAs, but may be subsequently
modified to start and stop fencing using pmStore(3) or pmstore(1).  Note:
only root may store to this metric and the PMCD PMDA cannot be fenced (it
will be silently ignored if attempted).

pmcd.pmlogger.host
Help:
The fully qualified domain name of the host on which a pmlogger
instance is running.

The instance names are process IDs of the active pmloggers.  The
primary pmlogger has an extra instance with the instance name "primary"
and an instance ID of zero (in addition to its normal process ID
instance).

pmcd.pmlogger.port
Help:
Each pmlogger instance has a port for receiving log control
information.  This metric is a list of the active pmlogger control
ports on the same machine as this PMCD (i.e. the host identified in the
corresponding pmcd.pmlogger.host metric).

The instance names are process IDs of the active pmloggers.  The
primary pmlogger has an extra instance with the instance name "primary"
and an instance ID of zero (in addition to its normal process ID
instance).

pmcd.pmlogger.archive
Help:
The full pathname through the filesystem on the corresponding host
(pmcd.pmlogger.host) that is the base name for the archive log files.

The instance names are process IDs of the active pmloggers.  The
primary pmlogger has an extra instance with the instance name "primary"
and an instance ID of zero (in addition to its normal process ID
instance).

pmcd.pmlogger.pmcd_host
Help:
The fully qualified domain name of the host from which a pmlogger
instance is fetching metrics to be archived.

The instance names are process IDs of the active pmloggers.  The
primary pmlogger has an extra instance with the instance name "primary"
and an instance ID of zero (in addition to its normal process ID
instance).

pmcd.pmie.configfile
Help:
The full path in the filesystem to the configuration file containing the
rules being evaluated by each pmie instance.

If the configuration file was supplied on the standard input, then this
metric will have the value "<stdin>".  If multiple configuration files were
given to pmie, then the value of this metric will be the first configuration
file specified.

pmcd.pmie.logfile
Help:
The file to which each instance of pmie is writting events.  No two pmie
instances can share the same log file.  If no logfile was specified when
pmie was started, this metrics has the value "<none>".  All daemon pmie
instances started through pmie_check(1) must have an associated log file.

pmcd.pmie.pmcd_host
Help:
The default host from which pmie is fetching metrics.  This is either the
hostname given to pmie on the command line or the local host.  Note that this
does not consider host names specified in the pmie configuration file (these
are considered non-default and can be more than one per pmie instance).
All daemon pmie instances started through pmie_check(1) will have their
default host passed in on their command line.

pmcd.pmie.numrules
Help:
The total number of rules being evaluated by each pmie process.

pmcd.pmie.actions
Help:
A cumulative count of the evaluated pmie rules which have evaluated to true.

This value is incremented once each time an action is executed.  This value
will always be less than or equal to pmcd.pmie.eval.true because predicates
which have evaluated to true may be suppressed in the action part of the
pmie rule, in which case this counter will not be incremented.

pmcd.pmie.eval.true
Help:
The predicate part of a pmie rule can be said to evaluate to either true,
false, or not known.  This metric is a cumulative count of the number of
rules which have evaluated to true for each pmie instance.

pmcd.pmie.eval.false
Help:
The predicate part of a pmie rule can be said to evaluate to either true,
false, or not known.  This metric is a cumulative count of the number of
rules which have evaluated to false for each pmie instance.

pmcd.pmie.eval.unknown
Help:
The predicate part of a pmie rule can be said to evaluate to either true,
false, or not known.  This metric is a cumulative count of the number of
rules which have not been successfully evaluated.  This could be due to not
yet having sufficient values to evaluate the rule, or a metric fetch may
have been unsuccessful in retrieving current values for metrics required
for evaluation of the rule.

pmcd.pmie.eval.expected
Help:
This is the expected rate of evaluation of pmie rules.  The value is
calculated once when pmie starts, and is the number of pmie rules divided
by the average time interval over which they are to be evaluated.

pmcd.pmie.eval.actual
Help:
A cumulative count of the pmie rules which have been evaluated.

This value is incremented once for each evaluation of each rule.

pmcd.buf.alloc
Help:
This metric returns the number of allocated buffers for the various buffer
pools used by pmcd.

This is handy for tracing memory utilization (and leaks) in DSOs during
development.

pmcd.buf.free
Help:
This metric returns the number of free buffers for the various buffer
pools used by pmcd.

This is handy for tracing memory utilization (and leaks) in DSOs during
development.

pmcd.client.whoami
Help:
This metric is defined over an instance domain containing one entry
per active client of pmcd.  The instance number is a sequence number
for each client (restarts at 0 each time pmcd is restarted).  The value
of the metric by default is the IP address of the client.

Clients can optionally use pmStore to modify their own "whoami" string
to provide more useful information about the client.

pmcd.client.start_date
Help:
The date and time in ctime(2) format on which the client connected
to pmcd.

pmcd.client.container
Help:
The name of the container (if any) associated with this context at
the time of the fetch request.  The container name can be set when
establishing a PMAPI context, or by storing into this metric using
the pmStore interface.

pmcd.cputime.total
Help:
Sum of user and system time since pmcd started.

pmcd.cputime.per_pdu_in
Help:
When first requested it is the average since pmcd started, so
pmcd.cputime.total divided by pmcd.pdu_in.total.

Subsequent fetches by a PMAPI client will return the average CPU
time per PDU received by pmcd (for all clients) since the last time
the PMAPI client fetched this metric.

pmcd.feature.secure
Help:
A value of zero indicates no support, one indicates actively available
(including configuration and validity of the server side certificates).

pmcd.feature.compress
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.ipv6
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.authentication
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.creds_required
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.unix_domain_sockets
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.service_discovery
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.containers
Help:
A value of zero indicates no support, one indicates actively available.

pmcd.feature.local
Help:
A value of zero indicates not enabled, one indicates the localhost-only
mode of operation is active.

pmcd.feature.client_cert_required
Help:
A value of zero indicates not required, one indicates required.

pmproxy.control.files
Help:
Count of currently mapped and exported statistics files.

pmproxy.control.debug
Help:
See pmdbg(1).  pmstore into this metric to change the debug value.

pmproxy.control.reload
Help:
Writing anything other then 0 to this metric will result in
re-reading directory and re-mapping files.

cgroup.subsys.hierarchy
Help:
subsystem hierarchy from /proc/cgroups

cgroup.subsys.count
Help:
count of known subsystems in /proc/cgroups

cgroup.subsys.num_cgroups
Help:
number of cgroups for each subsystem

cgroup.subsys.enabled
Help:
state of cgroups subsystems in the kernel

cgroup.mounts.subsys
Help:
mount points for each cgroup subsystem

cgroup.mounts.count
Help:
count of cgroup filesystem mount points

cgroup.cpu.stat.user
Help:
Time spent by tasks of the cgroup in user mode

cgroup.cpu.stat.system
Help:
Time spent by tasks of the cgroup in kernel mode

cgroup.cpu.stat.usage
Help:
CPU time consumed by processes in each cgroup

cgroup.cpuset.cpus
Help:
CPUs assigned to each individual cgroup

cgroup.cpuset.mems
Help:
Memory nodes assigned to each individual cgroup

cgroup.cpuset.id.container
Help:
Each cpuset cgroups container based on heuristics

cgroup.cpuacct.usage
Help:
CPU time consumed by processes in each cgroup

cgroup.cpuacct.usage_percpu
Help:
Per-CPU time consumed by processes in each cgroup

cgroup.cpuacct.stat.user
Help:
Time spent by tasks of the cgroup in user mode

cgroup.cpuacct.stat.system
Help:
Time spent by tasks of the cgroup in kernel mode

cgroup.cpuacct.id.container
Help:
Each cpuacct cgroups container based on heuristics

cgroup.cpusched.shares
Help:
Scheduler fairness CPU time division for each cgroup - details in
Documentation/scheduler/sched-design-CFS.txt in the kernel source.

cgroup.cpusched.periods
Help:
Scheduler group bandwidth enforcement interfaces that have elapsed,
refer to Documentation/scheduler/sched-bwc.txt in the kernel source.

cgroup.cpusched.throttled
Help:
Scheduler group bandwidth throttle/limit count - further discussion
in Documentation/scheduler/sched-bwc.txt in the kernel source.

cgroup.cpusched.throttled_time
Help:
The total time duration (in nanoseconds) for which entities of the
group have been throttled by the CFS scheduler - refer to discussion
in Documentation/scheduler/sched-bwc.txt in the kernel source.

cgroup.cpusched.cfs_period
Help:
The bandwidth allowed for a CFS group is specified using a quota and period.
Within each given "period" (usec), a group is allowed to consume only up to
"quota" usec of CPU time.  When the CPU bandwidth consumption of a group
exceeds this limit (for that period), the tasks belonging to its hierarchy
will be throttled and are not allowed to run again until the next period.
Further discussion in Documentation/scheduler/sched-bwc.txt in the kernel
sources.

cgroup.cpusched.cfs_quota
Help:
The bandwidth allowed for a CFS group is specified using a quota and period.
Within each given "period" (usec), a group is allowed to consume only up to
"quota" usec of CPU time.  When the CPU bandwidth consumption of a group
exceeds this limit (for that period), the tasks belonging to its hierarchy
will be throttled and are not allowed to run again until the next period.

A value of -1 indicates that the group does not have bandwidth restriction
in place.  Refer to discussion in Documentation/scheduler/sched-bwc.txt in
the kernel source.

cgroup.cpusched.id.container
Help:
Each cpusched cgroups container based on heuristics

cgroup.memory.usage
Help:
Current physical memory accounted to each cgroup

cgroup.memory.limit
Help:
Maximum memory that can be utilized by each cgroup

cgroup.memory.failcnt
Help:
Count of failures to allocate memory due to cgroup limit

cgroup.memory.stat.cache
Help:
Number of bytes of page cache memory

cgroup.memory.stat.rss
Help:
Anonymous and swap memory (incl transparent hugepages)

cgroup.memory.stat.rss_huge
Help:
Anonymous transparent hugepages

cgroup.memory.stat.mapped_file
Help:
Bytes of mapped file (incl tmpfs/shmem)

cgroup.memory.stat.writeback
Help:
Bytes of file/anonymous cache queued for syncing

cgroup.memory.stat.swap
Help:
Number of bytes of swap usage

cgroup.memory.stat.pgpgin
Help:
Number of charging events to the memory cgroup. The charging event happens
each time a page is accounted as either mapped anon page(RSS) or cache page
(Page Cache) to the cgroup.

cgroup.memory.stat.pgpgout
Help:
The uncharging event happens each time a page is unaccounted from
the cgroup.

cgroup.memory.stat.pgfault
Help:
Total number of page faults

cgroup.memory.stat.pgmajfault
Help:
Number of major page faults

cgroup.memory.stat.inactive_anon
Help:
Anonymous and swap cache memory on inactive LRU list

cgroup.memory.stat.active_anon
Help:
Anonymous and swap cache memory on active LRU list.

cgroup.memory.stat.inactive_file
Help:
File-backed memory on inactive LRU list

cgroup.memory.stat.active_file
Help:
File-backed memory on active LRU list

cgroup.memory.stat.unevictable
Help:
Memory that cannot be reclaimed (e.g. mlocked)

cgroup.memory.stat.anon
Help:
Anonymous memory

cgroup.memory.stat.anon_thp
Help:
Anonymous memory in transparent huge pages for each cgroup

cgroup.memory.stat.file
Help:
Bytes of cached file data total for each cgroup

cgroup.memory.stat.file_dirty
Help:
Bytes of dirty cached file data for each cgroup

cgroup.memory.stat.file_mapped
Help:
Bytes of mapped file data for each cgroup

cgroup.memory.stat.file_writeback
Help:
Bytes of file data under writeback for each cgroup

cgroup.memory.stat.kernel_stack
Help:
Bytes of kernel stack memory for each cgroup

cgroup.memory.stat.pgactivate
Help:
Activated pages for each cgroup

cgroup.memory.stat.pgdeactivate
Help:
Deactivated pages for each cgroup

cgroup.memory.stat.pglazyfree
Help:
Pages being lazily freed for each cgroup

cgroup.memory.stat.pglazyfreed
Help:
Pages lazily freed for each cgroup

cgroup.memory.stat.pgrefill
Help:
Refill pages for each cgroup

cgroup.memory.stat.pgscan
Help:
Scanned pages for each cgroup

cgroup.memory.stat.pgsteal
Help:
Steal pages for each cgroup

cgroup.memory.stat.shmem
Help:
Shared memory for each cgroup

cgroup.memory.stat.slab
Help:
Total slab pages for each cgroup

cgroup.memory.stat.slab_reclaimable
Help:
Reclaimable slab pages for each cgroup

cgroup.memory.stat.slab_unreclaimable
Help:
Unreclaimable slab pages for each cgroup

cgroup.memory.stat.sock
Help:
Pages in each cgroup used for sockets

cgroup.memory.stat.thp_collapse_alloc
Help:
Transparent huge page collapses for each cgroup

cgroup.memory.stat.thp_fault_alloc
Help:
Transparent huge page faults for each cgroup

cgroup.memory.stat.total.cache
Help:
Hierarchical, cumulative version of stat.cache

cgroup.memory.stat.total.rss
Help:
Hierarchical, cumulative version of stat.rss

cgroup.memory.stat.total.rss_huge
Help:
Hierarchical, cumulative version of stat.rss_huge

cgroup.memory.stat.total.mapped_file
Help:
Hierarchical, cumulative version of stat.mapped_file

cgroup.memory.stat.total.writeback
Help:
Hierarchical, cumulative version of stat.writeback

cgroup.memory.stat.total.swap
Help:
Hierarchical, cumulative version of stat.swap

cgroup.memory.stat.total.pgpgin
Help:
Hierarchical, cumulative version of stat.pgpgin

cgroup.memory.stat.total.pgpgout
Help:
Hierarchical, cumulative version of stat.pgpgout

cgroup.memory.stat.total.pgfault
Help:
Hierarchical, cumulative version of stat.pgfault

cgroup.memory.stat.total.pgmajfault
Help:
Hierarchical, cumulative version of stat.pgmajfault

cgroup.memory.stat.total.inactive_anon
Help:
Hierarchical, cumulative version of stat.inactive_anon

cgroup.memory.stat.total.active_anon
Help:
Hierarchical, cumulative version of stat.active_anon

cgroup.memory.stat.total.inactive_file
Help:
Hierarchical, cumulative version of stat.inactive_file

cgroup.memory.stat.total.active_file
Help:
Hierarchical, cumulative version of stat.active_file

cgroup.memory.stat.total.unevictable
Help:
Hierarchical, cumulative version of stat.unevictable

cgroup.memory.stat.recent.rotated_anon
Help:
VM internal parameter (see mm/vmscan.c)

cgroup.memory.stat.recent.rotated_file
Help:
VM internal parameter (see mm/vmscan.c)

cgroup.memory.stat.recent.scanned_anon
Help:
VM internal parameter (see mm/vmscan.c)

cgroup.memory.stat.recent.scanned_file
Help:
VM internal parameter (see mm/vmscan.c)

cgroup.memory.stat.workingset.activate
Help:
Activated working set pages for each cgroup

cgroup.memory.stat.workingset.nodereclaim
Help:
Working set pages under NUMA node reclaim for each cgroup

cgroup.memory.stat.workingset.refault
Help:
Refault working set pages for each cgroup

cgroup.memory.id.container
Help:
Each memory cgroups container based on heuristics

cgroup.netclass.classid
Help:
Network classifier cgroup class identifiers

cgroup.netclass.id.container
Help:
Each netclass cgroups container based on heuristics

cgroup.blkio.dev.sectors
Help:
Per-cgroup total (read+write) sectors

cgroup.blkio.dev.time
Help:
Per-device, per-cgroup total (read+write) time

cgroup.blkio.dev.io_merged.read
Help:
Per-cgroup read merges

cgroup.blkio.dev.io_merged.write
Help:
Per-cgroup write merges

cgroup.blkio.dev.io_merged.sync
Help:
Per-cgroup synchronous merges 

cgroup.blkio.dev.io_merged.async
Help:
Per-cgroup asynchronous merges

cgroup.blkio.dev.io_merged.total
Help:
Per-cgroup total merge operations

cgroup.blkio.dev.io_queued.read
Help:
Per-cgroup queued read operations

cgroup.blkio.dev.io_queued.write
Help:
Per-cgroup queued write operations

cgroup.blkio.dev.io_queued.sync
Help:
Per-cgroup queued synchronous operations

cgroup.blkio.dev.io_queued.async
Help:
Per-cgroup queued asynchronous operations

cgroup.blkio.dev.io_queued.total
Help:
Per-cgroup total operations queued

cgroup.blkio.dev.io_service_bytes.read
Help:
Per-cgroup bytes transferred in reads

cgroup.blkio.dev.io_service_bytes.write
Help:
Per-cgroup bytes transferred to disk in writes

cgroup.blkio.dev.io_service_bytes.sync
Help:
Per-cgroup sync bytes transferred

cgroup.blkio.dev.io_service_bytes.async
Help:
Per-cgroup async bytes transferred

cgroup.blkio.dev.io_service_bytes.total
Help:
Per-cgroup total bytes transferred

cgroup.blkio.dev.io_serviced.read
Help:
Per-cgroup read operations serviced

cgroup.blkio.dev.io_serviced.write
Help:
Per-cgroup write operations serviced

cgroup.blkio.dev.io_serviced.sync
Help:
Per-cgroup sync operations serviced

cgroup.blkio.dev.io_serviced.async
Help:
Per-cgroup async operations serviced

cgroup.blkio.dev.io_serviced.total
Help:
Per-cgroup total operations serviced

cgroup.blkio.dev.io_service_time.read
Help:
Per-cgroup read IO service time

cgroup.blkio.dev.io_service_time.write
Help:
Per-cgroup write IO service time

cgroup.blkio.dev.io_service_time.sync
Help:
Per-cgroup sync IO service time

cgroup.blkio.dev.io_service_time.async
Help:
Per-cgroup async IO service time

cgroup.blkio.dev.io_service_time.total
Help:
Per-cgroup IO service time

cgroup.blkio.dev.io_wait_time.read
Help:
Per-cgroup read IO wait time

cgroup.blkio.dev.io_wait_time.write
Help:
Per-cgroup write IO wait time

cgroup.blkio.dev.io_wait_time.sync
Help:
Per-cgroup sync IO wait time

cgroup.blkio.dev.io_wait_time.async
Help:
Per-cgroup async IO wait time

cgroup.blkio.dev.io_wait_time.total
Help:
Per-cgroup total IO wait time

cgroup.blkio.dev.throttle.io_service_bytes.read
Help:
Per-cgroup throttle bytes transferred in reads

cgroup.blkio.dev.throttle.io_service_bytes.write
Help:
Per-cgroup throttle bytes transferred to disk in writes

cgroup.blkio.dev.throttle.io_service_bytes.sync
Help:
Per-cgroup throttle sync bytes transferred

cgroup.blkio.dev.throttle.io_service_bytes.async
Help:
Per-cgroup throttle async bytes transferred

cgroup.blkio.dev.throttle.io_service_bytes.total
Help:
Per-cgroup total throttle bytes transferred

cgroup.blkio.dev.throttle.io_serviced.read
Help:
Per-cgroup throttle read operations serviced

cgroup.blkio.dev.throttle.io_serviced.write
Help:
Per-cgroup throttle write operations serviced

cgroup.blkio.dev.throttle.io_serviced.sync
Help:
Per-cgroup throttle sync operations serviced

cgroup.blkio.dev.throttle.io_serviced.async
Help:
Per-cgroup throttle async operations serviced

cgroup.blkio.dev.throttle.io_serviced.total
Help:
Per-cgroup total throttle operations serviced

cgroup.blkio.all.sectors
Help:
Per-cgroup total (read+write) sectors

cgroup.blkio.all.time
Help:
Per-device, per-cgroup total (read+write) time

cgroup.blkio.all.io_merged.read
Help:
Per-cgroup read merges

cgroup.blkio.all.io_merged.write
Help:
Per-cgroup write merges

cgroup.blkio.all.io_merged.sync
Help:
Per-cgroup synchronous merges 

cgroup.blkio.all.io_merged.async
Help:
Per-cgroup asynchronous merges

cgroup.blkio.all.io_merged.total
Help:
Per-cgroup total merge operations

cgroup.blkio.all.io_queued.read
Help:
Per-cgroup queued read operations

cgroup.blkio.all.io_queued.write
Help:
Per-cgroup queued write operations

cgroup.blkio.all.io_queued.sync
Help:
Per-cgroup queued synchronous operations

cgroup.blkio.all.io_queued.async
Help:
Per-cgroup queued asynchronous operations

cgroup.blkio.all.io_queued.total
Help:
Per-cgroup total operations queued

cgroup.blkio.all.io_service_bytes.read
Help:
Per-cgroup bytes transferred in reads

cgroup.blkio.all.io_service_bytes.write
Help:
Per-cgroup bytes transferred to disk in writes

cgroup.blkio.all.io_service_bytes.sync
Help:
Per-cgroup sync bytes transferred

cgroup.blkio.all.io_service_bytes.async
Help:
Per-cgroup async bytes transferred

cgroup.blkio.all.io_service_bytes.total
Help:
Per-cgroup total bytes transferred

cgroup.blkio.all.io_serviced.read
Help:
Per-cgroup read operations serviced

cgroup.blkio.all.io_serviced.write
Help:
Per-cgroup write operations serviced

cgroup.blkio.all.io_serviced.sync
Help:
Per-cgroup sync operations serviced

cgroup.blkio.all.io_serviced.async
Help:
Per-cgroup async operations serviced

cgroup.blkio.all.io_serviced.total
Help:
Per-cgroup total operations serviced

cgroup.blkio.all.io_service_time.read
Help:
Per-cgroup read IO service time

cgroup.blkio.all.io_service_time.write
Help:
Per-cgroup write IO service time

cgroup.blkio.all.io_service_time.sync
Help:
Per-cgroup sync IO service time

cgroup.blkio.all.io_service_time.async
Help:
Per-cgroup async IO service time

cgroup.blkio.all.io_service_time.total
Help:
Per-cgroup IO service time

cgroup.blkio.all.io_wait_time.read
Help:
Per-cgroup read IO wait time

cgroup.blkio.all.io_wait_time.write
Help:
Per-cgroup write IO wait time

cgroup.blkio.all.io_wait_time.sync
Help:
Per-cgroup sync IO wait time

cgroup.blkio.all.io_wait_time.async
Help:
Per-cgroup async IO wait time

cgroup.blkio.all.io_wait_time.total
Help:
Per-cgroup total IO wait time

cgroup.blkio.all.throttle.io_service_bytes.read
Help:
Per-cgroup throttle bytes transferred in reads

cgroup.blkio.all.throttle.io_service_bytes.write
Help:
Per-cgroup throttle bytes transferred to disk in writes

cgroup.blkio.all.throttle.io_service_bytes.sync
Help:
Per-cgroup throttle sync bytes transferred

cgroup.blkio.all.throttle.io_service_bytes.async
Help:
Per-cgroup throttle async bytes transferred

cgroup.blkio.all.throttle.io_service_bytes.total
Help:
Per-cgroup throttle total bytes transferred

cgroup.blkio.all.throttle.io_serviced.read
Help:
Per-cgroup throttle read operations serviced

cgroup.blkio.all.throttle.io_serviced.write
Help:
Per-cgroup throttle write operations serviced

cgroup.blkio.all.throttle.io_serviced.sync
Help:
Per-cgroup throttle sync operations serviced

cgroup.blkio.all.throttle.io_serviced.async
Help:
Per-cgroup throttle async operations serviced

cgroup.blkio.all.throttle.io_serviced.total
Help:
Per-cgroup total throttle operations serviced

cgroup.blkio.id.container
Help:
Each blkio cgroups container based on heuristics

cgroup.pressure.cpu.some.avg10sec
Help:
Indicates the time in which at least some cgroup tasks stalled on CPU
resources over the last 10 seconds.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name cpu.pressure

cgroup.pressure.cpu.some.avg1min
Help:
Indicates the time in which at least some cgroup tasks stalled on CPU
resources over the last 1 minute.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name cpu.pressure

cgroup.pressure.cpu.some.avg5min
Help:
Indicates the time in which at least some cgroup tasks stalled on CPU
resources over the last 5 minutes.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name cpu.pressure

cgroup.pressure.cpu.some.total
Help:
Indicates the time in which at least some cgroup tasks stalled on CPU
resources (total time, cumulative).  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name cpu.pressure

cgroup.pressure.memory.some.avg10sec
Help:
Indicates the time in which at least some cgroup tasks stalled on memory
resources over the last 10 seconds.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.some.avg1min
Help:
Indicates the time in which at least some cgroup tasks stalled on memory
resources over the last 1 minute.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.some.avg5min
Help:
Indicates the time in which at least some cgroup tasks stalled on memory
resources over the last 5 minutes.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.some.total
Help:
The CPU time for which at least some cgroup tasks stalled on memory
resources.  Pressure stall information (PSI) from:
$ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.full.avg10sec
Help:
Indicates the time in which all cgroup tasks stalled on memory
resources over the last 10 seconds.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.full.avg1min
Help:
Indicates the time in which all cgroup tasks stalled on memory
resources over the last 1 minute.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.full.avg5min
Help:
Indicates the time in which all cgroup tasks stalled on memory
resources over the last 5 minutes.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.memory.full.total
Help:
The CPU time for which all cgroup tasks stalled on memory resources.
Pressure stall information (PSI) from:
$ find /sys/fs/cgroup -name memory.pressure

cgroup.pressure.io.some.avg10sec
Help:
Indicates the time in which at least some cgroup tasks stalled on IO
resources over the last 10 seconds.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.some.avg1min
Help:
Indicates the time in which at least some cgroup tasks stalled on IO
resources over the last 1 minute.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.some.avg5min
Help:
Indicates the time in which at least some cgroup tasks stalled on IO
resources over the last 5 minutes.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.some.total
Help:
The CPU time in which at least some cgroup tasks stalled on IO
resources.  Pressure stall information (PSI) from:
$ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.full.avg10sec
Help:
Indicates the time in which all cgroup tasks stalled on input/output
resources over the last 10 seconds.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.full.avg1min
Help:
Indicates the time in which all cgroup tasks stalled on input/output
resources over the last 1 minute.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.full.avg5min
Help:
Indicates the time in which all cgroup tasks stalled on input/output
resources over the last 5 minutes.  Pressure stall information (PSI)
from: $ find /sys/fs/cgroup -name io.pressure

cgroup.pressure.io.full.total
Help:
The CPU time in which all cgroup tasks stalled on IO resources.
Pressure stall information (PSI) from:
$ find /sys/fs/cgroup -name io.pressure

cgroup.io.stat.rbytes
Help:
Bytes read per-cgroup, per-device

cgroup.io.stat.wbytes
Help:
Bytes written per-cgroup, per-device

cgroup.io.stat.rios
Help:
Read operations per-cgroup, per-device

cgroup.io.stat.wios
Help:
Write operations per-cgroup, per-device

cgroup.io.stat.dbytes
Help:
Direct IO bytes per-cgroup, per-device

cgroup.io.stat.dios
Help:
Direct IO operations per-cgroup, per-device

hotproc.nprocs
Help:
instantaneous number of interesting ("hot") processes

hotproc.psinfo.oom_score
Help:
out-of-memory process selection score (from /proc/<pid>/oom_score)

hotproc.psinfo.tgid
Help:
thread group identifier

hotproc.psinfo.ngid
Help:
NUMA group identifier (from /proc/<pid>/status)

hotproc.psinfo.cpusallowed
Help:
the cpus allowed list (from /proc/<pid>/status)

hotproc.psinfo.nvctxsw
Help:
number of non-voluntary context switches (from /proc/<pid>/status)

hotproc.psinfo.vctxsw
Help:
number of voluntary context switches (from /proc/<pid>/status)

hotproc.psinfo.labels
Help:
list of processes security labels (from /proc/<pid>/attr/current)

hotproc.psinfo.cgroups
Help:
list of processes cgroups (from /proc/<pid>/cgroup)

hotproc.psinfo.threads
Help:
number of threads (from /proc/<pid>/status)

hotproc.psinfo.sigcatch_s
Help:
caught signals mask in string form (from /proc/<pid>/status)

hotproc.psinfo.sigignore_s
Help:
ignored signals mask in string form (from /proc/<pid>/status)

hotproc.psinfo.blocked_s
Help:
blocked signals mask in string form (from /proc/<pid>/status)

hotproc.psinfo.signal_s
Help:
pending signals mask in string form (from /proc/<pid>/status)

hotproc.psinfo.environ
Help:
process environment (from /proc/<pid>/environ ascii space replaces null).

hotproc.psinfo.cguest_time
Help:
Guest time of the processs children

hotproc.psinfo.guest_time
Help:
Time spent running a virtual CPU for a guest operating system.

hotproc.psinfo.delayacct_blkio_time
Help:
Aggregated block I/O delays

hotproc.psinfo.policy
Help:
Scheduling policy

hotproc.psinfo.rt_priority
Help:
Real-time scheduling priority, a number in the range 1 to 99

hotproc.psinfo.psargs
Help:
full command string

hotproc.psinfo.wchan_s
Help:
This field needs access to a namelist file for proper 
address-to-symbol name translation. If no namelist file
is available, the address is printed instead. The namelist
file must match the current Linux kernel exactly.
The search path for the namelist file is as follows:
	/boot/System.map-`uname -r`
	/boot/System.map
	/lib/modules/`uname -r`/System.map
	/usr/src/linux/System.map
	/System.map

hotproc.psinfo.ttyname
Help:
name of controlling tty device, or ? if none. See also proc.psinfo.tty.

hotproc.psinfo.processor
Help:
last CPU the process was running on

hotproc.psinfo.exit_signal
Help:
the value in the exit_signal field of struct task_struct for the process

hotproc.psinfo.cnswap
Help:
count of page swap operations of all exited children

hotproc.psinfo.nswap
Help:
count of page swap operations

hotproc.psinfo.wchan
Help:
wait channel, kernel address this process is blocked or sleeping on

hotproc.psinfo.sigcatch
Help:
the value in the sigcatch field of struct task_struct for the process

hotproc.psinfo.sigignore
Help:
the value in the sigignore field of struct task_struct for the process

hotproc.psinfo.blocked
Help:
the value in the blocked field of struct task_struct for the process

hotproc.psinfo.signal
Help:
the value in the signal field of struct task_struct for the process

hotproc.psinfo.eip
Help:
the value in the eip field of struct task_struct for the process

hotproc.psinfo.esp
Help:
the value in the esp field of struct task_struct for the process

hotproc.psinfo.start_stack
Help:
address of the stack segment for the process

hotproc.psinfo.end_code
Help:
address of the end of the code segment for the process

hotproc.psinfo.start_code
Help:
address of the start of the code segment for the process

hotproc.psinfo.rss_rlim
Help:
limit on resident set size of process

hotproc.psinfo.rss
Help:
resident set size (i.e. physical memory) of the process

hotproc.psinfo.vsize
Help:
virtual size of the process in Kbytes

hotproc.psinfo.start_time
Help:
start time of the process relative to system boot time (in ms)

hotproc.psinfo.it_real_value
Help:
current interval timer value (zero if none)

hotproc.psinfo.nice
Help:
process nice value (negative nice values are lower priority)

hotproc.psinfo.priority
Help:
scheduling priority value

hotproc.psinfo.cstime
Help:
time (in ms) spent executing system code of all exited children

hotproc.psinfo.cutime
Help:
time (in ms) spent executing user code of all exited children

hotproc.psinfo.stime
Help:
time (in ms) spent executing system code (calls) since process started

hotproc.psinfo.utime
Help:
time (in ms) spent executing user code since process started

hotproc.psinfo.cmaj_flt
Help:
count of page faults other than reclaims of all exited children

hotproc.psinfo.maj_flt
Help:
count of page faults other than reclaims

hotproc.psinfo.cmin_flt
Help:
count of minor page faults (i.e. reclaims) of all exited children

hotproc.psinfo.minflt
Help:
count of minor page faults (i.e. reclaims)

hotproc.psinfo.flags
Help:
process state flags, as a bitmap

hotproc.psinfo.tty_pgrp
Help:
controlling tty process group identifier

hotproc.psinfo.tty
Help:
controlling tty device number (zero if none)

hotproc.psinfo.session
Help:
process session identifier

hotproc.psinfo.pgrp
Help:
process group identifier

hotproc.psinfo.ppid
Help:
parent process identifier

hotproc.psinfo.sname
Help:
process state identifier (see ps(1)). See also proc.runq metrics.

hotproc.psinfo.cmd
Help:
command name

hotproc.psinfo.pid
Help:
process identifier

hotproc.memory.vmnonlib
Help:
difference between process real memory use (vmreal) and libraries (vmlib)

hotproc.memory.vmreal
Help:
sum of resident set size and virtual memory swapped out

hotproc.memory.vmpte
Help:
memory occupied by page table entries (from /proc/<pid>/status)

hotproc.memory.vmhwm
Help:
peak usage of physical memory (from /proc/<pid>/status)

hotproc.memory.vmpin
Help:
fixed physical address unswappable pages (from /proc/<pid>/status)

hotproc.memory.vmpeak
Help:
peak virtual memory size (from /proc/<pid>/status)

hotproc.memory.vmswap
Help:
virtual memory size currently swapped out (from /proc/<pid>/status)

hotproc.memory.vmlib
Help:
virtual memory used for libraries (from /proc/<pid>/status)

hotproc.memory.vmexe
Help:
virtual memory used for non-library executable code (from /proc/<pid>/status)

hotproc.memory.vmstack
Help:
virtual memory used for stack (from /proc/<pid>/status)

hotproc.memory.vmdata
Help:
virtual memory used for data (from /proc/<pid>/status)

hotproc.memory.vmrss
Help:
resident virtual memory (from /proc/<pid>/status)

hotproc.memory.vmlock
Help:
locked virtual memory (from /proc/<pid>/status)

hotproc.memory.vmsize
Help:
total virtual memory (from /proc/<pid>/status)

hotproc.memory.maps
Help:
table of memory mapped by process in string form from /proc/<pid>/maps

hotproc.memory.dirty
Help:
instantaneous amount of memory that has been modified by the process, in Kbytes

hotproc.memory.datrss
Help:
instantaneous resident size of process data segment, in Kbytes

hotproc.memory.librss
Help:
instantaneous resident size of library code mapped by the process, in Kbytes

hotproc.memory.textrss
Help:
instantaneous resident size of process code segment in Kbytes

hotproc.memory.share
Help:
instantaneous amount of memory shared by this process with other processes 

hotproc.memory.rss
Help:
instantaneous resident size of process, excluding page table and task structure.

hotproc.memory.size
Help:
instantaneous virtual size of process, excluding page table and task structure.

hotproc.id.container
Help:
name of processes container (from /proc/<pid>/cgroup heuristics)

hotproc.id.fsgid_nm
Help:
filesystem group name based on filesystem group ID from /proc/<pid>/status

hotproc.id.sgid_nm
Help:
saved group name based on saved group ID from /proc/<pid>/status

hotproc.id.egid_nm
Help:
effective group name based on effective group ID from /proc/<pid>/status

hotproc.id.gid_nm
Help:
real group name based on real group ID from /proc/<pid>/status

hotproc.id.fsuid_nm
Help:
filesystem user name based on filesystem user ID from /proc/<pid>/status

hotproc.id.suid_nm
Help:
saved user name based on saved user ID from /proc/<pid>/status

hotproc.id.euid_nm
Help:
effective user name based on effective user ID from /proc/<pid>/status

hotproc.id.uid_nm
Help:
real user name based on real user ID from /proc/<pid>/status

hotproc.id.fsgid
Help:
filesystem group ID from /proc/<pid>/status

hotproc.id.sgid
Help:
saved group ID from /proc/<pid>/status

hotproc.id.egid
Help:
effective group ID from /proc/<pid>/status

hotproc.id.gid
Help:
real group ID from /proc/<pid>/status

hotproc.id.fsuid
Help:
filesystem user ID from /proc/<pid>/status

hotproc.id.suid
Help:
saved user ID from /proc/<pid>/status

hotproc.id.euid
Help:
effective user ID from /proc/<pid>/status

hotproc.id.uid
Help:
real user ID from /proc/<pid>/status

hotproc.io.cancelled_write_bytes
Help:
Number of bytes cancelled via truncate by this process.  Actual physical
writes for an individual process can be calculated as:
	proc.io.write_bytes - proc.io.cancelled_write_bytes.

hotproc.io.write_bytes
Help:
Number of bytes physically written to devices on behalf of this process.
This must be reduced by any truncated I/O (proc.io.cancelled_write_bytes).

hotproc.io.read_bytes
Help:
Number of bytes physically read on by devices on behalf of this process.

hotproc.io.syscw
Help:
Extended accounting information - count of number of calls to the
write(2), writev(2) and sendfile(2) syscalls by each process.

hotproc.io.syscr
Help:
Extended accounting information - count of number of calls to the
read(2), readv(2) and sendfile(2) syscalls by each process.

hotproc.io.wchar
Help:
Extended accounting information - count of the number of bytes that
have passed over the write(2), writev(2) and sendfile(2) syscalls by
each process.

hotproc.io.rchar
Help:
Extended accounting information - count of the number of bytes that
have passed over the read(2), readv(2) and sendfile(2) syscalls by
each process.

hotproc.schedstat.pcount
Help:
Number of times a process has been scheduled to run on a CPU (this is
incremented when a task actually reaches a CPU to run on, not simply
when it is added to the run queue).

hotproc.schedstat.run_delay
Help:
Length of time in nanoseconds that a process spent waiting to be scheduled
to run in the run queue.

hotproc.schedstat.cpu_time
Help:
Length of time in nanoseconds that a process has been running, including
scheduling time.

hotproc.fd.count
Help:
Number of file descriptors this process has open.

hotproc.namespaces.envid
Help:
OpenVZ container identifier

hotproc.namespaces.sid
Help:
descendant namespace session ID hierarchy (/proc/<pid>/status)

hotproc.namespaces.pgid
Help:
descendant namespace process group ID hierarchy (/proc/<pid>/status)

hotproc.namespaces.pid
Help:
descendant namespace process ID hierarchy (/proc/<pid>/status)

hotproc.namespaces.tgid
Help:
descendant namespace thread group ID hierarchy (/proc/<pid>/status)

hotproc.control.refresh
Help:
Controls how long it takes before the "interesting" process list is refreshed
and new cpuburn times (see hotproc.cpuburn) calculated.  This value can be
changed at any time by using pmstore(1). Once the value is changed, the instances
will not be available until after the new refresh period has elapsed.

hotproc.control.config
Help:
The configuration predicate that is used to characterize "interesting"
processes.  This will initially be the predicate as specified in the
configuration file.  This value can be changed at any time by using
pmstore(1).  Once the value is changed, the instances will not be available
until after the refresh period has elapsed.

hotproc.control.config_gen
Help:
Each time the configuration predicate is updated (see hotproc.control.config)
the configuration generation number is incremented.

hotproc.control.reload_config
Help:
Instructs the pmda to reload its configuration file.  This value can be
changed at any time by using pmstore(1). Once the value is changed, the instances
will not be available until after the new refresh period has elapsed.

hotproc.total.cpuidle
Help:
The fraction of all CPU time classified as idle over the last refresh
interval.

hotproc.total.cpuburn
Help:
The sum of the CPU utilization ("cpuburn" or the fraction of time that each
process was executing in user or system mode over the last refresh interval)
for all the "interesting" processes.

Values are in the range 0 to the number of CPUs.

hotproc.total.cpuother.transient
Help:
The total CPU utilization (fraction of time that each process was executing
in user or system mode) for processes which are not present throughout
the most recent refreshes interval.  The hotproc PMDA is limited to
selecting processes which are present throughout each refresh intervals.
If processes come and/or go during a refresh interval then they will never
be considered.  This metric gives an indication of the level of activity of
these "transient" processes.  If the value is large in comparison to the
sum of hotproc.total.cpuburn and hotproc.total.cpuother.not_cpuburn then
the "transient" processes are consuming lots of CPU time.  Under these
circumstances, the hotproc PMDA may be less useful, or consideration
should be given to decreasing the value of the refresh interval
(hotproc.control.refresh) so fewer "transient" processes escape
consideration.

Values are in the range 0 to the number of CPUs.

hotproc.total.cpuother.not_cpuburn
Help:
The sum of the CPU utilization ("cpuburn" or the fraction of time that
each process was executing in user or system mode over the last refresh
interval) for all the "uninteresting" processes.  If this value is high in
comparison to hotproc.total.cpuburn, then configuration predicate of the
hotproc PMDA is classifying a significant fraction of the CPU utilization
to processes that are not "interesting".

Values are in the range 0 to the number of CPUs.

hotproc.total.cpuother.total
Help:
Non-idle CPU utilization not accounted for by processes other than those
deemed "interesting".  It is equivalent to hotproc.total.cpuother.not_cpuburn
+ hotproc.total.cpuother.transient.

Values are in the range 0 to the number of CPUs.

hotproc.total.cpuother.percent
Help:
Gives an indication of how much of the CPU time the "transient" processes
and the "uninteresting" processes are accounting for.  Computed as:
    100 * hotproc.total.cpuother.total / number of CPUs

hotproc.predicate.ctxswitch
Help:
The number of context switches per second over the last refresh interval
for each "interesting" process.

hotproc.predicate.virtualsize
Help:
The virtual size of each "interesting" process in kilobytes at the last
refresh time.

hotproc.predicate.residentsize
Help:
The resident size of each "interesting" process in kilobytes at the last
refresh.

hotproc.predicate.iodemand
Help:
The total kilobytes read and written per second over the last refresh
interval for each "interesting" process.

hotproc.predicate.iowait
Help:
The fraction of time waiting for I/O for each "interesting" process over
refresh interval.

hotproc.predicate.schedwait
Help:
The fraction of time waiting on the run queue for each "interesting"
process over the last refresh interval.

hotproc.predicate.cpuburn
Help:
CPU utilization, or the fraction of time that each "interesting" process
was executing (user and system time) over the last refresh interval.
Also known as the "cpuburn" time.

containers.engine
Help:
technology backing each container (e.g. docker)

containers.name
Help:
mapping of unique container IDs to human-readable names

containers.pid
Help:
process identifier for each containers initial process

containers.cgroup
Help:
path mapping container names to their cgroups

containers.state.running
Help:
this container is currently running (one/zero)

containers.state.paused
Help:
this container is currently paused (one/zero)

containers.state.restarting
Help:
this container is restarting (one/zero)

xfs.write
Help:
This is the number of write(2) system calls made to files in
XFS file systems.

xfs.write_bytes
Help:
This is the number of bytes written via write(2) system calls to files
in XFS file systems. It can be used in conjunction with the write_calls
count to calculate the average size of the write operations to files in
XFS file systems.

xfs.read
Help:
This is the number of read(2) system calls made to files in XFS file
systems.

xfs.read_bytes
Help:
This is the number of bytes read via read(2) system calls to files in
XFS file systems. It can be used in conjunction with the read_calls
count to calculate the average size of the read operations to files in
XFS file systems.

xfs.iflush_count
Help:
This is the number of calls to xfs_iflush which gets called when an
inode is being flushed (such as by bdflush or tail pushing).
xfs_iflush searches for other inodes in the same cluster which are
dirty and flushable.

xfs.icluster_flushcnt
Help:
value from xs_icluster_flushcnt field of struct xfsstats

xfs.icluster_flushinode
Help:
This is the number of times that the inode clustering was not able to
flush anything but the one inode it was called with.

xfs.allocs.alloc_extent
Help:
Number of file system extents allocated over XFS filesystems

xfs.allocs.alloc_block
Help:
Number of file system blocks allocated over XFS filesystems

xfs.allocs.free_extent
Help:
Number of file system extents freed over XFS filesystems

xfs.allocs.free_block
Help:
Number of file system blocks freed over XFS filesystems

xfs.alloc_btree.lookup
Help:
Number of lookup operations in XFS filesystem allocation btrees

xfs.alloc_btree.compare
Help:
Number of compares in XFS filesystem allocation btree lookups

xfs.alloc_btree.insrec
Help:
Number of extent records inserted into XFS filesystem allocation btrees

xfs.alloc_btree.delrec
Help:
Number of extent records deleted from XFS filesystem allocation btrees

xfs.block_map.read_ops
Help:
Number of block map for read operations performed on XFS files

xfs.block_map.write_ops
Help:
Number of block map for write operations performed on XFS files

xfs.block_map.unmap
Help:
Number of block unmap (delete) operations performed on XFS files

xfs.block_map.add_exlist
Help:
Number of extent list insertion operations for XFS files

xfs.block_map.del_exlist
Help:
Number of extent list deletion operations for XFS files

xfs.block_map.look_exlist
Help:
Number of extent list lookup operations for XFS files

xfs.block_map.cmp_exlist
Help:
Number of extent list comparisons in XFS extent list lookups

xfs.bmap_btree.lookup
Help:
Number of block map btree lookup operations on XFS files

xfs.bmap_btree.compare
Help:
Number of block map btree compare operations in XFS block map lookups

xfs.bmap_btree.insrec
Help:
Number of block map btree records inserted for XFS files

xfs.bmap_btree.delrec
Help:
Number of block map btree records deleted for XFS files

xfs.dir_ops.lookup
Help:
This is a count of the number of file name directory lookups in XFS
filesystems. It counts only those lookups which miss in the operating
system's directory name lookup cache and must search the real directory
structure for the name in question.  The count is incremented once for
each level of a pathname search that results in a directory lookup.

xfs.dir_ops.create
Help:
This is the number of times a new directory entry was created in XFS
filesystems. Each time that a new file, directory, link, symbolic link,
or special file is created in the directory hierarchy the count is
incremented.

xfs.dir_ops.remove
Help:
This is the number of times an existing directory entry was removed in
XFS filesystems. Each time that a file, directory, link, symbolic link,
or special file is removed from the directory hierarchy the count is
incremented.

xfs.dir_ops.getdents
Help:
This is the number of times the XFS directory getdents operation was
performed. The getdents operation is used by programs to read the
contents of directories in a file system independent fashion.  This
count corresponds exactly to the number of times the getdents(2) system
call was successfully used on an XFS directory.

xfs.transactions.sync
Help:
This is the number of meta-data transactions which waited to be
committed to the on-disk log before allowing the process performing the
transaction to continue. These transactions are slower and more
expensive than asynchronous transactions, because they force the in
memory log buffers to be forced to disk more often and they wait for
the completion of the log buffer writes.

xfs.transactions.async
Help:
This is the number of meta-data transactions which did not wait to be
committed to the on-disk log before allowing the process performing the
transaction to continue. These transactions are faster and more
efficient than synchronous transactions, because they commit their data
to the in memory log buffers without forcing those buffers to be
written to disk. This allows multiple asynchronous transactions to be
committed to disk in a single log buffer write. Most transactions used
in XFS file systems are asynchronous.

xfs.transactions.empty
Help:
This is the number of meta-data transactions which did not actually
change anything. These are transactions which were started for some
purpose, but in the end it turned out that no change was necessary.

xfs.inode_ops.ig_attempts
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache. Whether the inode was found in the cache or
needed to be read in from the disk is not indicated here, but this can
be computed from the ig_found and ig_missed counts.

xfs.inode_ops.ig_found
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and found it. The closer this count is to the
ig_attempts count the better the inode cache is performing.

xfs.inode_ops.ig_frecycle
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and saw that it was there but was unable to
use the in memory inode because it was being recycled by another
process.

xfs.inode_ops.ig_missed
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and the inode was not there. The further this
count is from the ig_attempts count the better.

xfs.inode_ops.ig_dup
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and found that it was not there but upon
attempting to add the inode to the cache found that another process had
already inserted it.

xfs.inode_ops.ig_reclaims
Help:
This is the number of times the operating system recycled an XFS inode
from the inode cache in order to use the memory for that inode for
another purpose. Inodes are recycled in order to keep the inode cache
from growing without bound. If the reclaim rate is high it may be
beneficial to raise the vnode_free_ratio kernel tunable variable to
increase the size of inode cache.

xfs.inode_ops.ig_attrchg
Help:
This is the number of times the operating system explicitly changed the
attributes of an XFS inode. For example, this could be to change the
inode's owner, the inode's size, or the inode's timestamps.

xfs.log.writes
Help:
This variable counts the number of log buffer writes going to the
physical log partitions of XFS filesystems. Log data traffic is
proportional to the level of meta-data updating. Log buffer writes get
generated when they fill up or external syncs occur.

xfs.log.blocks
Help:
This variable counts the number of Kbytes of information being written
to the physical log partitions of XFS filesystems. Log data traffic
is proportional to the level of meta-data updating. The rate with which
log data gets written depends on the size of internal log buffers and
disk write speed. Therefore, filesystems with very high meta-data
updating may need to stripe the log partition or put the log partition
on a separate drive.

xfs.log.write_ratio
Help:
The ratio of log blocks written to log writes.  If block count isn't a
"reasonable" multiple of writes, then many small log writes are being
performed - this is suboptimal.  Perfection is 64.  Fine-grain control
can be obtained when this metric is used in conjuntion with pmstore(1)
and the xfs.control.reset metric.

xfs.log.noiclogs
Help:
This variable keeps track of times when a logged transaction can not
get any log buffer space. When this occurs, all of the internal log
buffers are busy flushing their data to the physical on-disk log.

xfs.log.force
Help:
The number of times the in-core log is forced to disk.  It is
equivalent to the number of successful calls to the function
xfs_log_force().

xfs.log.force_sleep
Help:
This metric is exported from the xs_log_force_sleep field of struct xfsstats

xfs.log_tail.try_logspace
Help:
This metric is exported from the xs_try_logspace field of struct xfsstats

xfs.log_tail.sleep_logspace
Help:
This metric is exported from the xs_sleep_logspace field of struct xfsstats

xfs.log_tail.push_ail.pushes
Help:
The number of times the tail of the AIL is moved forward.  It is
equivalent to the number of successful calls to the function
xfs_trans_push_ail().

xfs.log_tail.push_ail.success
Help:
value from xs_push_ail_success field of struct xfsstats

xfs.log_tail.push_ail.pushbuf
Help:
value from xs_push_ail_pushbuf field of struct xfsstats

xfs.log_tail.push_ail.pinned
Help:
value from xs_push_ail_pinned field of struct xfsstats

xfs.log_tail.push_ail.locked
Help:
value from xs_push_ail_locked field of struct xfsstats

xfs.log_tail.push_ail.flushing
Help:
value from xs_push_ail_flushing field of struct xfsstats

xfs.log_tail.push_ail.restarts
Help:
value from xs_push_ail_restarts field of struct xfsstats

xfs.log_tail.push_ail.flush
Help:
value from xs_push_ail_flush field of struct xfsstats

xfs.xstrat.bytes
Help:
This is the number of bytes of file data flushed out by the XFS
flushing daemons.

xfs.xstrat.quick
Help:
This is the number of buffers flushed out by the XFS flushing daemons
which are written to contiguous space on disk. The buffers handled by
the XFS daemons are delayed allocation buffers, so this count gives an
indication of the success of the XFS daemons in allocating contiguous
disk space for the data being flushed to disk.

xfs.xstrat.split
Help:
This is the number of buffers flushed out by the XFS flushing daemons
which are written to non-contiguous space on disk. The buffers handled
by the XFS daemons are delayed allocation buffers, so this count gives
an indication of the failure of the XFS daemons in allocating
contiguous disk space for the data being flushed to disk. Large values
in this counter indicate that the file system has become fragmented.

xfs.attr.get
Help:
The number of "get" operations performed on extended file attributes
within XFS filesystems.  The "get" operation retrieves the value of an
extended attribute.

xfs.attr.set
Help:
The number of "set" operations performed on extended file attributes
within XFS filesystems.  The "set" operation creates and sets the value
of an extended attribute.

xfs.attr.remove
Help:
The number of "remove" operations performed on extended file attributes
within XFS filesystems.  The "remove" operation deletes an extended
attribute.

xfs.attr.list
Help:
The number of "list" operations performed on extended file attributes
within XFS filesystems.  The "list" operation retrieves the set of
extended attributes associated with a file.

xfs.quota.reclaims
Help:
value from xs_qm_dqreclaims field of struct xfsstats

xfs.quota.reclaim_misses
Help:
value from xs_qm_dqreclaim_misses field of struct xfsstats

xfs.quota.dquot_dups
Help:
value from xs_qm_dquot_dups field of struct xfsstats

xfs.quota.cachemisses
Help:
value from xs_qm_dqcachemisses field of struct xfsstats

xfs.quota.cachehits
Help:
value from xs_qm_dqcachehits field of struct xfsstats

xfs.quota.wants
Help:
value from xs_qm_dqwants field of struct xfsstats

xfs.quota.shake_reclaims
Help:
value from xs_qm_dqshake_reclaims field of struct xfsstats

xfs.quota.inact_reclaims
Help:
value from xs_qm_dqinact_reclaims field of struct xfsstats

xfs.buffer.get
Help:
number of request buffer calls

xfs.buffer.create
Help:
number of buffers created

xfs.buffer.get_locked
Help:
number of requests for a locked buffer which succeeded

xfs.buffer.get_locked_waited
Help:
number of requests for a locked buffer which waited

xfs.buffer.busy_locked
Help:
number of non-blocking requests for a locked buffer which failed

xfs.buffer.miss_locked
Help:
number of requests for a locked buffer which failed due to no buffer

xfs.buffer.page_retries
Help:
number of retry attempts when allocating a page for insertion in a buffer

xfs.buffer.page_found
Help:
number of hits in the page cache when looking for a page

xfs.buffer.get_read
Help:
number of buffer get calls requiring immediate device reads

xfs.vnodes.active
Help:
number of vnodes not on free lists

xfs.vnodes.alloc
Help:
number of times vn_alloc called

xfs.vnodes.get
Help:
number of times vn_get called

xfs.vnodes.hold
Help:
number of times vn_hold called

xfs.vnodes.rele
Help:
number of times vn_rele called

xfs.vnodes.reclaim
Help:
number of times vn_reclaim called

xfs.vnodes.remove
Help:
number of times vn_remove called

xfs.vnodes.free
Help:
number of times vn_free called

xfs.control.reset
Help:
reset the values of all XFS metrics to zero

xfs.btree.alloc_blocks.lookup
Help:
Number of free-space-by-block-number btree record lookups

xfs.btree.alloc_blocks.compare
Help:
Number of free-space-by-block-number btree record compares

xfs.btree.alloc_blocks.insrec
Help:
Number of free-space-by-block-number btree insert record operations executed

xfs.btree.alloc_blocks.delrec
Help:
Number of free-space-by-block-number btree delete record operations executed

xfs.btree.alloc_blocks.newroot
Help:
Number of times a new level is added to a free-space-by-block-number btree

xfs.btree.alloc_blocks.killroot
Help:
Number of times a level is removed from a free-space-by-block-number btree

xfs.btree.alloc_blocks.increment
Help:
Number of times a cursor has been moved forward one free-space-by-block-number
btree record

xfs.btree.alloc_blocks.decrement
Help:
Number of times a cursor has been moved backward one free-space-by-block-number
btree record

xfs.btree.alloc_blocks.lshift
Help:
Left shift block operations to make space for a new free-space-by-block-number
btree record

xfs.btree.alloc_blocks.rshift
Help:
Right shift block operations to make space for a new free-space-by-block-number
btree record

xfs.btree.alloc_blocks.split
Help:
Split block operations to make space for a new free-space-by-block-number
btree record

xfs.btree.alloc_blocks.join
Help:
Merge block operations when deleting free-space-by-block-number btree records

xfs.btree.alloc_blocks.alloc
Help:
Btree block allocations during free-space-by-block-number btree operations

xfs.btree.alloc_blocks.free
Help:
Btree blocks freed during free-space-by-block-number btree operations

xfs.btree.alloc_blocks.moves
Help:
Records moved inside blocks during free-space-by-block-number btree operations

xfs.btree.alloc_contig.lookup
Help:
Number of free-space-by-size btree record lookups

xfs.btree.alloc_contig.compare
Help:
Number of free-space-by-size btree btree record compares

xfs.btree.alloc_contig.insrec
Help:
Number of free-space-by-size btree insert record operations executed

xfs.btree.alloc_contig.delrec
Help:
Number of free-space-by-size btree delete record operations executed

xfs.btree.alloc_contig.newroot
Help:
Number of times a new level is added to a free-space-by-size btree tree

xfs.btree.alloc_contig.killroot
Help:
Number of times a level is removed from a free-space-by-size btree tree

xfs.btree.alloc_contig.increment
Help:
Number of times a free-space-by-size btree cursor has been moved forward
one record

xfs.btree.alloc_contig.decrement
Help:
Number of times a free-space-by-size btree cursor has been moved backward
one record

xfs.btree.alloc_contig.lshift
Help:
Left shift block operations to make space for a new free-space-by-size
btree record

xfs.btree.alloc_contig.rshift
Help:
Right shift block operations to make space for a new free-space-by-size
btree record

xfs.btree.alloc_contig.split
Help:
Split block operations to make space for a new free-space-by-size btree
record

xfs.btree.alloc_contig.join
Help:
Merge block operations when deleting free-space-by-size btree records

xfs.btree.alloc_contig.alloc
Help:
Btree block allocations during free-space-by-size btree operations

xfs.btree.alloc_contig.free
Help:
Btree blocks freed during free-space-by-size btree operations

xfs.btree.alloc_contig.moves
Help:
Records moved inside blocks during free-space-by-size btree operations

xfs.btree.block_map.lookup
Help:
Number of inode-block-map/extent btree record lookups

xfs.btree.block_map.compare
Help:
Number of inode-block-map/extent btree record compares

xfs.btree.block_map.insrec
Help:
Number of inode-block-map/extent btree insert record operations executed

xfs.btree.block_map.delrec
Help:
Number of inode-block-map/extent btree delete record operations executed

xfs.btree.block_map.newroot
Help:
Number of times a new level is added to an inode-block-map/extent btree

xfs.btree.block_map.killroot
Help:
Number of times a level is removed from an inode-block-map/extent btree

xfs.btree.block_map.increment
Help:
Number of times an inode-block-map/extent btree cursor has been moved
forward one record

xfs.btree.block_map.decrement
Help:
Number of times an inode-block-map/extent btree cursor has been moved
backward one record

xfs.btree.block_map.lshift
Help:
Left shift block operations to make space for a new inode-block-map/extent
btree record

xfs.btree.block_map.rshift
Help:
Right shift block operations to make space for a new inode-block-map/extent
btree record

xfs.btree.block_map.split
Help:
Split block operations to make space for a new inode-block-map/extent
btree record

xfs.btree.block_map.join
Help:
Merge block operations when deleting inode-block-map/extent btree records

xfs.btree.block_map.alloc
Help:
Btree block allocations during inode-block-map/extent btree operations

xfs.btree.block_map.free
Help:
Btree blocks freed during inode-block-map/extent btree operations

xfs.btree.block_map.moves
Help:
Records moved inside blocks during inode-block-map/extent btree operations

xfs.btree.inode.lookup
Help:
Number of inode-allocation btree record lookups

xfs.btree.inode.compare
Help:
Number of inode-allocation btree record compares

xfs.btree.inode.insrec
Help:
Number of inode-allocation btree insert record operations executed

xfs.btree.inode.delrec
Help:
Number of inode-allocation btree delete record operations executed

xfs.btree.inode.newroot
Help:
Number of times a new level is added to an inode-allocation btree

xfs.btree.inode.killroot
Help:
Number of times a level is removed from an inode-allocation btree

xfs.btree.inode.increment
Help:
Number of times a cursor has been moved forward one inode-allocation
btree record

xfs.btree.inode.decrement
Help:
Number of times a cursor has been moved backward one inode-allocation
btree record

xfs.btree.inode.lshift
Help:
Left shift block operations to make space for a new inode-allocation
btree record

xfs.btree.inode.rshift
Help:
Right shift block operations to make space for a new inode-allocation
btree record

xfs.btree.inode.split
Help:
Split block operations to make space for a new inode-allocation btree record

xfs.btree.inode.join
Help:
Merge block operations when deleting inode-allocation btree records

xfs.btree.inode.alloc
Help:
Btree block allocations during inode-allocation btree operations

xfs.btree.inode.free
Help:
Btree blocks freed during inode-allocation btree operations

xfs.btree.inode.moves
Help:
Records moved inside blocks during inode-allocation btree operations

xfs.perdev.write
Help:
This is the number of write(2) system calls made to files in
XFS file systems.

xfs.perdev.write_bytes
Help:
This is the number of bytes written via write(2) system calls to files
in XFS file systems. It can be used in conjunction with the write_calls
count to calculate the average size of the write operations to files in
XFS file systems.

xfs.perdev.read
Help:
This is the number of read(2) system calls made to files in XFS file
systems.

xfs.perdev.read_bytes
Help:
This is the number of bytes read via read(2) system calls to files in
XFS file systems. It can be used in conjunction with the read_calls
count to calculate the average size of the read operations to files in
XFS file systems.

xfs.perdev.iflush_count
Help:
This is the number of calls to xfs_iflush which gets called when an
inode is being flushed (such as by bdflush or tail pushing).
xfs_iflush searches for other inodes in the same cluster which are
dirty and flushable.

xfs.perdev.icluster_flushcnt
Help:
value from xs_icluster_flushcnt field of struct xfsstats

xfs.perdev.icluster_flushinode
Help:
This is the number of times that the inode clustering was not able to
flush anything but the one inode it was called with.

xfs.perdev.allocs.alloc_extent
Help:
Number of file system extents allocated over XFS filesystems

xfs.perdev.allocs.alloc_block
Help:
Number of file system blocks allocated over XFS filesystems

xfs.perdev.allocs.free_extent
Help:
Number of file system extents freed over XFS filesystems

xfs.perdev.allocs.free_block
Help:
Number of file system blocks freed over XFS filesystems

xfs.perdev.alloc_btree.lookup
Help:
Number of lookup operations in XFS filesystem allocation btrees

xfs.perdev.alloc_btree.compare
Help:
Number of compares in XFS filesystem allocation btree lookups

xfs.perdev.alloc_btree.insrec
Help:
Number of extent records inserted into XFS filesystem allocation btrees

xfs.perdev.alloc_btree.delrec
Help:
Number of extent records deleted from XFS filesystem allocation btrees

xfs.perdev.block_map.read_ops
Help:
Number of block map for read operations performed on XFS files

xfs.perdev.block_map.write_ops
Help:
Number of block map for write operations performed on XFS files

xfs.perdev.block_map.unmap
Help:
Number of block unmap (delete) operations performed on XFS files

xfs.perdev.block_map.add_exlist
Help:
Number of extent list insertion operations for XFS files

xfs.perdev.block_map.del_exlist
Help:
Number of extent list deletion operations for XFS files

xfs.perdev.block_map.look_exlist
Help:
Number of extent list lookup operations for XFS files

xfs.perdev.block_map.cmp_exlist
Help:
Number of extent list comparisons in XFS extent list lookups

xfs.perdev.bmap_btree.lookup
Help:
Number of block map btree lookup operations on XFS files

xfs.perdev.bmap_btree.compare
Help:
Number of block map btree compare operations in XFS block map lookups

xfs.perdev.bmap_btree.insrec
Help:
Number of block map btree records inserted for XFS files

xfs.perdev.bmap_btree.delrec
Help:
Number of block map btree records deleted for XFS files

xfs.perdev.dir_ops.lookup
Help:
This is a count of the number of file name directory lookups in XFS
filesystems. It counts only those lookups which miss in the operating
system's directory name lookup cache and must search the real directory
structure for the name in question.  The count is incremented once for
each level of a pathname search that results in a directory lookup.

xfs.perdev.dir_ops.create
Help:
This is the number of times a new directory entry was created in XFS
filesystems. Each time that a new file, directory, link, symbolic link,
or special file is created in the directory hierarchy the count is
incremented.

xfs.perdev.dir_ops.remove
Help:
This is the number of times an existing directory entry was removed in
XFS filesystems. Each time that a file, directory, link, symbolic link,
or special file is removed from the directory hierarchy the count is
incremented.

xfs.perdev.dir_ops.getdents
Help:
This is the number of times the XFS directory getdents operation was
performed. The getdents operation is used by programs to read the
contents of directories in a file system independent fashion.  This
count corresponds exactly to the number of times the getdents(2) system
call was successfully used on an XFS directory.

xfs.perdev.transactions.sync
Help:
This is the number of meta-data transactions which waited to be
committed to the on-disk log before allowing the process performing the
transaction to continue. These transactions are slower and more
expensive than asynchronous transactions, because they force the in
memory log buffers to be forced to disk more often and they wait for
the completion of the log buffer writes.

xfs.perdev.transactions.async
Help:
This is the number of meta-data transactions which did not wait to be
committed to the on-disk log before allowing the process performing the
transaction to continue. These transactions are faster and more
efficient than synchronous transactions, because they commit their data
to the in memory log buffers without forcing those buffers to be
written to disk. This allows multiple asynchronous transactions to be
committed to disk in a single log buffer write. Most transactions used
in XFS file systems are asynchronous.

xfs.perdev.transactions.empty
Help:
This is the number of meta-data transactions which did not actually
change anything. These are transactions which were started for some
purpose, but in the end it turned out that no change was necessary.

xfs.perdev.inode_ops.ig_attempts
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache. Whether the inode was found in the cache or
needed to be read in from the disk is not indicated here, but this can
be computed from the ig_found and ig_missed counts.

xfs.perdev.inode_ops.ig_found
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and found it. The closer this count is to the
ig_attempts count the better the inode cache is performing.

xfs.perdev.inode_ops.ig_frecycle
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and saw that it was there but was unable to
use the in memory inode because it was being recycled by another
process.

xfs.perdev.inode_ops.ig_missed
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and the inode was not there. The further this
count is from the ig_attempts count the better.

xfs.perdev.inode_ops.ig_dup
Help:
This is the number of times the operating system looked for an XFS
inode in the inode cache and found that it was not there but upon
attempting to add the inode to the cache found that another process had
already inserted it.

xfs.perdev.inode_ops.ig_reclaims
Help:
This is the number of times the operating system recycled an XFS inode
from the inode cache in order to use the memory for that inode for
another purpose. Inodes are recycled in order to keep the inode cache
from growing without bound. If the reclaim rate is high it may be
beneficial to raise the vnode_free_ratio kernel tunable variable to
increase the size of inode cache.

xfs.perdev.inode_ops.ig_attrchg
Help:
This is the number of times the operating system explicitly changed the
attributes of an XFS inode. For example, this could be to change the
inode's owner, the inode's size, or the inode's timestamps.

xfs.perdev.log.writes
Help:
This variable counts the number of log buffer writes going to the
physical log partitions of XFS filesystems. Log data traffic is
proportional to the level of meta-data updating. Log buffer writes get
generated when they fill up or external syncs occur.

xfs.perdev.log.blocks
Help:
This variable counts the number of Kbytes of information being written
to the physical log partitions of XFS filesystems. Log data traffic
is proportional to the level of meta-data updating. The rate with which
log data gets written depends on the size of internal log buffers and
disk write speed. Therefore, filesystems with very high meta-data
updating may need to stripe the log partition or put the log partition
on a separate drive.

xfs.perdev.log.write_ratio
Help:
The ratio of log blocks written to log writes.  If block count isn't a
"reasonable" multiple of writes, then many small log writes are being
performed - this is suboptimal.  Perfection is 64.  Fine-grain control
can be obtained when this metric is used in conjuntion with pmstore(1)
and the xfs.control.reset metric.

xfs.perdev.log.noiclogs
Help:
This variable keeps track of times when a logged transaction can not
get any log buffer space. When this occurs, all of the internal log
buffers are busy flushing their data to the physical on-disk log.

xfs.perdev.log.force
Help:
The number of times the in-core log is forced to disk.  It is
equivalent to the number of successful calls to the function
xfs_log_force().

xfs.perdev.log.force_sleep
Help:
This metric is exported from the xs_log_force_sleep field of struct xfsstats

xfs.perdev.log_tail.try_logspace
Help:
This metric is exported from the xs_try_logspace field of struct xfsstats

xfs.perdev.log_tail.sleep_logspace
Help:
This metric is exported from the xs_sleep_logspace field of struct xfsstats

xfs.perdev.log_tail.push_ail.pushes
Help:
The number of times the tail of the AIL is moved forward.  It is
equivalent to the number of successful calls to the function
xfs_trans_push_ail().

xfs.perdev.log_tail.push_ail.success
Help:
value from xs_push_ail_success field of struct xfsstats

xfs.perdev.log_tail.push_ail.pushbuf
Help:
value from xs_push_ail_pushbuf field of struct xfsstats

xfs.perdev.log_tail.push_ail.pinned
Help:
value from xs_push_ail_pinned field of struct xfsstats

xfs.perdev.log_tail.push_ail.locked
Help:
value from xs_push_ail_locked field of struct xfsstats

xfs.perdev.log_tail.push_ail.flushing
Help:
value from xs_push_ail_flushing field of struct xfsstats

xfs.perdev.log_tail.push_ail.restarts
Help:
value from xs_push_ail_restarts field of struct xfsstats

xfs.perdev.log_tail.push_ail.flush
Help:
value from xs_push_ail_flush field of struct xfsstats

xfs.perdev.xstrat.bytes
Help:
This is the number of bytes of file data flushed out by the XFS
flushing daemons.

xfs.perdev.xstrat.quick
Help:
This is the number of buffers flushed out by the XFS flushing daemons
which are written to contiguous space on disk. The buffers handled by
the XFS daemons are delayed allocation buffers, so this count gives an
indication of the success of the XFS daemons in allocating contiguous
disk space for the data being flushed to disk.

xfs.perdev.xstrat.split
Help:
This is the number of buffers flushed out by the XFS flushing daemons
which are written to non-contiguous space on disk. The buffers handled
by the XFS daemons are delayed allocation buffers, so this count gives
an indication of the failure of the XFS daemons in allocating
contiguous disk space for the data being flushed to disk. Large values
in this counter indicate that the file system has become fragmented.

xfs.perdev.attr.get
Help:
The number of "get" operations performed on extended file attributes
within XFS filesystems.  The "get" operation retrieves the value of an
extended attribute.

xfs.perdev.attr.set
Help:
The number of "set" operations performed on extended file attributes
within XFS filesystems.  The "set" operation creates and sets the value
of an extended attribute.

xfs.perdev.attr.remove
Help:
The number of "remove" operations performed on extended file attributes
within XFS filesystems.  The "remove" operation deletes an extended
attribute.

xfs.perdev.attr.list
Help:
The number of "list" operations performed on extended file attributes
within XFS filesystems.  The "list" operation retrieves the set of
extended attributes associated with a file.

xfs.perdev.quota.reclaims
Help:
value from xs_qm_dqreclaims field of struct xfsstats

xfs.perdev.quota.reclaim_misses
Help:
value from xs_qm_dqreclaim_misses field of struct xfsstats

xfs.perdev.quota.dquot_dups
Help:
value from xs_qm_dquot_dups field of struct xfsstats

xfs.perdev.quota.cachemisses
Help:
value from xs_qm_dqcachemisses field of struct xfsstats

xfs.perdev.quota.cachehits
Help:
value from xs_qm_dqcachehits field of struct xfsstats

xfs.perdev.quota.wants
Help:
value from xs_qm_dqwants field of struct xfsstats

xfs.perdev.quota.shake_reclaims
Help:
value from xs_qm_dqshake_reclaims field of struct xfsstats

xfs.perdev.quota.inact_reclaims
Help:
value from xs_qm_dqinact_reclaims field of struct xfsstats

xfs.perdev.buffer.get
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.create
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.get_locked
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.get_locked_waited
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.busy_locked
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.miss_locked
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.page_retries
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.page_found
Full Help: Error: One-line or help text is not available

xfs.perdev.buffer.get_read
Full Help: Error: One-line or help text is not available

xfs.perdev.vnodes.active
Help:
number of vnodes not on free lists

xfs.perdev.vnodes.alloc
Help:
number of times vn_alloc called

xfs.perdev.vnodes.get
Help:
number of times vn_get called

xfs.perdev.vnodes.hold
Help:
number of times vn_hold called

xfs.perdev.vnodes.rele
Help:
number of times vn_rele called

xfs.perdev.vnodes.reclaim
Help:
number of times vn_reclaim called

xfs.perdev.vnodes.remove
Help:
number of times vn_remove called

xfs.perdev.vnodes.free
Help:
number of times vn_free called

xfs.perdev.btree.alloc_blocks.lookup
Help:
Number of free-space-by-block-number btree record lookups

xfs.perdev.btree.alloc_blocks.compare
Help:
Number of free-space-by-block-number btree record compares

xfs.perdev.btree.alloc_blocks.insrec
Help:
Number of free-space-by-block-number btree insert record operations executed

xfs.perdev.btree.alloc_blocks.delrec
Help:
Number of free-space-by-block-number btree delete record operations executed

xfs.perdev.btree.alloc_blocks.newroot
Help:
Number of times a new level is added to a free-space-by-block-number btree

xfs.perdev.btree.alloc_blocks.killroot
Help:
Number of times a level is removed from a free-space-by-block-number btree

xfs.perdev.btree.alloc_blocks.increment
Help:
Number of times a cursor has been moved forward one free-space-by-block-number
btree record

xfs.perdev.btree.alloc_blocks.decrement
Help:
Number of times a cursor has been moved backward one free-space-by-block-number
btree record

xfs.perdev.btree.alloc_blocks.lshift
Help:
Left shift block operations to make space for a new free-space-by-block-number
btree record

xfs.perdev.btree.alloc_blocks.rshift
Help:
Right shift block operations to make space for a new free-space-by-block-number
btree record

xfs.perdev.btree.alloc_blocks.split
Help:
Split block operations to make space for a new free-space-by-block-number
btree record

xfs.perdev.btree.alloc_blocks.join
Help:
Merge block operations when deleting free-space-by-block-number btree records

xfs.perdev.btree.alloc_blocks.alloc
Help:
Btree block allocations during free-space-by-block-number btree operations

xfs.perdev.btree.alloc_blocks.free
Help:
Btree blocks freed during free-space-by-block-number btree operations

xfs.perdev.btree.alloc_blocks.moves
Help:
Records moved inside blocks during free-space-by-block-number btree operations

xfs.perdev.btree.alloc_contig.lookup
Help:
Number of free-space-by-size btree record lookups

xfs.perdev.btree.alloc_contig.compare
Help:
Number of free-space-by-size btree btree record compares

xfs.perdev.btree.alloc_contig.insrec
Help:
Number of free-space-by-size btree insert record operations executed

xfs.perdev.btree.alloc_contig.delrec
Help:
Number of free-space-by-size btree delete record operations executed

xfs.perdev.btree.alloc_contig.newroot
Help:
Number of times a new level is added to a free-space-by-size btree tree

xfs.perdev.btree.alloc_contig.killroot
Help:
Number of times a level is removed from a free-space-by-size btree tree

xfs.perdev.btree.alloc_contig.increment
Help:
Number of times a free-space-by-size btree cursor has been moved forward
one record

xfs.perdev.btree.alloc_contig.decrement
Help:
Number of times a free-space-by-size btree cursor has been moved backward
one record

xfs.perdev.btree.alloc_contig.lshift
Help:
Left shift block operations to make space for a new free-space-by-size
btree record

xfs.perdev.btree.alloc_contig.rshift
Help:
Right shift block operations to make space for a new free-space-by-size
btree record

xfs.perdev.btree.alloc_contig.split
Help:
Split block operations to make space for a new free-space-by-size btree
record

xfs.perdev.btree.alloc_contig.join
Help:
Merge block operations when deleting free-space-by-size btree records

xfs.perdev.btree.alloc_contig.alloc
Help:
Btree block allocations during free-space-by-size btree operations

xfs.perdev.btree.alloc_contig.free
Help:
Btree blocks freed during free-space-by-size btree operations

xfs.perdev.btree.alloc_contig.moves
Help:
Records moved inside blocks during free-space-by-size btree operations

xfs.perdev.btree.block_map.lookup
Help:
Number of inode-block-map/extent btree record lookups

xfs.perdev.btree.block_map.compare
Help:
Number of inode-block-map/extent btree record compares

xfs.perdev.btree.block_map.insrec
Help:
Number of inode-block-map/extent btree insert record operations executed

xfs.perdev.btree.block_map.delrec
Help:
Number of inode-block-map/extent btree delete record operations executed

xfs.perdev.btree.block_map.newroot
Help:
Number of times a new level is added to an inode-block-map/extent btree

xfs.perdev.btree.block_map.killroot
Help:
Number of times a level is removed from an inode-block-map/extent btree

xfs.perdev.btree.block_map.increment
Help:
Number of times an inode-block-map/extent btree cursor has been moved
forward one record

xfs.perdev.btree.block_map.decrement
Help:
Number of times an inode-block-map/extent btree cursor has been moved
backward one record

xfs.perdev.btree.block_map.lshift
Help:
Left shift block operations to make space for a new inode-block-map/extent
btree record

xfs.perdev.btree.block_map.rshift
Help:
Right shift block operations to make space for a new inode-block-map/extent
btree record

xfs.perdev.btree.block_map.split
Help:
Split block operations to make space for a new inode-block-map/extent
btree record

xfs.perdev.btree.block_map.join
Help:
Merge block operations when deleting inode-block-map/extent btree records

xfs.perdev.btree.block_map.alloc
Help:
Btree block allocations during inode-block-map/extent btree operations

xfs.perdev.btree.block_map.free
Help:
Btree blocks freed during inode-block-map/extent btree operations

xfs.perdev.btree.block_map.moves
Help:
Records moved inside blocks during inode-block-map/extent btree operations

xfs.perdev.btree.inode.lookup
Help:
Number of inode-allocation btree record lookups

xfs.perdev.btree.inode.compare
Help:
Number of inode-allocation btree record compares

xfs.perdev.btree.inode.insrec
Help:
Number of inode-allocation btree insert record operations executed

xfs.perdev.btree.inode.delrec
Help:
Number of inode-allocation btree delete record operations executed

xfs.perdev.btree.inode.newroot
Help:
Number of times a new level is added to an inode-allocation btree

xfs.perdev.btree.inode.killroot
Help:
Number of times a level is removed from an inode-allocation btree

xfs.perdev.btree.inode.increment
Help:
Number of times a cursor has been moved forward one inode-allocation
btree record

xfs.perdev.btree.inode.decrement
Help:
Number of times a cursor has been moved backward one inode-allocation
btree record

xfs.perdev.btree.inode.lshift
Help:
Left shift block operations to make space for a new inode-allocation
btree record

xfs.perdev.btree.inode.rshift
Help:
Right shift block operations to make space for a new inode-allocation
btree record

xfs.perdev.btree.inode.split
Help:
Split block operations to make space for a new inode-allocation btree record

xfs.perdev.btree.inode.join
Help:
Merge block operations when deleting inode-allocation btree records

xfs.perdev.btree.inode.alloc
Help:
Btree block allocations during inode-allocation btree operations

xfs.perdev.btree.inode.free
Help:
Btree blocks freed during inode-allocation btree operations

xfs.perdev.btree.inode.moves
Help:
Records moved inside blocks during inode-allocation btree operations

quota.state.project.accounting
Help:
1 indicates quota accounting enabled, else 0

quota.state.project.enforcement
Help:
1 indicates quotas enforced, else 0

quota.project.space.hard
Help:
hard limit for this project and filesys in Kbytes

quota.project.space.soft
Help:
soft limit for this project and filesys in Kbytes

quota.project.space.used
Help:
space used for this project and filesys in Kbytes

quota.project.space.time_left
Help:
when soft limit is exceeded, seconds until it is enacted

quota.project.files.hard
Help:
file count hard limit for this project and filesys

quota.project.files.soft
Help:
file count soft limit for this project and filesys

quota.project.files.used
Help:
file count for this project and filesys

quota.project.files.time_left
Help:
when soft limit is exceeded, seconds until it is enacted

infiniband.hca.type
Help:
Node type: channel adapter (CA), switch, router etc

infiniband.hca.ca_type
Help:
HCA type, e.g. MT23108,

infiniband.hca.numports
Help:
Number of ports on HCA

infiniband.hca.fw_ver
Help:
Version of HCA firmware

infiniband.hca.hw_ver
Help:
Version of HCA hardware

infiniband.hca.node_guid
Help:
Node's Global Unique Identifier - 64 bit integer to refer to the node

infiniband.hca.system_guid
Help:
System's Global Unique Identifier - 64 bit integer to refer to the system

infiniband.port.guid
Help:
Port's Global Unique Identifier - 64 bit integer to refer to the port

infiniband.port.gid_prefix
Help:
GID prefix, assigned by subnet manager

infiniband.port.lid
Help:
Port's Local Identifier, assigned by subnet manager

infiniband.port.state
Help:
Port's state - can be Active, Down, NoChange, Armed or Initialize

infiniband.port.phystate
Help:
Port's physical state

infiniband.port.rate
Help:
Port's Data Rate: 2, 5, 10 or 20 Gbps

infiniband.port.capabilities
Help:
Port's capabilities.

infiniband.port.linkspeed
Help:
This is a string which represents the base link speed of the port.
Multiplying link speed by link width gives port's data rate.

infiniband.port.linkwidth
Help:
Number of bi-directional Infiniband links active on the port.
Also known as X-factor, as in 1X, 4X, 12X.

infiniband.port.in.bytes
Help:
Counter of data octets received on all VLs at the port. This 
includes all octets between (and not including) the start of 
packet delimiter and the VCRC, and may include packets containing errors.
It excludes all link packets. 

This counter is implemented by sampling underlying saturating PortRcvData 
counter. When a value of saturated counter reaches predefined threshold,
the counter is reset after its value is copied into internal state.

infiniband.port.in.packets
Help:
Counter of data packets received on all VLs at the port. This 
may include packets containing errors but excludes all link packets. 

infiniband.port.in.errors.drop
Help:
Number of packets received on the port that were discarded because they 
could not be forwarded by the switch relay due to DLID mapping, VL mapping
or looping. Implemented by sampling 16 bit PortRcvSwitchRelayErrors 
counter.

infiniband.port.in.errors.filter
Help:
Number of packets received by the port that were discarded because
it was a raw packet and FilterRawInbound is enabled or because 
PartitionEnforcementInbound is enabled and packet failed partition 
key check or IP version check. Implemented by sampling  8 bit 
PortRcvConstraintErrors counter.

infiniband.port.in.errors.local
Help:
Counter of packets containing local physical errors, malformed data or 
link packets or packets discarded due to buffer overrun. Implemented by
sampling 16 bit PortRcvErrors counter.

infiniband.port.in.errors.remote
Help:
Number of packets marked with End Bad Packet delimited received by
the port. Implemented by sampling 16 bit PortRcvRemotePhysicalerrors 
counter.

infiniband.port.out.bytes
Help:
Counter of data octets, transmitted on all VLs from the port. This 
includes all octets between (and not including) the start of 
packet delimiter and the VCRC, and may include packets containing errors.
It excludes all link packets. 

This counter is implemented by sampling underlying saturating PortXmtData 
counter. When a value of saturated counter reaches predefined threshold,
the counter is reset after its value is copied into internal state.

infiniband.port.out.packets
Help:
Counter of data packets transmitted on all VLs from the port. This 
may include packets containing errors but excludes all link packets. 

infiniband.port.out.errors.drop
Help:
Number of outbound packets which were droped because port is down
or congested. Implemented by sampling 16 bit PortXmtDiscard counter.

infiniband.port.out.errors.filter
Help:
Number of packets not transmitted by the port because
it was a raw packet and FilterRawInbound is enabled or because 
PartitionEnforcementInbound is enabled and packet failed partition 
key check or IP version check. Implemented by sampling  8 bit 
PortXmitConstraintErrors counter.

infiniband.port.total.bytes
Help:
Cumulative value of infiniband.port.in.bytes and 
infiniband.port.out.bytes, provided for convenience.

infiniband.port.total.packets
Help:
Cumulative value of infiniband.port.in.packets and 
infiniband.port.out.packets, provided for convenience.

infiniband.port.total.errors.drop
Help:
Cumulative counter of infiniband.port.in.errors.drop and 
infiniband.out.errors.drops.

infiniband.port.total.errors.filter
Help:
Cumulative counter of infiniband.port.in.errors.filter and 
infiniband.out.errors.filter.

infiniband.port.total.errors.link
Help:
Number of times Port Training state machine has failed to 
complete link recovery process and downed the link. Implemented by 
sampling 8 bit LinkDownedCounter.

infiniband.port.total.errors.recover
Help:
Number of times Port Training state machine has managed successfully
complete link recovery process. Implemented by sampling 8 bit 
LinkErrorRecoveryCounter.

infiniband.port.total.errors.integrity
Help:
Number of times the count of local physical errors exceeded the threshold.
Implemented by sampling 4 bit LocalLinkIntegrityErrors counter.

infiniband.port.total.errors.vl15
Help:
Number of times packets to VL15 (management virtual line) was dropped
due to resource limitations. Implemented by sampling 16 bit VL15Dropped
counter.

infiniband.port.total.errors.overrun
Help:
The number of times buffer overrun errors had persisted over multiple 
flow control update times.  Implemented by sampling 4 bit 
ExcessiveBufferOverrun counter.

infiniband.port.total.errors.symbol
Help:
Total number of minor link errors detected on one or more physical lines.
Implemented by sampling 16 bit SymbolErrorCounter.

infiniband.port.switch.in.bytes
Help:
Counter for the bytes received by a port. This is calculated using the counter
of the switch the port is attached to.

infiniband.port.switch.in.packets
Help:
Counter for the packets received by a port. This is calculated using the
counter of the switch the port is attached to.

infiniband.port.switch.out.bytes
Help:
Counter for the bytes transmitted by a port. This is calculated using the
counter of the switch the port is attached to.

infiniband.port.switch.out.packets
Help:
Counter for the packets transmitted by a port. This is calculated using the
counter of the switch the port is attached to.

infiniband.port.switch.total.bytes
Help:
Cumulative value of infiniband.port.switch.in.bytes and 
infiniband.port.switch.out.bytes, provided for convenience.

infiniband.port.switch.total.packets
Help:
Cumulative value of infiniband.port.switch.in.packets and 
infiniband.port.switch.out.packets, provided for convenience.

infiniband.control.query_timeout
Help:
Timeout in milliseconds for MAD rpcs. Default value is 1000 milliseconds.
Timeout can be set per port.

infiniband.control.hiwat
Help:
Threshold values for each MAD performance counter. Due to saturating
nature of the counters they're reset when value of a particular counter
gets above a threshold. Setting threshold to the maximum value disables
the reset mechanism.

lustre.lnet.drop_count
Help:
drop count

lustre.lnet.drop_length
Help:
drop bytes

lustre.lnet.recv_length
Help:
receive bytes

lustre.lnet.recv_count
Help:
receive count

lustre.lnet.errors
Help:
errors

lustre.lnet.send_length
Help:
transmit bytes

lustre.lnet.msgs_max
Help:
messages maximum

lustre.lnet.msgs_alloc
Help:
messages currently allocated

lustre.lnet.route_length
Help:
route bytes

lustre.lnet.send_count
Help:
transmit count

lustre.lnet.route_count
Help:
route count

lustre.llite.unlink.count
Help:
number of calls

lustre.llite.inode_permission.count
Help:
number of calls

lustre.llite.getxattr.count
Help:
number of calls

lustre.llite.ioctl.count
Help:
number of calls

lustre.llite.dirty_pages_misses.count
Help:
number of calls

lustre.llite.mknod.count
Help:
number of calls

lustre.llite.dirty_pages_hits.count
Help:
number of calls

lustre.llite.symlink.count
Help:
number of calls

lustre.llite.fsync.count
Help:
number of calls

lustre.llite.getxattr_hits.count
Help:
number of calls

lustre.llite.setattr.count
Help:
number of calls

lustre.llite.getattr.count
Help:
number of calls

lustre.llite.rename.count
Help:
number of calls

lustre.llite.superblock
Help:
Superblock Identifier

lustre.llite.seek.count
Help:
number of calls

lustre.llite.readdir.count
Help:
number of calls

lustre.llite.listxattr.count
Help:
number of calls

lustre.llite.mmap.count
Help:
number of calls

lustre.llite.setxattr.count
Help:
number of calls

lustre.llite.open.count
Help:
number of calls

lustre.llite.osc_read.max
Help:
maximum byte value seen in a call

lustre.llite.osc_read.total
Help:
total byte count

lustre.llite.osc_read.count
Help:
number of calls

lustre.llite.osc_read.min
Help:
minimum byte value seen in a call

lustre.llite.brw_read.total
Help:
total page count

lustre.llite.brw_read.min
Help:
minimum page value seen in a call

lustre.llite.brw_read.count
Help:
number of calls

lustre.llite.brw_read.max
Help:
maximum page value seen in a call

lustre.llite.create.count
Help:
number of calls

lustre.llite.removexattr.count
Help:
number of calls

lustre.llite.mkdir.count
Help:
number of calls

lustre.llite.alloc_inode.count
Help:
number of calls

lustre.llite.link.count
Help:
number of calls

lustre.llite.close.count
Help:
number of calls

lustre.llite.statfs.count
Help:
number of calls

lustre.llite.flock.count
Help:
number of calls

lustre.llite.write_bytes.count
Help:
number of calls

lustre.llite.write_bytes.max
Help:
maximum byte value seen in a call

lustre.llite.write_bytes.min
Help:
minimum byte value seen in a call

lustre.llite.write_bytes.total
Help:
total byte count

lustre.llite.volume
Help:
Volume Name

lustre.llite.osc_write.min
Help:
minimum byte value seen in a call

lustre.llite.osc_write.count
Help:
number of calls

lustre.llite.osc_write.max
Help:
maximum byte value seen in a call

lustre.llite.osc_write.total
Help:
total byte count

lustre.llite.rmdir.count
Help:
number of calls

lustre.llite.read_bytes.total
Help:
total byte count

lustre.llite.read_bytes.min
Help:
minimum byte value seen in a call

lustre.llite.read_bytes.count
Help:
number of calls

lustre.llite.read_bytes.max
Help:
maximum byte value seen in a call

lustre.llite.brw_write.max
Help:
maximum page value seen in a call

lustre.llite.brw_write.count
Help:
number of calls

lustre.llite.brw_write.min
Help:
minimum page value seen in a call

lustre.llite.brw_write.total
Help:
total page count

lustre.llite.truncate.count
Help:
number of calls

perfevent.version
Help:
The version number of the pmda.

perfevent.active
Help:
The number of active counters.

perfevent.hwcounters.cycles.dutycycle
Full Help: Error: One-line or help text is not available

perfevent.hwcounters.cycles.value
Full Help: Error: One-line or help text is not available

perfevent.hwcounters.instructions.dutycycle
Full Help: Error: One-line or help text is not available

perfevent.hwcounters.instructions.value
Full Help: Error: One-line or help text is not available

perfevent.derived.active
Full Help: Error: One-line or help text is not available

proc.nprocs
Help:
instantaneous number of processes

proc.psinfo.oom_score
Help:
out-of-memory process selection score (from /proc/<pid>/oom_score)

proc.psinfo.tgid
Help:
thread group identifier

proc.psinfo.ngid
Help:
NUMA group identifier (from /proc/<pid>/status)

proc.psinfo.cpusallowed
Help:
the cpus allowed list (from /proc/<pid>/status)

proc.psinfo.nvctxsw
Help:
number of non-voluntary context switches (from /proc/<pid>/status)

proc.psinfo.vctxsw
Help:
number of voluntary context switches (from /proc/<pid>/status)

proc.psinfo.labels
Help:
list of processes security labels (from /proc/<pid>/attr/current)

proc.psinfo.cgroups
Help:
list of processes cgroups (from /proc/<pid>/cgroup)

proc.psinfo.threads
Help:
number of threads (from /proc/<pid>/status)

proc.psinfo.sigcatch_s
Help:
caught signals mask in string form (from /proc/<pid>/status)

proc.psinfo.sigignore_s
Help:
ignored signals mask in string form (from /proc/<pid>/status)

proc.psinfo.blocked_s
Help:
blocked signals mask in string form (from /proc/<pid>/status)

proc.psinfo.signal_s
Help:
pending signals mask in string form (from /proc/<pid>/status)

proc.psinfo.environ
Help:
process environment (from /proc/<pid>/environ ascii space replaces null).

proc.psinfo.cguest_time
Help:
Guest time of the processs children

proc.psinfo.guest_time
Help:
Time spent running a virtual CPU for a guest operating system.

proc.psinfo.delayacct_blkio_time
Help:
Aggregated block I/O delays

proc.psinfo.policy
Help:
Scheduling policy

proc.psinfo.rt_priority
Help:
Real-time scheduling priority, a number in the range 1 to 99

proc.psinfo.psargs
Help:
full command string

proc.psinfo.wchan_s
Help:
This field needs access to a namelist file for proper 
address-to-symbol name translation. If no namelist file
is available, the address is printed instead. The namelist
file must match the current Linux kernel exactly.
The search path for the namelist file is as follows:
	/boot/System.map-`uname -r`
	/boot/System.map
	/lib/modules/`uname -r`/System.map
	/usr/src/linux/System.map
	/System.map

proc.psinfo.ttyname
Help:
name of controlling tty device, or ? if none. See also proc.psinfo.tty.

proc.psinfo.processor
Help:
last CPU the process was running on

proc.psinfo.exit_signal
Help:
the value in the exit_signal field of struct task_struct for the process

proc.psinfo.cnswap
Help:
count of page swap operations of all exited children

proc.psinfo.nswap
Help:
count of page swap operations

proc.psinfo.wchan
Help:
wait channel, kernel address this process is blocked or sleeping on

proc.psinfo.sigcatch
Help:
the value in the sigcatch field of struct task_struct for the process

proc.psinfo.sigignore
Help:
the value in the sigignore field of struct task_struct for the process

proc.psinfo.blocked
Help:
the value in the blocked field of struct task_struct for the process

proc.psinfo.signal
Help:
the value in the signal field of struct task_struct for the process

proc.psinfo.eip
Help:
the value in the eip field of struct task_struct for the process

proc.psinfo.esp
Help:
the value in the esp field of struct task_struct for the process

proc.psinfo.start_stack
Help:
address of the stack segment for the process

proc.psinfo.end_code
Help:
address of the end of the code segment for the process

proc.psinfo.start_code
Help:
address of the start of the code segment for the process

proc.psinfo.rss_rlim
Help:
limit on resident set size of process

proc.psinfo.rss
Help:
resident set size (i.e. physical memory) of the process

proc.psinfo.vsize
Help:
virtual size of the process in Kbytes

proc.psinfo.start_time
Help:
start time of the process relative to system boot time (in ms)

proc.psinfo.it_real_value
Help:
current interval timer value (zero if none)

proc.psinfo.nice
Help:
process nice value (negative nice values are lower priority)

proc.psinfo.priority
Help:
scheduling priority value

proc.psinfo.cstime
Help:
time (in ms) spent executing system code of all exited children

proc.psinfo.cutime
Help:
time (in ms) spent executing user code of all exited children

proc.psinfo.stime
Help:
time (in ms) spent executing system code (calls) since process started

proc.psinfo.utime
Help:
time (in ms) spent executing user code since process started

proc.psinfo.cmaj_flt
Help:
count of page faults other than reclaims of all exited children

proc.psinfo.maj_flt
Help:
count of page faults other than reclaims

proc.psinfo.cmin_flt
Help:
count of minor page faults (i.e. reclaims) of all exited children

proc.psinfo.minflt
Help:
count of minor page faults (i.e. reclaims)

proc.psinfo.flags
Help:
process state flags, as a bitmap

proc.psinfo.tty_pgrp
Help:
controlling tty process group identifier

proc.psinfo.tty
Help:
controlling tty device number (zero if none)

proc.psinfo.session
Help:
process session identifier

proc.psinfo.pgrp
Help:
process group identifier

proc.psinfo.ppid
Help:
parent process identifier

proc.psinfo.sname
Help:
process state identifier (see ps(1)). See also proc.runq metrics.

proc.psinfo.cmd
Help:
command name

proc.psinfo.pid
Help:
process identifier

proc.memory.vmnonlib
Help:
difference between process real memory use (vmreal) and libraries (vmlib)

proc.memory.vmreal
Help:
sum of resident set size and virtual memory swapped out

proc.memory.vmpte
Help:
memory occupied by page table entries (from /proc/<pid>/status)

proc.memory.vmhwm
Help:
peak usage of physical memory (from /proc/<pid>/status)

proc.memory.vmpin
Help:
fixed physical address unswappable pages (from /proc/<pid>/status)

proc.memory.vmpeak
Help:
peak virtual memory size (from /proc/<pid>/status)

proc.memory.vmswap
Help:
virtual memory size currently swapped out (from /proc/<pid>/status)

proc.memory.vmlib
Help:
virtual memory used for libraries (from /proc/<pid>/status)

proc.memory.vmexe
Help:
virtual memory used for non-library executable code (from /proc/<pid>/status)

proc.memory.vmstack
Help:
virtual memory used for stack (from /proc/<pid>/status)

proc.memory.vmdata
Help:
virtual memory used for data (from /proc/<pid>/status)

proc.memory.vmrss
Help:
resident virtual memory (from /proc/<pid>/status)

proc.memory.vmlock
Help:
locked virtual memory (from /proc/<pid>/status)

proc.memory.vmsize
Help:
total virtual memory (from /proc/<pid>/status)

proc.memory.maps
Help:
table of memory mapped by process in string form from /proc/<pid>/maps

proc.memory.dirty
Help:
instantaneous amount of memory that has been modified by the process, in Kbytes

proc.memory.datrss
Help:
instantaneous resident size of process data segment, in Kbytes

proc.memory.librss
Help:
instantaneous resident size of library code mapped by the process, in Kbytes

proc.memory.textrss
Help:
instantaneous resident size of process code segment in Kbytes

proc.memory.share
Help:
instantaneous amount of memory shared by this process with other processes 

proc.memory.rss
Help:
instantaneous resident size of process, excluding page table and task structure.

proc.memory.size
Help:
instantaneous virtual size of process, excluding page table and task structure.

proc.id.container
Help:
name of processes container (from /proc/<pid>/cgroup heuristics)

proc.id.fsgid_nm
Help:
filesystem group name based on filesystem group ID from /proc/<pid>/status

proc.id.sgid_nm
Help:
saved group name based on saved group ID from /proc/<pid>/status

proc.id.egid_nm
Help:
effective group name based on effective group ID from /proc/<pid>/status

proc.id.gid_nm
Help:
real group name based on real group ID from /proc/<pid>/status

proc.id.fsuid_nm
Help:
filesystem user name based on filesystem user ID from /proc/<pid>/status

proc.id.suid_nm
Help:
saved user name based on saved user ID from /proc/<pid>/status

proc.id.euid_nm
Help:
effective user name based on effective user ID from /proc/<pid>/status

proc.id.uid_nm
Help:
real user name based on real user ID from /proc/<pid>/status

proc.id.fsgid
Help:
filesystem group ID from /proc/<pid>/status

proc.id.sgid
Help:
saved group ID from /proc/<pid>/status

proc.id.egid
Help:
effective group ID from /proc/<pid>/status

proc.id.gid
Help:
real group ID from /proc/<pid>/status

proc.id.fsuid
Help:
filesystem user ID from /proc/<pid>/status

proc.id.suid
Help:
saved user ID from /proc/<pid>/status

proc.id.euid
Help:
effective user ID from /proc/<pid>/status

proc.id.uid
Help:
real user ID from /proc/<pid>/status

proc.io.cancelled_write_bytes
Help:
Number of bytes cancelled via truncate by this process.  Actual physical
writes for an individual process can be calculated as:
	proc.io.write_bytes - proc.io.cancelled_write_bytes.

proc.io.write_bytes
Help:
Number of bytes physically written to devices on behalf of this process.
This must be reduced by any truncated I/O (proc.io.cancelled_write_bytes).

proc.io.read_bytes
Help:
Number of bytes physically read on by devices on behalf of this process.

proc.io.syscw
Help:
Extended accounting information - count of number of calls to the
write(2), writev(2) and sendfile(2) syscalls by each process.

proc.io.syscr
Help:
Extended accounting information - count of number of calls to the
read(2), readv(2) and sendfile(2) syscalls by each process.

proc.io.wchar
Help:
Extended accounting information - count of the number of bytes that
have passed over the write(2), writev(2) and sendfile(2) syscalls by
each process.

proc.io.rchar
Help:
Extended accounting information - count of the number of bytes that
have passed over the read(2), readv(2) and sendfile(2) syscalls by
each process.

proc.schedstat.pcount
Help:
Number of times a process has been scheduled to run on a CPU (this is
incremented when a task actually reaches a CPU to run on, not simply
when it is added to the run queue).

proc.schedstat.run_delay
Help:
Length of time in nanoseconds that a process spent waiting to be scheduled
to run in the run queue.

proc.schedstat.cpu_time
Help:
Length of time in nanoseconds that a process has been running, including
scheduling time.

proc.fd.count
Help:
Number of file descriptors this process has open.

proc.namespaces.envid
Help:
OpenVZ container identifier

proc.namespaces.sid
Help:
descendant namespace session ID hierarchy (/proc/<pid>/status)

proc.namespaces.pgid
Help:
descendant namespace process group ID hierarchy (/proc/<pid>/status)

proc.namespaces.pid
Help:
descendant namespace process ID hierarchy (/proc/<pid>/status)

proc.namespaces.tgid
Help:
descendant namespace thread group ID hierarchy (/proc/<pid>/status)

proc.runq.runnable
Help:
Instantaneous number of runnable (on run queue) processes;
state 'R' in ps(1).

proc.runq.blocked
Help:
Instantaneous number of processes in uninterruptible sleep or parked;
state 'D' in ps(1).

proc.runq.sleeping
Help:
Instantaneous number of processes sleeping; state 'S' in ps(1).

proc.runq.stopped
Help:
Instantaneous number of traced, stopped or suspended processes; state
'tT' in ps(1).

proc.runq.swapped
Help:
Instantaneous number of processes (excluding kernel threads) that are
swapped; state 'SW' in ps(1).

proc.runq.defunct
Help:
Instantaneous number of defunct/zombie processes; state 'Z' in ps(1).

proc.runq.unknown
Help:
Instantaneous number of processes is an unknown state, including all
kernel threads

proc.runq.kernel
Help:
Instantaneous number of processes with virtual size of zero (kernel threads)

proc.control.all.threads
Help:
If set to one, the process instance domain as reported by pmdaproc
contains all threads as well as the processes that started them.
If set to zero, the process instance domain contains only processes.

This setting is persistent for the life of pmdaproc and affects all
client tools that request instances and values from pmdaproc.
Use either pmstore(1) or pmStore(3) to modify this metric.

proc.control.perclient.threads
Help:
If set to one, the process instance domain as reported by pmdaproc
contains all threads as well as the processes that started them.
If set to zero, the process instance domain contains only processes.

This setting is only visible to the active client context.  In other
words, storing into this metric has no effect for other monitoring
tools.  See proc.control.all.threads, if that is the desired outcome.
Only pmStore(3) can effectively set this metric (pmstore(1) cannot).

proc.control.perclient.cgroups
Help:
If set to the empty string (the default), the process instance domain
as reported by pmdaproc contains all processes.  However, a cgroup
name (full path) can be stored into this metric in order to restrict
processes reported to only those within the specified cgroup.  This
set is further affected by the value of proc.control.perclient.threads.

This setting is only visible to the active client context.  In other
words, storing into this metric has no effect for other monitoring
tools.  pmStore(3) must be used to set this metric (not pmstore(1)).

event.flags
Full Help: Error: One-line or help text is not available

event.missed
Full Help: Error: One-line or help text is not available

proc.psinfo.age
Full Help: Error: One-line or help text is not available

proc.io.total_bytes
Full Help: Error: One-line or help text is not available

proc.hog.cpu
Full Help: Error: One-line or help text is not available

proc.hog.mem
Full Help: Error: One-line or help text is not available

proc.hog.disk
Full Help: Error: One-line or help text is not available

disk.dev.await
Full Help: Error: One-line or help text is not available

disk.dev.r_await
Full Help: Error: One-line or help text is not available

disk.dev.w_await
Full Help: Error: One-line or help text is not available

disk.dev.avg_qlen
Full Help: Error: One-line or help text is not available

disk.dev.avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dev.r_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dev.w_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dev.util
Full Help: Error: One-line or help text is not available

disk.dm.await
Full Help: Error: One-line or help text is not available

disk.dm.r_await
Full Help: Error: One-line or help text is not available

disk.dm.w_await
Full Help: Error: One-line or help text is not available

disk.dm.avg_qlen
Full Help: Error: One-line or help text is not available

disk.dm.avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dm.r_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dm.w_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.dm.util
Full Help: Error: One-line or help text is not available

disk.md.await
Full Help: Error: One-line or help text is not available

disk.md.r_await
Full Help: Error: One-line or help text is not available

disk.md.w_await
Full Help: Error: One-line or help text is not available

disk.md.avg_qlen
Full Help: Error: One-line or help text is not available

disk.md.avg_rqsz
Full Help: Error: One-line or help text is not available

disk.md.r_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.md.w_avg_rqsz
Full Help: Error: One-line or help text is not available

disk.md.util
Full Help: Error: One-line or help text is not available

kernel.cpu.util.user
Full Help: Error: One-line or help text is not available

kernel.cpu.util.nice
Full Help: Error: One-line or help text is not available

kernel.cpu.util.sys
Full Help: Error: One-line or help text is not available

kernel.cpu.util.idle
Full Help: Error: One-line or help text is not available

kernel.cpu.util.intr
Full Help: Error: One-line or help text is not available

kernel.cpu.util.wait
Full Help: Error: One-line or help text is not available

kernel.cpu.util.steal
Full Help: Error: One-line or help text is not available
